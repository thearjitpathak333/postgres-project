<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PostgreSQL Knowledge Base</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/exclamation-circle.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/bug.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/bolt.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/lock-closed.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/server.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/archive-box.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/cpu-chip.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/magnifying-glass.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/shield-check.html" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/circle-stack.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/arrow-up-tray.svg" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/heroicons/2.1.1/24/outline/wrench-screwdriver.svg" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">


    <style>
        body {
            font-family: 'Inter', sans-serif;
        }

        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

        /* Custom Colors & Theme Adjustments - Light Mode Defaults */
        /* Body & Backgrounds */
        .bg-light-peach { background-color: #FFF8F3; } /* Very light, warm background */
        .bg-smooth-cream { background-color: #FDF9F3; } /* Slightly different warm off-white */
        .text-dark-charcoal { color: #2B2D42; } /* Dark text for readability */
        .text-medium-gray { color: #5B6A78; } /* Medium text for secondary info */

        /* Sidebar & Navigation */
        .bg-sidebar-light { background-color: #F8F9FA; } /* Off-white for sidebar */
        .border-soft-gray { border-color: #E2E8F0; } /* Light border for separation */

        /* Primary Accent Color (Teal/Aqua) */
        .bg-accent-light { background-color: #E6FFFA; } /* Very light accent background */
        .text-accent-dark { color: #2D9B91; } /* Darker accent text */
        .hover-accent-bg:hover { background-color: #E0F2F0; } /* Subtle hover */

        /* Sidebar Item Active and Hover States */
        .sidebar-item.active {
            background-color: #C0F0F0; /* Brighter accent for active state */
            color: #00796B; /* Deeper teal for active text */
            font-weight: 600;
        }
        .sidebar-parent.active {
            background-color: #EDF7F6;
            color: #2D9B91;
        }


        .sidebar-item:hover:not(.active) {
            background-color: #EDF7F6; /* Lighter hover for non-active items */
            color: #2D9B91; /* Accent color on hover */
        }

        /* Card and Accordion Backgrounds */
        .bg-card-light { background-color: #FFFFFF; } /* Pure white for cards */

        /* Dynamic Colors for Dashboard Cards */
        .text-dashboard-primary { color: #4CAF50; } /* Green for positive metrics */
        .text-dashboard-secondary { color: #FFC107; } /* Amber for neutral/attention */
        .text-dashboard-critical { color: #F44336; } /* Red for critical */
        .text-dashboard-info { color: #2196F3; } /* Blue for informational metrics */


        .accordion-content {
            display: none;
            overflow: hidden;
            transition: max-height 0.3s ease-in-out;
        }

        .code-block {
            position: relative;
        }

        .copy-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background-color: #4B5563; /* Gray-700 for code controls */
            color: white;
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
            font-size: 0.75rem;
            cursor: pointer;
            opacity: 0;
            transition: opacity 0.2s ease-in-out;
        }

        .code-block:hover .copy-btn {
            opacity: 1;
        }

        .copy-feedback {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background-color: #16A34A; /* Green-600 */
            color: white;
            padding: 0.25rem 0.5rem;
            border-radius: 0.25rem;
            font-size: 0.75rem;
        }

        /* Chatbot specific styles */
        #chatbot-container {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 320px;
            height: 400px; /* Adjust height as needed */
            background-color: #FFFFFF;
            border-radius: 12px;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.15);
            display: flex;
            flex-direction: column;
            overflow: hidden;
            z-index: 1000;
            transform: translateY(100%) scale(0.8);
            opacity: 0;
            transition: all 0.3s ease-out;
            transform-origin: bottom right;
        }

        #chatbot-container.open {
            transform: translateY(0) scale(1);
            opacity: 1;
        }

        #chatbot-toggle-button {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background-color: #2D9B91; /* Accent color */
            color: white;
            border-radius: 50%;
            width: 56px;
            height: 56px;
            display: flex;
            justify-content: center;
            align-items: center;
            font-size: 24px;
            cursor: pointer;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            z-index: 1001;
            transition: transform 0.2s ease-in-out;
        }

        #chatbot-toggle-button:hover {
            transform: scale(1.05);
        }

        #chatbot-header {
            background-color: #2D9B91; /* Accent color */
            color: white;
            padding: 12px 16px;
            border-top-left-radius: 12px;
            border-top-right-radius: 12px;
            font-weight: 600;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        #chatbot-close-button {
            background: none;
            border: none;
            color: white;
            font-size: 20px;
            cursor: pointer;
        }

        #chatbot-messages {
            flex-grow: 1;
            padding: 15px;
            overflow-y: auto;
            background-color: #FDF9F3; /* Smooth cream background */
            border-bottom: 1px solid #E2E8F0;
        }

        .chatbot-message {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 8px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .chatbot-message.user {
            background-color: #E6FFFA; /* Accent light */
            color: #2B2D42; /* Dark charcoal */
            align-self: flex-end;
            margin-left: auto;
        }

        .chatbot-message.bot {
            background-color: #EDF7F6; /* Lighter hover accent */
            color: #2B2D42; /* Dark charcoal */
            align-self: flex-start;
            margin-right: auto;
        }

        #chatbot-input-area {
            display: flex;
            padding: 10px 15px;
            border-top: 1px solid #E2E8F0;
            background-color: #FFFFFF;
        }

        #chatbot-input {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #CBD5E0; /* Slate-300 */
            border-radius: 8px;
            margin-right: 10px;
            font-size: 14px;
            outline: none;
        }

        #chatbot-input:focus {
            border-color: #2D9B91; /* Accent dark */
            box-shadow: 0 0 0 2px rgba(45, 155, 145, 0.2);
        }

        #chatbot-send-button {
            background-color: #2D9B91; /* Accent dark */
            color: white;
            border: none;
            border-radius: 8px;
            padding: 10px 15px;
            cursor: pointer;
            transition: background-color 0.2s ease-in-out;
        }

        #chatbot-send-button:hover {
            background-color: #00796B; /* Deeper teal */
        }

        /* Dark Mode Styles */
        body.dark {
            background-color: #1a202c; /* Dark background */
            color: #e2e8f0; /* Light text */
        }

        body.dark .text-dark-charcoal { color: #e2e8f0; } /* Light text for dark mode */
        body.dark .text-medium-gray { color: #a0aec0; } /* Lighter gray for secondary text */

        body.dark .bg-sidebar-light { background-color: #2d3748; } /* Darker sidebar */
        body.dark .border-soft-gray { border-color: #4a5568; } /* Darker border */

        body.dark .bg-card-light { background-color: #2d3748; } /* Darker cards */
        body.dark .bg-smooth-cream { background-color: #202a36; } /* Darker main content area */

        /* Dark Mode Accent colors */
        body.dark .bg-accent-light { background-color: #4c6f6d; } /* Darker accent background */
        body.dark .text-accent-dark { color: #81e6d9; } /* Lighter accent text */
        body.dark .hover-accent-bg:hover { background-color: #3b5c5a; } /* Darker subtle hover */

        body.dark .sidebar-item.active {
            background-color: #00796b; /* Darker accent for active state */
            color: #ffffff; /* White text for active */
        }
        body.dark .sidebar-parent.active {
            background-color: #3b5c5a;
            color: #81e6d9;
        }

        body.dark .sidebar-item:hover:not(.active) {
            background-color: #1a4f4b; /* Darker hover for non-active items */
            color: #81e6d9; /* Accent color on hover */
        }

        body.dark #chatbot-container,
        body.dark #chatbot-input-area {
            background-color: #2d3748;
            border-color: #4a5568;
        }

        body.dark #chatbot-messages {
            background-color: #202a36;
            border-color: #4a5568;
        }

        body.dark .chatbot-message.user {
            background-color: #00796b;
            color: #ffffff;
        }

        body.dark .chatbot-message.bot {
            background-color: #4a5568;
            color: #e2e8f0;
        }

        body.dark #chatbot-input {
            background-color: #2d3748;
            color: #e2e8f0;
            border-color: #4a5568;
        }
        body.dark #chatbot-input:focus {
            border-color: #81e6d9;
            box-shadow: 0 0 0 2px rgba(129, 230, 217, 0.2);
        }

        /* Icon colors for dark mode if they are currentColor */
        body.dark .sidebar-item svg {
            stroke: currentColor; /* Ensure SVG icons respect text color */
        }

        /* Styling for the new error log format */
        .error-section-title {
            font-weight: 600; /* Semi-bold */
            color: #2B2D42; /* Dark charcoal */
            margin-top: 1rem;
            margin-bottom: 0.5rem;
            display: block; /* Ensures it takes its own line */
        }

        body.dark .error-section-title {
            color: #e2e8f0; /* Light text for dark mode */
        }

        .error-content-body ul {
            list-style-type: disc;
            margin-left: 1.25rem; /* Equivalent to pl-5 */
            padding-left: 0;
        }
        .error-content-body li {
            margin-bottom: 0.25rem;
        }
        /* Style for code blocks within content */
        pre {
            background-color: #2d3748; /* Dark background for code */
            color: #e2e8f0; /* Light text for code */
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            margin-top: 0.5rem;
            margin-bottom: 1rem;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
            position: relative; /* For copy button positioning */
        }

        code {
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
            background-color: #e2e8f0; /* Light background for inline code */
            color: #2d3748; /* Dark text for inline code */
            padding: 0.2em 0.4em;
            border-radius: 0.25rem;
            font-size: 0.875em; /* Slightly smaller than parent */
        }

        body.dark code {
            background-color: #4a5568; /* Darker background for inline code in dark mode */
            color: #e2e8f0; /* Light text for inline code in dark mode */
        }

        /* Table styling for join examples */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
            font-size: 0.9rem;
        }
        .data-table th, .data-table td {
            border: 1px solid #e2e8f0; /* soft-gray equivalent */
            padding: 0.75rem;
            text-align: left;
        }
        .data-table th {
            background-color: #F8F9FA; /* sidebar-light equivalent */
            font-weight: 600;
            color: #2B2D42; /* dark-charcoal equivalent */
        }
        body.dark .data-table th {
            background-color: #2d3748; /* Darker sidebar equivalent */
            color: #e2e8f0; /* Light text */
        }
        body.dark .data-table td {
            border-color: #4a5568; /* Darker border */
        }

        /* Quick Access Section Styles */
        .quick-access-card {
            background-color: #FFFFFF;
            border-radius: 0.75rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }

        .quick-access-header {
            background-color: #F8F9FA;
            padding: 1rem 1.25rem;
            border-bottom: 1px solid #E2E8F0;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .quick-access-header h6 {
            margin: 0;
            font-size: 1rem;
            font-weight: 600;
            color: #2D9B91; /* Accent dark */
        }

        .quick-access-body {
            padding: 0;
        }

        .common-issue-item {
            display: flex;
            align-items: center;
            padding: 0.75rem 1.25rem;
            border-bottom: 1px solid #E2E8F0;
            text-decoration: none;
            color: #2B2D42;
            transition: background-color 0.2s ease-in-out;
        }

        .common-issue-item:last-child {
            border-bottom: none;
        }

        .common-issue-item:hover {
            background-color: #EDF7F6; /* Lighter hover accent */
        }

        .issue-icon-wrapper {
            width: 32px;
            height: 32px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-shrink: 0;
            margin-right: 0.75rem;
        }

        .issue-icon-wrapper.critical { background-color: rgba(244, 67, 54, 0.1); }
        .issue-icon-wrapper.high { background-color: rgba(255, 193, 7, 0.1); }
        .issue-icon-wrapper.medium { background-color: rgba(33, 150, 243, 0.1); }
        .issue-icon-wrapper.low { background-color: rgba(91, 106, 120, 0.1); }

        .issue-icon-wrapper i {
            font-size: 0.9rem;
        }

        .issue-content-wrapper {
            flex-grow: 1;
        }

        .issue-title {
            font-weight: 500;
            font-size: 0.9rem;
            line-height: 1.3;
        }

        .issue-category {
            font-size: 0.75rem;
            color: #5B6A78;
        }

        .issue-arrow {
            color: #5B6A78;
            font-size: 0.75rem;
        }

        body.dark .quick-access-card {
            background-color: #2d3748;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
        }

        body.dark .quick-access-header {
            background-color: #202a36;
            border-bottom-color: #4a5568;
        }

        body.dark .quick-access-header h6 {
            color: #81e6d9;
        }

        body.dark .common-issue-item {
            background-color: #2d3748;
            border-bottom-color: #4a5568;
            color: #e2e8f0;
        }

        body.dark .common-issue-item:hover {
            background-color: #3b5c5a;
        }

        body.dark .issue-category {
            color: #a0aec0;
        }

        body.dark .issue-arrow {
            color: #a0aec0;
        }
        
        /* Chart specific styles */
        .chart-container {
            position: relative;
            height: 300px; /* Adjust height as needed */
            width: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #overviewChart {
            max-width: 100%;
            max-height: 100%;
        }

        #chart-center-text {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            pointer-events: none; /* Allows clicks to pass through to the chart */
            z-index: 10;
            background: rgba(255, 255, 255, 0.9);
            border-radius: 8px;
            padding: 10px 15px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        body.dark #chart-center-text {
            background: rgba(45, 55, 72, 0.9);
        }

        #chart-center-text .h4 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 0.25rem;
            color: #2B2D42;
        }

        body.dark #chart-center-text .h4 {
            color: #e2e8f0;
        }

        #chart-center-text .small {
            font-size: 0.75rem;
            color: #5B6A78;
        }

        body.dark #chart-center-text .small {
            color: #a0aec0;
        }
    </style>
</head>

<body class="bg-light-peach text-dark-charcoal">

    <div class="flex h-screen">
        <aside id="sidebar"
            class="w-64 bg-sidebar-light border-r border-soft-gray flex flex-col transition-all duration-300 -translate-x-full sm:translate-x-0 shadow-lg sm:shadow-md">
            <div class="p-4 border-b border-soft-gray flex items-center space-x-3">
                <span class="inline-block p-2 bg-accent-light text-accent-dark rounded-lg">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                        stroke="currentColor" class="w-6 h-6">
                        <path stroke-linecap="round" stroke-linejoin="round"
                            d="M20.25 6.375c0 2.278-3.693 4.125-8.25 4.125S3.75 8.653 3.75 6.375 7.443 2.25 12 2.25s8.25 1.872 8.25 4.125zm-1.125 3.375a4.125 4.125 0 01-8.25 0v-.375c0-2.278 3.693-4.125 8.25-4.125s8.25 1.872 8.25 4.125v.375zm-1.125 3.375a4.125 4.125 0 01-8.25 0v-.375c0-2.278 3.693-4.125 8.25-4.125s8.25 1.872 8.25 4.125v.375zM12 18.75c-4.557 0-8.25-1.872-8.25-4.125v-.375c0-2.278 3.693-4.125 8.25-4.125s8.25 1.872 8.25 4.125v.375c0 2.253-3.693 4.125-8.25 4.125z" />
                    </svg>
                </span>
                <h1 class="text-xl font-bold text-dark-charcoal">Knowledge Base</h1>
            </div>
            <!-- Adjusted padding and spacing for a more compact sidebar -->
            <nav id="main-nav" class="flex-1 p-2 space-y-1 overflow-y-auto">
                </nav>
            <div class="p-4 border-t border-soft-gray text-xs text-medium-gray">
                <p>&copy; 2024 PostgreSQL Error Knowledge Base. All rights reserved.</p>
            </div>
        </aside>

        <main class="flex-1 flex flex-col overflow-hidden">
            <header class="bg-card-light border-b border-soft-gray p-4 flex justify-between items-center">
                <button id="menu-toggle" class="sm:hidden p-2 text-medium-gray hover:bg-soft-gray rounded-lg">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                        stroke="currentColor" class="w-6 h-6">
                        <path stroke-linecap="round" stroke-linejoin="round"
                            d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
                    </svg>
                </button>
                <div id="search-container" class="relative w-full max-w-lg hidden">
                    <div class="absolute inset-y-0 left-0 pl-3 flex items-center pointer-events-none">
                        <svg class="h-5 w-5 text-medium-gray" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20"
                            fill="currentColor" aria-hidden="true">
                            <path fill-rule="evenodd"
                                d="M9 3.5a5.5 5.5 0 100 11 5.5 5.5 0 000-11zM2 9a7 7 0 1112.452 4.391l3.328 3.329a.75.75 0 11-1.06 1.06l-3.329-3.328A7 7 0 012 9z"
                                clip-rule="evenodd" />
                        </svg>
                    </div>
                    <input type="text" id="search-input" placeholder="Search issues in this category..."
                        class="block w-full pl-10 pr-3 py-2 border border-soft-gray rounded-md leading-5 bg-card-light placeholder-medium-gray focus:outline-none focus:placeholder-light-gray focus:ring-1 focus:ring-accent-dark focus:border-accent-dark sm:text-sm">
                </div>
                <div id="header-title" class="text-lg font-semibold text-dark-charcoal"></div>

                <button id="theme-toggle" class="p-2 text-medium-gray hover:bg-soft-gray rounded-lg ml-auto">
                    <svg id="theme-toggle-light-icon" class="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h1M3 12H2m15.325-6.675l.707-.707M6.675 17.325l-.707.707M18.675 17.325l.707.707M6.675 6.675l-.707-.707M12 7a5 5 0 100 10 5 5 0 000-10z" />
                    </svg>
                    <svg id="theme-toggle-dark-icon" class="w-6 h-6 hidden" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z" />
                    </svg>
                </button>
            </header>

            <div id="content-area" class="flex-1 overflow-y-auto p-4 sm:p-6 lg:p-8 bg-smooth-cream">
                </div>
        </main>
    </div>

    <div id="chatbot-container">
        <div id="chatbot-header">
            <span>PostgreSQL Bot</span>
            <button id="chatbot-close-button">&times;</button>
        </div>
        <div id="chatbot-messages">
            <div class="chatbot-message bot">Hello! Type an error or a keyword to find a solution.</div>
        </div>
        <div id="chatbot-input-area">
            <input type="text" id="chatbot-input" placeholder="Ask about an error...">
            <button id="chatbot-send-button">Send</button>
        </div>
    </div>

    <button id="chatbot-toggle-button">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" class="w-7 h-7">
            <path stroke-linecap="round" stroke-linejoin="round" d="M8.625 12a.375.375 0 11-.75 0 .375.375 0 01.75 0zm0 0H8.25m4.125 0a.375.375 0 11-.75 0 .375.375 0 01.75 0zm0 0H12m4.125 0a.375.375 0 11-.75 0 .375.375 0 01.75 0zm0 0h-.375M21 12c0 4.556-4.03 8.25-9 8.25a9.75 9.75 0 01-1.62-.108V21.75a.75.75 0 01-1.5 0v-2.625M4.78 17.61a9 9 0 01-1.89-4.363C2.145 10.51 3.56 7.07 6.742 5.034a3 3 0 014.242 0-5.96 5.96 0 014.242 0c3.182 2.036 4.607 5.476 3.732 8.513l.774.774a.75.75 0 01-1.06 1.06l-.774-.774Z" />
        </svg>
    </button>
    <script>
        // Data from Catalog.json
        const catalogData = [
            {
                "table_name": "pg_class",
                "purpose": "Stores metadata about tables, indexes, sequences, views, materialized views, composite types, and TOAST tables. It's the central catalog for 'relations' in PostgreSQL.",
                "important_columns": [
                "relname (name of the relation)",
                "relnamespace (OID of the namespace/schema)",
                "relkind (type of relation: r=table, i=index, v=view, m=materialized view, S=sequence, t=TOAST table, c=composite type, f=foreign table, p=partitioned table, I=partitioned index)",
                "reltuples (estimated number of live rows)",
                "relpages (estimated number of disk pages)"
                ],
                "sample_select_query": "SELECT relname, relkind, reltuples, relpages FROM pg_class WHERE relnamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public') AND relkind IN ('r', 'v', 'm');",
                "use_in_monitoring_debugging": "Used to get an overview of all relations in the database, their types, estimated sizes, and row counts. Useful for understanding database schema, identifying large tables/indexes, and checking for potential bloat (by comparing reltuples/relpages with actual counts/sizes)."
            },
            {
                "table_name": "pg_attribute",
                "purpose": "Stores metadata about columns (attributes) of relations (tables, views, etc.) defined in pg_class.",
                "important_columns": [
                "attrelid (OID of the relation this attribute belongs to)",
                "attname (name of the attribute/column)",
                "atttypid (OID of the data type of the attribute)",
                "attnum (column number, starting from 1 for user columns)",
                "attnotnull (true if column is NOT NULL)",
                "atthasdef (true if column has a default value)"
                ],
                "sample_select_query": "SELECT a.attname, pg_catalog.format_type(a.atttypid, a.atttypmod) AS data_type, a.attnotnull FROM pg_attribute a WHERE a.attrelid = 'your_table_name'::regclass AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum;",
                "use_in_monitoring_debugging": "Provides detailed information about table columns, including data types, nullability, and default values. Essential for schema introspection, understanding table structures, and debugging issues related to data types or constraints."
            },
            {
                "table_name": "pg_stat_activity",
                "purpose": "Provides real-time information about all active sessions connected to the PostgreSQL database server.",
                "important_columns": [
                "pid (process ID of the backend)",
                "usename (user connected to the session)",
                "datname (database connected to)",
                "application_name (application connecting to the database)",
                "client_addr (IP address of the client)",
                "state (current state of the backend: active, idle, idle in transaction, etc.)",
                "query (the SQL query currently being executed)",
                "query_start (timestamp when the current query started)",
                "wait_event_type (type of event the backend is waiting for)",
                "wait_event (specific event the backend is waiting for)"
                ],
                "sample_select_query": "SELECT pid, usename, datname, client_addr, state, query, query_start, age(now(), query_start) AS query_age FROM pg_stat_activity WHERE state = 'active' ORDER BY query_age DESC;",
                "use_in_monitoring_debugging": "Crucial for real-time monitoring of database activity. Helps identify long-running queries, blocked sessions, idle-in-transaction sessions, and resource bottlenecks. Can be used to pinpoint problematic queries or applications causing performance issues."
            },
            {
                "table_name": "pg_indexes",
                "purpose": "A view that provides access to useful information about each index in the database, simplifying index management.",
                "important_columns": [
                "schemaname (name of the schema containing the table and index)",
                "tablename (name of the table the index is for)",
                "indexname (name of the index)",
                "indexdef (the CREATE INDEX command used to define the index)"
                ],
                "sample_select_query": "SELECT schemaname, tablename, indexname, indexdef FROM pg_indexes WHERE schemaname = 'public' ORDER BY tablename, indexname;",
                "use_in_monitoring_debugging": "Used to list existing indexes, understand their definitions, and identify missing or redundant indexes. Helps in optimizing query performance by ensuring appropriate indexes are in place and by analyzing index usage (often in conjunction with `pg_stat_all_indexes`)."
            },
            {
                "table_name": "pg_locks",
                "purpose": "Provides information about all active locks held by database processes, including shared and exclusive locks on various database objects.",
                "important_columns": [
                "pid (process ID holding or waiting for the lock)",
                "locktype (type of lock: relation, tuple, transactionid, etc.)",
                "database (OID of the database the lock is on)",
                "relation::regclass (name of the relation if it's a relation lock)",
                "mode (lock mode: AccessShareLock, RowExclusiveLock, ExclusiveLock, etc.)",
                "granted (true if the lock is granted, false if waiting)"
                ],
                "sample_select_query": "SELECT\n  blocked_locks.pid AS blocked_pid,\n  blocked_activity.usename AS blocked_user,\n  blocked_activity.query AS blocked_query,\n  blocking_locks.pid AS blocking_pid,\n  blocking_activity.usename AS blocking_user,\n  blocking_activity.query AS blocking_query\nFROM pg_catalog.pg_locks blocked_locks\nJOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid\nJOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype\n  AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database\n  AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation\n  AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page\n  AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple\n  AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid\n  AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid\n  AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid\n  AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid\n  AND blocking_locks.pid != blocked_locks.pid\nJOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid\nWHERE NOT blocked_locks.granted;",
                "use_in_monitoring_debugging": "Essential for diagnosing and resolving locking issues, deadlocks, and blocking sessions. Helps identify which processes are holding locks and which processes are waiting for them, allowing DBAs to troubleshoot and potentially terminate problematic sessions."
            },
            {
                "table_name": "pg_database",
                "purpose": "Stores information about the available databases within the PostgreSQL cluster. Unlike most system catalogs, it is shared across all databases.",
                "important_columns": [
                "datname (database name)",
                "datdba (OID of the database owner)",
                "encoding (character encoding for the database)",
                "datistemplate (true if this database can be cloned)",
                "datallowconn (true if connections are allowed to this database)",
                "datconnlimit (maximum number of concurrent connections)"
                ],
                "sample_select_query": "SELECT datname, pg_catalog.pg_encoding_to_char(encoding) AS encoding_name, datistemplate, datallowconn, datconnlimit FROM pg_database ORDER BY datname;",
                "use_in_monitoring_debugging": "Provides an overview of all databases in the cluster. Useful for checking database configurations, identifying template databases, and monitoring connection limits. Helps in managing database-level settings and understanding the overall database landscape."
            },
            {
                "table_name": "pg_tables",
                "purpose": "A view that provides access to useful information about each table in the database, excluding system tables by default.",
                "important_columns": [
                "schemaname (name of schema containing table)",
                "tablename (name of table)",
                "tableowner (name of table's owner)",
                "tablespace (name of tablespace containing table)",
                "hasindexes (true if table has any indexes)",
                "hastriggers (true if table has any triggers)"
                ],
                "sample_select_query": "SELECT schemaname, tablename, tableowner, tablespace FROM pg_tables WHERE schemaname NOT IN ('pg_catalog', 'information_schema') ORDER BY schemaname, tablename;",
                "use_in_monitoring_debugging": "Provides a user-friendly way to list and inspect tables within the database, excluding internal system tables. Useful for schema exploration, identifying table ownership, and quickly checking for the presence of indexes or triggers on user tables."
            }
        ];

        const db = {
            dashboard: {
                title: "Dashboard", // Keep title for sidebar display
                metrics: {}, // Will be populated dynamically
                content: (metrics) => `
                    <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-4 mb-6">
                        <div class="bg-card-light p-4 rounded-lg shadow-md text-center transform transition-transform duration-200 hover:-translate-y-1 hover:shadow-lg">
                            <h3 class="text-md font-semibold text-medium-gray">Total Issues Cataloged</h3>
                            <p class="text-4xl font-bold text-dashboard-primary mt-1">${metrics.totalErrors}</p>
                        </div>
                        <div class="bg-card-light p-4 rounded-lg shadow-md text-center transform transition-transform duration-200 hover:-translate-y-1 hover:shadow-lg">
                            <h3 class="text-md font-semibold text-medium-gray">Category with Most Issues</h3>
                            <p class="text-2xl font-bold text-dashboard-secondary mt-1">${metrics.categoryMostErrors}</p>
                        </div>
                        <div class="bg-card-light p-4 rounded-lg shadow-md text-center transform transition-transform duration-200 hover:-translate-y-1 hover:shadow-lg">
                            <h3 class="text-md font-semibold text-medium-gray">Critical Issues Identified</h3>
                            <p class="text-4xl font-bold text-dashboard-critical mt-1">${metrics.criticalIssues}</p>
                        </div>
                        <div class="bg-card-light p-4 rounded-lg shadow-md text-center transform transition-transform duration-200 hover:-translate-y-1 hover:shadow-lg">
                            <h3 class="text-md font-semibold text-medium-gray">Total Categories</h3>
                            <p class="text-4xl font-bold text-dashboard-info mt-1">${metrics.totalCategories}</p>
                        </div>
                    </div>
                    <div class="grid grid-cols-1 lg:grid-cols-2 gap-6 mb-6">
                        <!-- Chart Section -->
                        <div class="col-span-1">
                            <div class="bg-card-light p-6 rounded-lg shadow-md">
                                <h2 class="text-xl font-semibold text-dark-charcoal mb-4">Issue Distribution by Category</h2>
                                <div class="chart-container">
                                    <canvas id="categoryChart"></canvas>
                                    <div id="chart-center-text">
                                        <div class="h4" id="total-issues-display">0</div>
                                        <div class="small text-medium-gray">Total Issues</div>
                                    </div>
                                </div>
                                <details id="category-filter-details" class="w-full p-4 bg-smooth-cream rounded-md border border-soft-gray mt-6">
                                    <summary class="text-lg font-semibold text-dark-charcoal cursor-pointer flex justify-between items-center">
                                        Filter Categories
                                        <svg class="w-5 h-5 transform transition-transform" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
                                        </svg>
                                    </summary>
                                    <div id="category-checkboxes" class="space-y-2 mt-3">
                                        <!-- Checkboxes will be dynamically added here -->
                                    </div>
                                    <div class="flex flex-col sm:flex-row space-y-2 sm:space-y-0 sm:space-x-2 mt-4">
                                        <button id="select-all-btn" class="flex-1 bg-accent-dark text-white p-2 rounded-md hover:bg-teal-700 transition-colors text-sm">Select All</button>
                                        <button id="deselect-all-btn" class="flex-1 bg-gray-300 text-dark-charcoal p-2 rounded-md hover:bg-gray-400 transition-colors text-sm">Deselect All</button>
                                    </div>
                                </details>
                            </div>
                        </div>
                        <!-- Quick Access Section -->
                        <div class="col-span-1">
                            <div class="quick-access-card">
                                <div class="quick-access-header">
                                    <i class="fas fa-bolt text-accent-dark"></i>
                                    <h6>Quick Access to Common Issues</h6>
                                </div>
                                <div class="quick-access-body" id="common-issues-list">
                                    <!-- Common issues will be dynamically loaded here -->
                                </div>
                            </div>
                        </div>
                    </div>
                `
            },
            'glossary': {
                title: "Glossary",
                intro: "This section provides definitions for common PostgreSQL terms and concepts.",
                issues: [
                  {
        "title": "Indexes",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Indexes are special lookup tables that the database search engine can use to speed up data retrieval. They are created on one or more columns of a table, allowing the database to quickly locate rows without scanning the entire table. While they improve read performance, they add overhead to write operations (INSERT, UPDATE, DELETE) as the index also needs to be maintained.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostgreSQL has continuously improved its indexing capabilities and introduced new index types (e.g., BRIN in 9.5, SP-GiST in 9.2). Performance of existing index types is also regularly optimized.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/indexes.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 11. Indexes</a></p>"
    },
    {
        "title": "B-tree Index",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>B-tree (Balanced Tree) is the most common and default index type in PostgreSQL. It is highly efficient for equality and range queries on ordered data (numbers, strings, dates). It works by storing sorted key values and pointers, allowing for logarithmic time complexity in searches, inserts, and deletes. PostgreSQL's B-tree implementation is based on Lehman & Yao Algorithm and B+-Trees.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>B-tree indexes are a fundamental and highly optimized part of PostgreSQL. While their core structure is stable, performance improvements and optimizations (e.g., better concurrency, space utilization) are ongoing in newer versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/indexes-types.html#INDEX-TYPES-BTREE\" target=\"_blank\" class=\"text-accent-dark hover:underline\">11.3. B-Tree Indexes</a></p>"
    },
    {
        "title": "GiST Index (Generalized Search Tree)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>GiST (Generalized Search Tree) is a general-purpose, balanced tree structure that can be used to implement various specialized indexing schemes. It's particularly useful for indexing complex data types and queries that involve non-standard search operations, such as geometric data, full-text search, and k-nearest neighbor searches. GiST is extensible, allowing users to define custom indexing strategies.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>GiST was introduced in PostgreSQL 8.2 and has been continually enhanced with new operator classes and performance improvements, making it more versatile for various data types and query patterns.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/gist.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 66. GiST Indexes</a></p>"
    },
    {
        "title": "GIN Index (Generalized Inverted Index)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>GIN (Generalized Inverted Index) is designed for indexing composite values where the items to be indexed are of composite values and searching is required for an element that appears within the composite items. It is highly effective for data types that contain multiple discrete values within a single column, such as arrays, JSONB documents, and full-text search lexemes. GIN indexes store a list of locations (postings) for each indexed key.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>GIN indexes are crucial for modern PostgreSQL features like JSONB and full-text search. They were introduced in PostgreSQL 8.2 and have seen significant performance improvements, especially in handling large posting lists and write performance.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/gin.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 65. GIN Indexes</a></p>"
    },
    {
        "title": "Partitioning",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Table partitioning is a technique that divides a large table into smaller, more manageable pieces called partitions. Each partition is a separate table, but they can be queried as if they were a single logical table. Partitioning improves performance for large tables by allowing queries to scan only relevant partitions, simplifies data management (e.g., archiving old data), and can improve vacuuming efficiency.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Declarative partitioning was introduced in PostgreSQL 10, significantly simplifying the process compared to earlier versions that required manual inheritance and trigger-based solutions. Subsequent versions (11, 12, 13, 14, 15) have added more features like default partitions, hash partitioning, and improved pruning.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-partitioning.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.11. Table Partitioning</a></p>"
    },
    {
        "title": "Materialized View",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A materialized view is a database object that contains the results of a query, physically stored on disk. Unlike a regular view, which is a virtual table, a materialized view pre-computes and caches the data, making subsequent queries against it much faster. It needs to be explicitly refreshed to reflect changes in the underlying base tables.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Materialized views were introduced in PostgreSQL 9.3. The `REFRESH MATERIALIZED VIEW CONCURRENTLY` option (introduced in 9.4) allows refreshing without blocking concurrent reads, which was a significant improvement for production environments.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-creatematerializedview.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">CREATE MATERIALIZED VIEW Documentation</a></p>"
    },
    {
        "title": "Triggers",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A trigger is a special kind of function that is automatically executed whenever a specified event occurs in the database. These events can be INSERT, UPDATE, or DELETE operations on a table. Triggers are used to enforce complex business rules, maintain data integrity, audit changes, or perform cascading actions.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Triggers are a long-standing feature in PostgreSQL. The introduction of `FOR EACH ROW` and `FOR EACH STATEMENT` options, as well as support for various trigger languages (e.g., PL/pgSQL), has made them very flexible. Event triggers (introduced in 9.3) allow reacting to DDL commands.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-createtrigger.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">CREATE TRIGGER Documentation</a></p>"
    },
    {
        "title": "Functions (Stored Procedures)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In PostgreSQL, a function (often called a stored procedure in other databases) is a block of code that performs a specific task and can return a value. Functions can be written in various languages (e.g., PL/pgSQL, C, Python, Perl) and are used to encapsulate complex logic, improve code reusability, and enhance security by granting execution privileges without direct table access. PostgreSQL 11 introduced explicit `PROCEDURE` commands for routines that do not return a value and can manage transactions.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostgreSQL 11 introduced `CREATE PROCEDURE` for routines that can manage transactions and do not return a value, distinguishing them from traditional functions. Before 11, `RETURNS void` functions served this purpose. Performance and capabilities of procedural languages like PL/pgSQL are continuously improved.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-createfunction.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">CREATE FUNCTION Documentation</a></p>"
    },
    {
        "title": "Extensions",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL extensions are packages of related SQL objects (functions, data types, operators, indexes, etc.) that can be loaded into a database to extend its functionality. They allow users to add powerful features (e.g., PostGIS for geospatial data, pg_stat_statements for query monitoring) as if they were built-in, simplifying management and distribution of custom features.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The extension mechanism was introduced in PostgreSQL 9.1, making it much easier to package and install additional functionality compared to previous methods. The ecosystem of available extensions has grown significantly since then.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/extend-extensions.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">38.17. Packaging Related Objects into an Extension</a></p>"
    },
    {
        "title": "Autovacuum",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Autovacuum is a background daemon that automatically performs VACUUM and ANALYZE operations on tables. It monitors table activity and, when certain thresholds are met (based on dead tuples or transaction ID wraparound risk), it triggers these maintenance tasks. Autovacuum is crucial for preventing table bloat, reclaiming disk space, updating query planner statistics, and avoiding transaction ID wraparound.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Autovacuum has been present for many versions but has seen continuous improvements in its efficiency, default settings, and configurability (e.g., per-table settings). Modern autovacuum is much more aggressive and effective at keeping databases healthy.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/runtime-config-autovacuum.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">20.10. Automatic Vacuuming</a></p>"
    },
    {
        "title": "Shared Buffers",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Shared buffers is the main memory area used by PostgreSQL to cache data pages (8KB blocks) read from disk. When a query needs data, it first checks shared buffers. If the data is found there (a cache hit), it avoids a slower disk I/O operation. Properly sizing shared buffers is critical for database performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The concept of shared buffers is fundamental. Modern PostgreSQL versions have improved buffer management algorithms. The recommended size for `shared_buffers` has generally increased with available RAM on servers.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-SHARED-BUFFERS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">20.4. Resource Consumption - shared_buffers</a></p>"
    },
    {
        "title": "Work Mem",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>`work_mem` is a GUC parameter that specifies the maximum amount of memory to be used by a query operation (like sorting or hashing) before it starts writing temporary files to disk. Each sorting or hashing operation can use up to this amount of memory. Setting it too low can lead to frequent disk spills, while setting it too high can exhaust system memory if many complex queries run concurrently.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`work_mem` has been a key tuning parameter for a long time. Its impact remains consistent, though the default values might have been adjusted in newer versions to reflect increased typical server memory.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-WORK-MEM\" target=\"_blank\" class=\"text-accent-dark hover:underline\">20.4. Resource Consumption - work_mem</a></p>"
    },
    {
        "title": "Prepared Statements",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A prepared statement is a server-side object that allows a client to execute a SQL statement multiple times with different parameters without re-parsing and re-planning the statement each time. This can improve performance by reducing overhead, especially for frequently executed queries. It also helps prevent SQL injection attacks by separating the query structure from the data.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Prepared statements are a long-standing feature. PostgreSQL 9.3 introduced behavior where the planner might re-parse/re-plan if `search_path` changes. PostgreSQL 12 improved the plan cache heuristic, allowing the planner to choose between a generic plan and a custom plan more intelligently.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-prepare.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">PREPARE Documentation</a></p>"
    },
    {
        "title": "Transaction Isolation Levels",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Transaction isolation levels define how concurrent transactions interact and how visible changes made by one transaction are to others. PostgreSQL supports four standard SQL isolation levels: Read Uncommitted (mapped to Read Committed), Read Committed (default), Repeatable Read, and Serializable. Each level offers different guarantees regarding data consistency and concurrency, with higher levels providing stronger guarantees but potentially lower concurrency.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostgreSQL's implementation of isolation levels is robust and adheres to the SQL standard. The default `Read Committed` provides a good balance of consistency and concurrency for most applications. The `Serializable` isolation level offers the strongest guarantees, preventing all forms of transaction anomalies.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/transaction-iso.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 13. Concurrency Control - Transaction Isolation</a></p>"
    },
    {
        "title": "Advisory Locks",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Advisory locks are a mechanism in PostgreSQL that allows applications to implement cooperative locking. Unlike regular locks, which are enforced by the database system (e.g., row locks, table locks), advisory locks are not automatically enforced by the database and rely on applications to respect them. They are useful for coordinating access to resources that are not directly managed by PostgreSQL, such as external files or application-level resources.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Advisory locks have been available in PostgreSQL for many versions. They provide a flexible way for applications to manage concurrency beyond standard SQL locking. Functions like `pg_advisory_lock()` and `pg_try_advisory_lock()` are stable.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-ADVISORY-LOCKS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">9.27. Interprocess Communication Functions - Advisory Locks</a></p>"
    },
    {
        "title": "LISTEN/NOTIFY",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `LISTEN` and `NOTIFY` commands provide a simple interprocess communication mechanism within PostgreSQL. A session can `LISTEN` on a named channel, and any other session can `NOTIFY` that channel. All sessions listening on that channel will then receive a notification. This is useful for implementing lightweight event-driven architectures, such as invalidating application caches or triggering background processes.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`LISTEN`/`NOTIFY` has been a core feature for a long time. While simple, it's a stable and effective way for applications to communicate asynchronously through the database.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-listen.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">LISTEN Documentation</a></p>"
    },
    {
        "title": "PL/pgSQL",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PL/pgSQL is a block-structured procedural language provided by PostgreSQL. It allows users to write functions, procedures, and triggers with control structures (loops, conditionals), error handling, and variable declarations, extending the capabilities of SQL. It is the most commonly used procedural language for writing server-side logic in PostgreSQL.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PL/pgSQL has been the default procedural language for many years and is continuously enhanced with new features, better performance, and improved debugging capabilities in each PostgreSQL release.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/plpgsql.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 43. PL/pgSQL - SQL Procedural Language</a></p>"
    },
    {
        "title": "JSONB",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>JSONB (JSON Binary) is a binary storage format for JSON data in PostgreSQL. Unlike the `JSON` data type (which stores the text representation), JSONB parses the JSON input into a decomposed binary format, which makes it much faster for querying and indexing. It supports a rich set of operators and functions for manipulating and querying JSON data, including GIN indexing for efficient searches within documents.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>JSONB was introduced in PostgreSQL 9.4 and quickly became the preferred way to store JSON data due to its performance benefits over the `JSON` type (introduced in 9.2). PostgreSQL 12 added support for SQL/JSON standard and JSONPath queries, significantly enhancing its capabilities.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-json.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.14. JSON Types</a></p>"
    },
    {
        "title": "MVCC (Multi-Version Concurrency Control)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>MVCC is the core mechanism PostgreSQL uses to handle concurrency without traditional read locks. When data is updated or deleted, PostgreSQL creates a new version of the row (a new tuple) rather than overwriting the old one. Each transaction gets a \"snapshot\" of the database, ensuring it sees a consistent state, unaware of changes made by concurrent transactions that haven't yet committed.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The fundamental principles of MVCC have been stable for many major versions. However, related mechanisms like VACUUM and HOT updates have seen significant improvements in versions 8.3, 9.0, and beyond, making MVCC more efficient.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/mvcc-intro.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 13. Concurrency Control</a></p>"
    },
    {
        "title": "FSM (Free Space Map)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The Free Space Map is a data structure that tracks pages in a table's heap file with available free space for new tuples. When you perform an INSERT, PostgreSQL consults the FSM to quickly find a page that can accommodate the new row, avoiding a costly sequential scan of the table. It is crucial for efficient insert performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The management of FSM has been largely automated and improved since version 8.4. Before that, it required more manual tuning. Modern autovacuum processes are responsible for keeping the FSM up-to-date.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-fsm.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">19.4.4. Free Space Map</a></p>"
    },
    {
        "title": "CTID (Tuple Identifier)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A CTID is a system column present in every PostgreSQL table that uniquely identifies the physical location of a row (tuple) within its table. It consists of a pair of numbers: the block (or page) number and the item's index within that block, for example, <code>(0,42)</code>. While it provides the fastest possible access to a row, it should not be used as a long-term identifier because it can change after a VACUUM FULL or an UPDATE.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The concept and format of the CTID are fundamental and have not changed across PostgreSQL versions. It remains a core part of the storage architecture.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-system-columns.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.5. System Columns</a></p>"
    },
    {
        "title": "GUC (Grand Unified Configuration)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>GUC refers to the entire system of runtime configuration parameters in PostgreSQL, managed primarily through the <code>postgresql.conf</code> file. These parameters control various aspects of the database's behavior, from memory allocation (e.g., <code>shared_buffers</code>) to logging and query planning. Many can be changed on-the-fly with <code>ALTER SYSTEM</code> or at the session level.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>New GUCs are added with almost every major release, and some defaults are adjusted to reflect modern hardware capabilities. For example, <code>wal_keep_segments</code> was replaced by <code>wal_keep_size</code> in version 13.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/runtime-config.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 20. Server Configuration</a></p>"
    },
    {
        "title": "WAL (Write-Ahead Log)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The Write-Ahead Log is the mechanism that ensures data durability and crash safety in PostgreSQL. Before any changes are written to the main data files (the heap), they are first recorded in the WAL. In the event of a server crash, PostgreSQL replays the WAL from the last checkpoint to restore the database to a consistent state, guaranteeing that no committed transactions are lost.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>WAL is a core feature. Major enhancements have been made over time, including performance improvements, new GUCs for tuning (like <code>max_wal_size</code>), and forming the basis for streaming replication (since 9.0) and logical replication (since 10).</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/wal.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 30. Write-Ahead Logging (WAL)</a></p>"
    },
    {
        "title": "HOT (Heap-Only Tuple) Update",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A HOT update is a highly efficient type of row update that can occur when no indexed columns are modified. It creates the new version of the tuple on the same page as the old one, and a forwarding pointer is set up. This avoids the overhead of creating new entries in every index on the table, significantly improving update performance and reducing index bloat.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>HOT updates were introduced in PostgreSQL 8.3 and have been a key performance feature since. The effectiveness of HOT depends on having sufficient free space on the page, which is controlled by the table's <code>fillfactor</code> storage parameter.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-hot.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">70.5. Heap-Only Tuples (HOT)</a></p>"
    },
    {
        "title": "TOAST (The Oversized-Attribute Storage Technique)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>TOAST is PostgreSQL's mechanism for storing large field values (like <code>text</code>, <code>jsonb</code>, or large <code>varchar</code> fields) that don't fit within a standard 8KB data page. It automatically compresses and/or breaks the large value into smaller chunks, which are stored in a separate \"TOAST table.\" This keeps the main table lean and fast to scan.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>TOAST is a fundamental storage feature. While its core mechanism is stable, compression algorithms and strategies have been refined in newer versions, offering better performance and storage efficiency.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-toast.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">70.2. TOAST</a></p>"
    },
    {
        "title": "VACUUM",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>VACUUM is a critical maintenance process in PostgreSQL that reclaims storage occupied by dead tuples (old row versions left behind by UPDATEs or DELETEs). It also updates the Free Space Map and table statistics used by the query planner. Regular vacuuming is essential to prevent table bloat and ensure optimal query performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Autovacuum, which automates this process, has become much more aggressive and efficient in modern versions (9.6+), reducing the need for manual intervention. VACUUM FULL, which rewrites the entire table and locks it, should be used sparingly.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-vacuum.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">VACUUM Command Documentation</a></p>"
    },
    {
        "title": "ANALYZE",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The ANALYZE command collects statistics about the contents of tables in the database, such as data distribution and the number of distinct values in each column. The query planner then uses these statistics to generate the most efficient execution plans for queries. It can be run manually or is typically handled automatically by the autovacuum daemon.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The quality and types of statistics collected have improved over versions. PostgreSQL 10 introduced extended statistics, allowing for the collection of more complex, multi-column statistics to improve planning for correlated columns.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-analyze.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">ANALYZE Command Documentation</a></p>"
    },
    {
        "title": "EXPLAIN",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>EXPLAIN is a powerful diagnostic tool that shows the execution plan generated by the PostgreSQL query planner for a given SQL statement. Using <code>EXPLAIN ANALYZE</code> not only shows the plan but also executes the query and displays the actual execution times and row counts, which is invaluable for identifying performance bottlenecks like slow joins or table scans.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The output of EXPLAIN has become more detailed and informative with each major release. For instance, buffer usage, WAL records, and JIT (Just-In-Time compilation) details have been added in recent versions (10, 11, 12).</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-explain.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">EXPLAIN Command Documentation</a></p>"
    },
    {
        "title": "Heap",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The term \"heap\" or \"table heap\" refers to the main file(s) on disk where the actual data for a table is stored. Each table corresponds to a heap file that is organized into a series of fixed-size blocks or pages (typically 8KB). All row versions (tuples) reside in the heap.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The fundamental heap structure is core to PostgreSQL. Performance enhancements like HOT updates directly optimize operations within the heap pages. The physical layout is stable across versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-file-layout.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">70.1. Database File Layout</a></p>"
    },
    {
        "title": "Tuple",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In PostgreSQL's internal terminology, a \"tuple\" is the equivalent of a row in a table. Each tuple is a single row version stored within a page of the table's heap file. Due to MVCC, a logical row can have multiple physical tuples (versions) representing its state at different points in time.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This is a fundamental architectural concept and has not changed. Understanding the distinction between a logical row and a physical tuple is key to understanding MVCC and VACUUM.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-page-layout.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">70.6. Page-Level Internals</a></p>"
    },
    {
        "title": "Page",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A page (or block) is the basic unit of storage and I/O in PostgreSQL, with a default size of 8KB. All table and index data is stored as an array of pages. When PostgreSQL needs to read or write data, it does so one page at a time, loading it into the shared_buffers cache.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The default page size is fixed at compile time and has remained 8KB for many years. The internal layout of pages is highly stable, forming the foundation of PostgreSQL's storage layer.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-page-layout.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">70.6. Page-Level Internals</a></p>"
    },
    {
        "title": "Transaction ID (XID)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A Transaction ID (XID) is a 32-bit unsigned integer assigned to every transaction in PostgreSQL. It is used by the MVCC system to determine which tuples are visible to which transactions. The finite nature of XIDs leads to the \"transaction wraparound\" problem, which VACUUM is responsible for preventing.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The 32-bit XID is fundamental. PostgreSQL 13 introduced improvements to how VACUUM handles XID wraparound in partitioned tables, and monitoring for wraparound issues has been consistently improved in each release.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/routine-vacuuming.html#VACUUM-FOR-WRAPAROUND\" target=\"_blank\" class=\"text-accent-dark hover:underline\">25.1.5. Preventing Transaction ID Wraparound Failures</a></p>"
    },
    {
        "title": "Checkpoint",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A checkpoint is a point in the WAL sequence at which all data files have been updated to reflect the information in the log. It is a crucial process that flushes all dirty data pages from shared buffers to disk, ensuring durability and creating a known-good point from which crash recovery can begin. Checkpoints are triggered automatically based on time or the amount of WAL generated.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Checkpoint tuning has seen major improvements. Modern versions (9.5+) have a much better default configuration (e.g., <code>max_wal_size</code>) that spreads checkpoint I/O over time, reducing performance spikes associated with older, more frequent checkpoints.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/wal-configuration.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">30.5. Checkpoints</a></p>"
    },
    {
        "title": "pg_hba.conf",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The <code>pg_hba.conf</code> (host-based authentication) file is the primary configuration file that controls client authentication. It contains a set of records, each specifying a connection type, database, user, client address, and the authentication method to be used for that connection (e.g., <code>md5</code>, <code>scram-sha-256</code>, <code>peer</code>). The server reads this file at startup and on reload.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The <code>scram-sha-256</code> method was introduced in version 10 as a more secure alternative to <code>md5</code>. The file's syntax and importance have remained consistent across versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/auth-pg-hba-conf.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">21.1. The pg_hba.conf File</a></p>"
    },
    {
        "title": "postgresql.conf",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>This is the main configuration file for the PostgreSQL server, containing hundreds of GUC parameters that control its behavior. It manages settings for memory, connections, logging, replication, query planning, and more. Changes often require a server reload or restart to take effect.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This file is always present, but new parameters are added, and some are deprecated or renamed with each major version. Since version 9.4, <code>ALTER SYSTEM</code> provides a SQL-based way to change parameters in this file.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/runtime-config.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 20. Server Configuration</a></p>"
    },
    {
        "title": "Role",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In PostgreSQL, a \"role\" is an entity that can own database objects and have database privileges. Depending on how it's configured, a role can be considered a user, a group, or both. This unified concept simplifies permission management, allowing roles to inherit privileges from other roles they are members of.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The concept of roles unifying users and groups was introduced in PostgreSQL 8.1. Since then, the system has been enhanced with features like default privileges and predefined roles for monitoring and administration.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/database-roles.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 22. Database Roles</a></p>"
    },
    {
        "title": "Schema",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A schema is a namespace within a database that contains named objects like tables, views, functions, and indexes. It allows you to group objects for organizational purposes and to avoid naming conflicts. Every database has a default <code>public</code> schema, but creating separate schemas is a best practice for managing complex applications.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Schemas are a fundamental, stable feature of PostgreSQL, conforming to the SQL standard. They are essential for multi-tenant architectures and logical application separation.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-schemas.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.9. Schemas</a></p>"
    },
    {
        "title": "Tablespace",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A tablespace is a location on the file system where PostgreSQL stores the data files for database objects. It allows a database administrator to map logical objects (like a table or index) to different physical storage devices. This is useful for managing storage, such as placing a large, heavily-used index on a faster SSD while the main table resides on cheaper magnetic storage.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Tablespaces have been a core feature for many versions. Their primary use case remains the same: managing physical data layout across different storage tiers.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/manage-ag-tablespaces.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 23. Tablespaces</a></p>"
    },
    {
        "title": "Streaming Replication",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Streaming replication is a method of creating a hot standby (read-only replica) of a primary PostgreSQL server. The primary server streams its WAL records over the network to the standby, which applies them in near-real-time. This provides high availability (for fast failover) and read scaling (by offloading read queries to the standby).</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Introduced in version 9.0, streaming replication has been continuously improved. Synchronous replication (9.1), cascading replication (9.2), and replication slots (9.4) have made it more robust and flexible.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/warm-standby.html#STREAMING-REPLICATION\" target=\"_blank\" class=\"text-accent-dark hover:underline\">27.2.5. Streaming Replication</a></p>"
    },
    {
        "title": "Logical Replication",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Logical replication is a method of replicating data objects and their changes based on their replication identity (usually a primary key), rather than their physical block location. This allows for more flexible replication, such as replicating between different major PostgreSQL versions, replicating only a subset of tables, or consolidating multiple databases into one.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Logical replication was introduced as a core feature in PostgreSQL 10, built upon the logical decoding infrastructure from version 9.4. It has seen significant enhancements in subsequent versions, including the ability to replicate TRUNCATE and partitioned table changes.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/logical-replication.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 31. Logical Replication</a></p>"
    },
    {
        "title": "Foreign Data Wrapper (FDW)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A Foreign Data Wrapper is an extension that allows PostgreSQL to access and manipulate data stored in external data sources, presenting it as if it were a local table (a \"foreign table\"). There are FDWs available for connecting to other PostgreSQL databases (<code>postgres_fdw</code>), as well as other systems like MySQL, Oracle, files, and NoSQL databases.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The SQL/MED (Management of External Data) standard was implemented starting in PostgreSQL 9.1. The <code>postgres_fdw</code> has seen major improvements, including predicate pushdown and, in recent versions (14+), asynchronous execution, making cross-database queries much more performant.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/postgres-fdw.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">postgres_fdw Documentation</a></p>"
    },
    {
        "title": "Common Table Expression (CTE)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A Common Table Expression, defined using the <code>WITH</code> clause, allows you to create a temporary, named result set that exists only for the duration of a single query. CTEs are useful for breaking down complex queries into simpler, more readable logical steps. They can be referenced multiple times within the main query.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>CTEs were introduced in PostgreSQL 8.4. Prior to version 12, CTEs acted as an \"optimization fence,\" meaning they were always materialized (executed and stored). Since version 12, the planner can choose to inline the CTE logic into the main query, often leading to better performance.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/queries-with.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">7.8. WITH Queries (Common Table Expressions)</a></p>"
    },
    {
        "title": "Window Function",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A window function performs a calculation across a set of table rows that are somehow related to the current row. Unlike regular aggregate functions, which group rows into a single output row, window functions return a value for each row based on a \"window\" of related rows defined by the <code>OVER()</code> clause. They are powerful for tasks like running totals, ranking, and moving averages.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Window functions were introduced in PostgreSQL 8.4 and have been progressively enhanced. Newer versions have added more functions and improved the performance of window function execution.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/tutorial-window.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">3.5. Window Functions</a></p>"
    },
    {
        "title": "Numeric Data Types",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL offers a rich set of numeric data types for storing various kinds of numbers, including integers (<code>smallint</code>, <code>integer</code>, <code>bigint</code>), floating-point numbers (<code>real</code>, <code>double precision</code>), and arbitrary precision numbers (<code>numeric</code>/<code>decimal</code>). Choosing the appropriate type is crucial for storage efficiency and precision.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>These fundamental data types have been stable across many versions. Performance optimizations for arithmetic operations are continuously made, but their core behavior remains consistent.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-numeric.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.1. Numeric Types</a></p>"
    },
    {
        "title": "Character Data Types",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL provides several character data types for storing text strings: <code>char(n)</code> for fixed-length strings (padded with spaces), <code>varchar(n)</code> for variable-length strings with an optional maximum length, and <code>text</code> for variable-length strings with no explicit length limit. <code>text</code> is generally preferred for its flexibility.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>These types are fundamental. Performance for text manipulation and storage has seen continuous improvements, especially with better handling of encoding and collation.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-character.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.3. Character Types</a></p>"
    },
    {
        "title": "Date/Time Data Types",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL offers comprehensive date and time data types, including <code>date</code>, <code>time</code>, <code>timestamp</code> (with or without time zone), and <code>interval</code>. The `timestamp with time zone` type is highly recommended for applications needing to store time-zone-aware data, as it converts values to UTC internally.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Date/time handling has been robust for many versions. Improvements include better handling of daylight saving time transitions and performance for complex date/time arithmetic.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-datetime.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.5. Date/Time Types</a></p>"
    },
    {
        "title": "Boolean Data Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The <code>boolean</code> data type stores truth values: <code>TRUE</code>, <code>FALSE</code>, or <code>NULL</code>. It is highly efficient, using only one byte of storage. PostgreSQL is flexible with input, accepting various literal values like 't', 'f', 'yes', 'no', '1', '0'.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The boolean type is a fundamental and stable feature, consistent across all PostgreSQL versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-boolean.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.6. Boolean Type</a></p>"
    },
    {
        "title": "Array Data Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL allows columns to be defined as variable-length, multi-dimensional arrays of any built-in or user-defined type. This enables storing collections of values within a single column, which can simplify schema design for certain use cases (e.g., tags, phone numbers). Array operators and functions facilitate querying and manipulation.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Array types have been supported since PostgreSQL 8.2. Newer versions have added more array functions and improved performance for array operations, especially when combined with GIN indexes.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/arrays.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.15. Arrays</a></p>"
    },
    {
        "title": "Composite Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A composite type (or row type) is a user-defined data type that groups multiple fields into a single structure, similar to a `struct` in C or a `record` in Pascal. They can be used as column types in tables, as arguments to functions, or as return types from functions, promoting logical grouping and code reusability.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Composite types have been a part of PostgreSQL for a long time, reflecting its advanced type system. They are a stable feature used for modeling complex data structures directly within the database.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/rowtypes.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.16. Composite Types</a></p>"
    },
    {
        "title": "Range Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A range type represents a range of values of a specific data type (e.g., `int4range` for integers, `tsrange` for timestamps). They are useful for representing time periods, numerical intervals, or other continuous ranges. PostgreSQL provides specialized operators for range types to check for overlaps, containment, and adjacency.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Range types were introduced in PostgreSQL 9.2, significantly enhancing its ability to handle interval data. New range types and operators have been added in subsequent versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/rangetypes.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.17. Range Types</a></p>"
    },
    {
        "title": "Enum Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An enum (enumerated) type is a user-defined data type that comprises a static, ordered list of values. It restricts a column's values to only those specified in the enum definition, ensuring data integrity and readability. Enums are useful for columns with a limited, predefined set of choices (e.g., 'pending', 'approved', 'rejected').</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Enum types were introduced in PostgreSQL 8.3. They provide a strong type-safe alternative to using `TEXT` or `CHAR` with `CHECK` constraints for predefined lists.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-enum.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.7. Enumerated Types</a></p>"
    },
    {
        "title": "Domain",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A domain is a user-defined data type based on an existing base type, but with optional constraints (like `NOT NULL`, `CHECK` clauses) and a default value. Domains allow for centralizing data validation rules, ensuring consistency across multiple tables that use the same logical type. For example, a `positive_integer` domain could ensure a number is always greater than zero.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Domains are a standard SQL feature and have been available in PostgreSQL for many versions. They provide a way to enforce data integrity beyond basic data types.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/domains.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.18. Domains</a></p>"
    },
    {
        "title": "Arithmetic Operators",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL supports standard arithmetic operators for numeric data types, including addition (+), subtraction (-), multiplication (*), division (/), modulus (%), and exponentiation (^). These operators are used to perform mathematical calculations within SQL queries.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>These operators are fundamental and have been consistently available across all PostgreSQL versions. Performance of these operations is highly optimized.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/functions-math.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">9.5. Mathematical Functions and Operators</a></p>"
    },
    {
        "title": "Comparison Operators",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Comparison operators are used in SQL `WHERE` clauses and `JOIN` conditions to compare two expressions. Common operators include equals (=), not equals (<> or !=), less than (<), greater than (>), less than or equals (<=), and greater than or equals (>=). They return a boolean value (TRUE, FALSE, or NULL).</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Standard comparison operators are a core part of SQL and have been consistently supported across all PostgreSQL versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/functions-comparison.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">9.2. Comparison Operators</a></p>"
    },
    {
        "title": "Logical Operators",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Logical operators combine or modify boolean expressions in SQL queries. The primary logical operators are `AND`, `OR`, and `NOT`. `AND` returns true if both expressions are true; `OR` returns true if at least one expression is true; `NOT` negates the boolean value of an expression.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>These are fundamental SQL operators and have been consistently available across all PostgreSQL versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-expressions.html#SQL-SYNTAX-OPERATORS-LOGICAL\" target=\"_blank\" class=\"text-accent-dark hover:underline\">4.2. Logical Operators</a></p>"
    },
    {
        "title": "String Operators",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL provides various operators for manipulating and comparing string (text) data. Key operators include concatenation (<code>||</code>), pattern matching (<code>LIKE</code>, <code>ILIKE</code>, <code>SIMILAR TO</code>, and regular expression operators like <code>~</code>, <code>~*</code>), and comparison operators for string ordering.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>String functions and operators have been continuously enhanced. Regular expression support has improved over versions, and performance for string operations is a constant focus.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/functions-string.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">9.4. String Functions and Operators</a></p>"
    },
    {
        "title": "JSONB Operators",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL's `JSONB` data type comes with a rich set of specialized operators for querying and manipulating JSON documents. These include operators for checking key/value existence (<code>?</code>, <code>?|</code>, <code>?&</code>), containment (<code>@></code>), and path-based queries (<code>@?</code>, <code>@@</code>).</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>JSONB and its operators were introduced in PostgreSQL 9.4. PostgreSQL 12 significantly expanded JSONB capabilities with SQL/JSON path language support and new operators like `@@` and `@?`.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/functions-json.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">9.16. JSON Functions and Operators</a></p>"
    },
    {
        "title": "Array Operators",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL provides a set of operators specifically designed for array data types. These include operators for checking if an array contains certain elements (<code>@></code>), if one array is contained within another (<code><@</code>), or if two arrays overlap (<code>&&</code>). These operators are often used with GIN or GiST indexes for efficient array searching.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Array operators have been available since array types were introduced. Performance with indexes has improved over time, making array queries more efficient.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/functions-array.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">9.18. Array Functions and Operators</a></p>"
    },
    {
        "title": "pg_class",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_class</code> is a system catalog table that stores information about tables, indexes, sequences, views, materialized views, and other relation-like objects in a PostgreSQL database. It contains metadata such as the object's name, OID, owner, access method, and physical storage details.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This is a core system catalog. Its structure evolves with new features (e.g., new columns for partitioning or JIT), but it remains central to PostgreSQL's internal object management.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/catalog-pg-class.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">52.8. pg_class</a></p>"
    },
    {
        "title": "pg_attribute",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_attribute</code> is a system catalog table that stores information about the columns (attributes) of tables, indexes, and other relation-like objects. It contains details like column name, data type, length, nullability, and default values. It is often joined with `pg_class` to get a complete picture of a table's structure.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>A fundamental system catalog, its structure is stable, though new attributes might be added to support new column-level features.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/catalog-pg-attribute.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">52.5. pg_attribute</a></p>"
    },
    {
        "title": "pg_index",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_index</code> is a system catalog table that stores information specific to indexes. It links an index to its indexed table and contains details about the index's columns, unique constraints, primary key status, and other index-specific properties. It's used by the query planner to determine available indexes.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This catalog is essential for index management. Its structure adapts to new index features (e.g., expression indexes, partial indexes), but its core purpose is consistent.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/catalog-pg-index.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">52.19. pg_index</a></p>"
    },
    {
        "title": "pg_settings",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_settings</code> is a system view that provides information about the current runtime configuration parameters of the PostgreSQL server. It lists all GUCs, their current values, default values, whether they can be changed, and their context (e.g., `postmaster`, `superuser`, `user`). It's invaluable for monitoring and tuning the database.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This view is regularly updated with each new PostgreSQL version to reflect new or deprecated GUCs. It's a key tool for administrators.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/view-pg-settings.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">52.30. pg_settings</a></p>"
    },
    {
        "title": "pg_stat_activity",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_stat_activity</code> is a system view that provides real-time information about all active backend processes (client connections) connected to the current database. It shows details like the process ID, user, database, client address, current query, query start time, and wait events. It is essential for monitoring database activity and troubleshooting performance issues.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This view is crucial for monitoring. New columns (e.g., `wait_event_type`, `backend_type`) have been added in recent versions (9.6, 10, 14) to provide more granular insights into what processes are doing.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW\" target=\"_blank\" class=\"text-accent-dark hover:underline\">28.2. The Statistics Collector - pg_stat_activity</a></p>"
    },
    {
        "title": "pg_locks",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_locks</code> is a system view that provides real-time information about all active locks held by sessions and transactions in the database. It shows details like the lock type (e.g., `Relation`, `Tuple`, `Transactionid`), the object being locked, the mode of the lock, and whether it's granted or waiting. It's essential for diagnosing blocking and deadlocks.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This view is critical for concurrency troubleshooting. Its structure has been stable, though new lock types might be added as new features are introduced.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/view-pg-locks.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">52.22. pg_locks</a></p>"
    },
    {
        "title": "Table Inheritance",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL supports table inheritance, where a table can inherit columns from one or more other tables. Queries against the parent table will implicitly include rows from its children tables. While it can be useful for certain modeling scenarios, declarative partitioning (introduced in PostgreSQL 10) is generally preferred for managing large datasets that were previously handled with inheritance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Table inheritance has been a feature for a long time. While still supported, its use for large data management has largely been superseded by declarative partitioning in PostgreSQL 10+.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-inherit.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.10. Inheritance</a></p>"
    },
    {
        "title": "Rules (Query Rewrite)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The PostgreSQL rule system allows you to define rewrite rules that modify or replace queries before they are executed. Rules operate at a very low level, transforming the query tree. While powerful for certain advanced use cases (like implementing updatable views), they are often complex and can be difficult to debug. Triggers are generally a simpler and more common alternative for most data modification logic.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The rule system is a long-standing feature, but its use has become less common for general application logic with the introduction of more robust features like updatable views (without rules) and `ON CONFLICT` clauses. It remains a powerful, but niche, tool.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/rules.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 42. The Rule System</a></p>"
    },
    {
        "title": "Row Level Security (RLS)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Row Level Security (RLS) allows database administrators to define policies that restrict which rows a user can see or modify in a table, based on the user's role, context, or data values. This provides a fine-grained access control mechanism, ensuring that users only interact with data relevant and authorized for them, without needing to modify application queries.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>RLS was introduced in PostgreSQL 9.5. It has been enhanced in subsequent versions with features like `WITH CHECK` policies and better integration with `SECURITY INVOKER` functions, making it more flexible and robust for multi-tenant applications.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-rowsecurity.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.8. Row Security Policies</a></p>"
    },
    {
        "title": "UPSERT (ON CONFLICT)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>UPSERT, implemented with the `INSERT ... ON CONFLICT` clause, provides a way to atomically insert a new row into a table if it doesn't already exist, or update an existing row if a conflict (e.g., a duplicate primary key or unique constraint) occurs. This avoids race conditions that can arise from separate `SELECT` and `INSERT/UPDATE` statements.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The `ON CONFLICT` clause was introduced in PostgreSQL 9.5, providing a highly anticipated and robust UPSERT capability. It significantly simplified common application patterns that previously required complex procedural code or external locking.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-insert.html#SQL-ON-CONFLICT\" target=\"_blank\" class=\"text-accent-dark hover:underline\">INSERT ... ON CONFLICT Documentation</a></p>"
    },
    {
        "title": "BRIN Index (Block Range Index)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>BRIN (Block Range Index) is a type of index designed for very large tables where data is naturally ordered (e.g., by time or ID). Instead of indexing individual rows, BRIN stores summary information (like min/max values) for ranges of physical data blocks. This makes BRIN indexes very small and fast to scan, especially when queries filter on columns that are physically correlated with their storage order.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>BRIN indexes were introduced in PostgreSQL 9.5. They are particularly effective for time-series data or large tables where data is inserted in a naturally sorted order, complementing partitioning strategies.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/brin-intro.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">67.1. BRIN Indexes</a></p>"
    },
    {
        "title": "SP-GiST Index (Space-Partitioned Generalized Search Tree)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>SP-GiST (Space-Partitioned Generalized Search Tree) is an index type that supports a wide range of non-balanced data structures, such as quadtrees, k-d trees, and radix trees. It is particularly useful for indexing data where the search space can be naturally partitioned, like geometric data, phone numbers, or IP addresses, offering efficient searching for these specialized data types.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>SP-GiST was introduced in PostgreSQL 9.2. It provides an extensible framework for indexing data types that don't fit well with traditional B-tree or GiST indexes, expanding PostgreSQL's indexing capabilities.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/spgist.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 68. SP-GiST Indexes</a></p>"
    },
    {
        "title": "Bloom Filter Index",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A Bloom filter is a space-efficient probabilistic data structure used to test whether an element is a member of a set. In PostgreSQL, the `bloom` extension provides Bloom filter indexes, which are useful for accelerating queries with many `AND` conditions on multiple columns. While they can produce false positives (indicating an element *might* be in the set when it's not), they never produce false negatives.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The `bloom` extension is a community-contributed module, not part of core PostgreSQL. Its availability and features depend on the extension's version, typically supporting recent PostgreSQL releases.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/bloom.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.10. bloom (Bloom Filter Index)</a></p>"
    },
    {
        "title": "JIT (Just-In-Time Compilation)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>JIT (Just-In-Time) compilation is a technique where parts of a query's execution plan are compiled into machine code at runtime, rather than being interpreted. This can significantly speed up computationally intensive operations within a query, such as expression evaluation, tuple deforming, and aggregation, especially for complex analytical queries.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>JIT compilation was introduced in PostgreSQL 11, leveraging LLVM. It has been further optimized in subsequent versions (12, 13, 14, 15) to cover more types of operations and improve its effectiveness for various workloads.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/jit-reason.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">33. Just-in-Time Compilation (JIT)</a></p>"
    },
    {
        "title": "Parallel Query",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Parallel query allows PostgreSQL to utilize multiple CPU cores to execute parts of a single query concurrently. This can significantly speed up operations like sequential scans, large joins, and aggregations on large datasets by dividing the work among multiple worker processes. The query planner automatically decides when and how to parallelize a query.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Parallel query capabilities were introduced in PostgreSQL 9.6 (for sequential scans and aggregates). Subsequent versions (10, 11, 12, 13, 14, 15) have expanded parallelization to cover more types of query operations, including parallel B-tree index scans, hash joins, and more complex plans.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/parallel-query.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">16.2. Parallel Queries</a></p>"
    },
    {
        "title": "psql",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>psql</code> is the command-line terminal client for PostgreSQL. It allows users to interact with the database by typing SQL queries, executing meta-commands (like <code>\\dt</code> to list tables), and running scripts. It's an essential tool for database administration, development, and debugging.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>psql</code> is a core utility that ships with PostgreSQL and is continuously improved with new meta-commands, output formatting options, and usability enhancements in each release.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/app-psql.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">psql Documentation</a></p>"
    },
    {
        "title": "pg_dumpall",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_dumpall</code> is a utility that dumps all PostgreSQL databases of a cluster into a single script file. It includes global objects like roles and tablespaces, which are not included in individual `pg_dump` outputs. It's commonly used for full cluster backups or migrating an entire PostgreSQL instance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>pg_dumpall</code> is a long-standing utility. Its functionality is updated with each major PostgreSQL version to ensure compatibility with new features and global objects.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/app-pgdumpall.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_dumpall Documentation</a></p>"
    },
    {
        "title": "pg_upgrade",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_upgrade</code> is a utility that allows in-place upgrades of a PostgreSQL database cluster to a newer major version without requiring a full dump and restore. It works by rewriting system catalog tables and linking to the old data files, significantly reducing downtime for major version upgrades.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>pg_upgrade</code> was introduced in PostgreSQL 9.0 and has been continuously improved to support new major version upgrades and handle various migration scenarios, making upgrades much smoother.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/pgupgrade.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_upgrade Documentation</a></p>"
    },
    {
        "title": "pg_repack",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_repack</code> is an extension that allows you to reorganize tables and indexes in PostgreSQL databases with minimal locks, unlike `VACUUM FULL` or `REINDEX`. It removes bloat from tables and indexes online, rebuilding them in a new, compact copy and then atomically swapping the old and new versions. This is crucial for maintaining performance in heavily updated tables.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>pg_repack</code> is a popular community extension. Its functionality relies on internal PostgreSQL features and is updated to support new major versions, providing a vital online maintenance tool.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://pgxn.org/dist/pg_repack/\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_repack PGXN Page</a></p>"
    },
    {
        "title": "pg_checksums",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_checksums</code> is a utility used to enable, disable, or verify data checksums on a PostgreSQL data directory. Data checksums provide an additional layer of data integrity protection by detecting corruption that might occur due to hardware failures or file system issues. They are typically enabled during `initdb`.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Data checksums were introduced as an optional feature in PostgreSQL 9.3 and became verifiable with `pg_checksums` in PostgreSQL 12. Enabling them is a recommended best practice for data integrity.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/app-pgchecksums.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_checksums Documentation</a></p>"
    },
    {
        "title": "Cost-Based Optimizer",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL uses a cost-based optimizer (CBO) to determine the most efficient execution plan for a given SQL query. The CBO estimates the cost (in terms of CPU, I/O, and network usage) of various possible execution plans based on table statistics, available indexes, and configuration parameters. It then chooses the plan with the lowest estimated cost.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The CBO is continually refined in every PostgreSQL release. Improvements include better cost models, new optimization techniques (e.g., JIT, parallel query), and enhanced statistics collection, leading to more intelligent plan choices.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/planner-optimizer.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">16.1. Overview of the Optimizer</a></p>"
    },
    {
        "title": "Execution Plan",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An execution plan is the sequence of operations that the PostgreSQL database system will perform to execute a SQL query. It describes how tables will be accessed (e.g., sequential scan, index scan), how data will be joined (e.g., hash join, nested loop join), and how results will be aggregated or sorted. The `EXPLAIN` command is used to view these plans.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The complexity and detail of execution plans have grown with PostgreSQL's capabilities (e.g., parallel query nodes, JIT information). The planner's ability to generate optimal plans improves with each version.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/using-explain.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">16.4. Using EXPLAIN</a></p>"
    },
    {
        "title": "Planner",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The planner (or optimizer) is the component of PostgreSQL that takes a parsed SQL query and generates an optimal execution plan. It considers various factors like table statistics, available indexes, and resource settings to estimate the cost of different execution strategies and selects the cheapest one.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The planner is a highly active area of development. Each PostgreSQL version introduces improvements to its heuristics, cost models, and ability to leverage new features like JIT and parallel queries for better plan generation.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/planner-optimizer.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">16.1. Overview of the Optimizer</a></p>"
    },
    {
        "title": "Executor",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The executor is the component of PostgreSQL that takes the execution plan generated by the planner and actually runs it. It retrieves data from tables, performs joins, filters, sorts, and aggregations as specified in the plan, and returns the final result set to the client.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The executor's efficiency is continuously improved. Features like JIT compilation directly optimize the execution phase, making data processing faster.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/overview.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 1. A Brief History of PostgreSQL</a></p>"
    },
    {
        "title": "Relation",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In PostgreSQL, the term \"relation\" is used broadly to refer to any object that can store data and has a name in the system catalogs. This includes tables, indexes, sequences, views, and materialized views. It's a more general term than \"table\" and is used internally to manage various database objects.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This is a fundamental internal concept that remains consistent across versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/glossary.html#GLOSSARY-RELATION\" target=\"_blank\" class=\"text-accent-dark hover:underline\">PostgreSQL Glossary - Relation</a></p>"
    },
    {
        "title": "OID (Object Identifier)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An OID (Object Identifier) is a system-wide unique 32-bit integer assigned to every object created in a PostgreSQL database cluster (e.g., tables, functions, data types). While OIDs are generally hidden from users, they are used internally by PostgreSQL to identify objects. For most user-facing applications, primary keys are preferred for identifying rows.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>OIDs are a legacy feature. While still present and used internally, they are no longer the default for new tables (since PostgreSQL 8.1) and are generally discouraged for application use due to potential wraparound issues in very large systems.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-oid.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.19. Object Identifier Types</a></p>"
    },
    {
        "title": "System Columns",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL automatically adds several hidden \"system columns\" to every table. These columns store metadata about each row, such as the `ctid` (tuple identifier), `xmin` (ID of the inserting transaction), `xmax` (ID of the deleting transaction), and `cmin`/`cmax` (command IDs). These are crucial for MVCC and internal operations but are not typically accessed directly by applications.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>System columns are fundamental to PostgreSQL's MVCC architecture and have been stable across versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-system-columns.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.5. System Columns</a></p>"
    },
    {
        "title": "Data Consistency",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Data consistency, as part of the ACID properties (Atomicity, Consistency, Isolation, Durability), ensures that any transaction brings the database from one valid state to another. This means that all data must comply with defined rules, constraints (e.g., primary keys, foreign keys, check constraints), and business logic. If a transaction violates these rules, it is rolled back.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostgreSQL's commitment to data consistency is a cornerstone of its design and has been unwavering across all versions. New features like declarative partitioning and RLS further enhance consistency management.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/mvcc-intro.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 13. Concurrency Control</a></p>"
    },
    {
        "title": "Durability",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Durability, as part of the ACID properties, guarantees that once a transaction has been committed, its changes will persist even in the event of system failures (e.g., power outages, crashes). PostgreSQL achieves durability primarily through its Write-Ahead Log (WAL), ensuring that all changes are recorded to disk before the transaction is considered complete.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Durability is a core strength of PostgreSQL. WAL and checkpointing mechanisms have been continuously optimized to ensure robust data persistence and faster crash recovery.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/wal.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 30. Write-Ahead Logging (WAL)</a></p>"
    },
    {
        "title": "Atomicity",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Atomicity, as part of the ACID properties, ensures that a transaction is treated as a single, indivisible unit of work. Either all of the operations within a transaction are successfully completed and committed to the database, or none of them are. If any part of the transaction fails, the entire transaction is rolled back, leaving the database in its state before the transaction began.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Atomicity is a fundamental guarantee provided by PostgreSQL's transaction management system and has been consistent across all versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/tutorial-transactions.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">3.4. Transactions</a></p>"
    },
    {
        "title": "Isolation",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Isolation, as part of the ACID properties, ensures that concurrent transactions execute independently without interfering with each other. Each transaction sees a consistent snapshot of the database, as if it were the only transaction running. PostgreSQL's Multi-Version Concurrency Control (MVCC) is the primary mechanism for achieving isolation.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostgreSQL's MVCC implementation provides strong isolation guarantees. While the core concept is stable, performance and efficiency of MVCC-related operations (like VACUUM) have seen continuous improvements.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/transaction-iso.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 13. Concurrency Control - Transaction Isolation</a></p>"
    },
    {
        "title": "Concurrency Control",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Concurrency control refers to the mechanisms used by a database management system to manage simultaneous access to data by multiple users or processes. Its goal is to allow concurrent operations while maintaining data consistency and integrity, preventing issues like dirty reads, lost updates, and deadlocks. PostgreSQL primarily uses MVCC for concurrency control.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostgreSQL's MVCC-based concurrency control is a defining feature. Continuous improvements are made to reduce contention, improve locking mechanisms, and enhance the efficiency of background processes like autovacuum that support concurrency.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/mvcc-intro.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 13. Concurrency Control</a></p>"
    },
    {
        "title": "Deadlock",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A deadlock occurs when two or more transactions are waiting indefinitely for each other to release locks. For example, transaction A holds a lock on resource X and waits for a lock on resource Y, while transaction B holds a lock on resource Y and waits for a lock on resource X. PostgreSQL automatically detects deadlocks and aborts one of the transactions (the \"victim\") to resolve the situation, allowing the other to proceed.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Deadlock detection and resolution mechanisms are robust and have been a stable part of PostgreSQL for many versions. Monitoring tools like `pg_locks` help identify potential deadlock scenarios.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/explicit-locking.html#LOCKING-DEADLOCKS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">13.3. Explicit Locking - Deadlocks</a></p>"
    },
    {
        "title": "EXPLAIN ANALYZE",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>EXPLAIN ANALYZE</code> is an extension of the `EXPLAIN` command that not only displays the query execution plan but also actually executes the query. It then shows the real-world performance metrics for each step of the plan, including actual row counts, execution times, and buffer usage. This is an indispensable tool for performance tuning and understanding why a query is slow.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The output of `EXPLAIN ANALYZE` has become increasingly detailed and useful with each PostgreSQL release, incorporating information about JIT compilation, parallel query workers, and more granular timing and buffer statistics.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-explain.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">EXPLAIN Command Documentation</a></p>"
    },
    {
        "title": "Buffer Cache",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The buffer cache, primarily represented by `shared_buffers`, is an area in shared memory where PostgreSQL stores frequently accessed data pages from disk. Its purpose is to reduce disk I/O by serving data directly from memory. A high cache hit ratio indicates efficient use of the buffer cache, leading to better performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The buffer cache is a core component. Its management and efficiency have been continuously optimized across PostgreSQL versions, including improvements in buffer replacement algorithms.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-SHARED-BUFFERS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">20.4. Resource Consumption - shared_buffers</a></p>"
    },
    {
        "title": "WAL Sender/Receiver",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In streaming replication, the WAL sender process runs on the primary server, reading WAL records and sending them to the standby. The WAL receiver process runs on the standby server, receiving WAL records from the primary and writing them to the standby's WAL files. These processes facilitate near-real-time data synchronization between primary and standby servers.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>These processes were introduced with streaming replication in PostgreSQL 9.0 and have been optimized for performance, reliability, and error handling in subsequent versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/warm-standby.html#STREAMING-REPLICATION\" target=\"_blank\" class=\"text-accent-dark hover:underline\">27.2.5. Streaming Replication</a></p>"
    },
    {
        "title": "Replication Slot",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A replication slot is a feature that prevents the primary server from removing WAL segments until they have been consumed by all configured standbys or logical decoding clients. This ensures that standbys do not fall out of sync due to WAL archiving or cleanup on the primary, greatly improving the reliability of replication and logical decoding.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Replication slots were introduced in PostgreSQL 9.4 and are crucial for robust streaming and logical replication setups, preventing data loss due to WAL removal on the primary.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/warm-standby.html#STANDBY-REPLICATION-SLOTS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">27.2.6. Replication Slots</a></p>"
    },
    {
        "title": "PITR (Point-In-Time Recovery)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Point-In-Time Recovery (PITR) is a powerful backup and recovery strategy that allows restoring a PostgreSQL database to any specific point in time (e.g., before an accidental `DELETE` or `DROP`). It combines a full base backup with a continuous archive of WAL segments, enabling recovery to a precise transaction boundary.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PITR has been a core recovery feature for many versions. Improvements include better tools for managing WAL archives and faster recovery processes.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/backup-recovery.html#BACKUP-PITR\" target=\"_blank\" class=\"text-accent-dark hover:underline\">25.3. Continuous Archiving and Point-in-Time Recovery (PITR)</a></p>"
    },
    {
        "title": "VACUUM FREEZE",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>VACUUM FREEZE</code> is a special mode of the `VACUUM` command that marks all tuples in a table as \"frozen,\" meaning they are visible to all past and future transactions. This is done to prevent transaction ID wraparound issues, as frozen tuples no longer consume transaction IDs. Autovacuum automatically performs freezing as needed.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Freezing is a critical part of preventing XID wraparound. The automatic nature of autovacuum has made manual `VACUUM FREEZE` less necessary, but the underlying mechanism is stable.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-vacuum.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">VACUUM Command Documentation</a></p>"
    },
    {
        "title": "TOAST Table",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>When a large field value (e.g., `text` or `bytea`) exceeds a certain threshold, PostgreSQL moves it out of the main table's data page into a separate storage area called a TOAST table. Each main table that might contain TOASTable data has an associated TOAST table. This keeps the main table rows compact and improves scan performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>TOAST tables are a fundamental storage optimization. Their management and efficiency have been consistently improved across versions, including better compression and storage strategies.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/storage-toast.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">70.2. TOAST</a></p>"
    },
    {
        "title": "Fillfactor",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>fillfactor</code> is a storage parameter that specifies how full a table's data pages should be allowed to become. A lower `fillfactor` leaves more free space on pages, which can improve the efficiency of HOT (Heap-Only Tuple) updates and reduce page splits, especially in tables with frequent updates. However, it also means more disk space is used.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>fillfactor</code> has been a tuning parameter for many versions. Its optimal setting depends on the workload (update-heavy vs. insert-heavy) and the effectiveness of HOT updates.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-createtable.html#SQL-CREATETABLE-STORAGE-PARAMETERS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">CREATE TABLE - Storage Parameters - fillfactor</a></p>"
    },
    {
        "title": "Bloat",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Bloat refers to the unused space within database objects (tables and indexes) caused by the accumulation of dead tuples (old row versions) that have not yet been reclaimed by VACUUM. It leads to inefficient storage, increased I/O operations, reduced cache efficiency, and degraded query performance. Regular maintenance (VACUUM, REINDEX, pg_repack) is needed to address bloat.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Bloat is an inherent consequence of PostgreSQL's MVCC. Autovacuum improvements in newer versions have significantly reduced the severity of bloat, but it remains a concept to understand for optimal performance.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/routine-vacuuming.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">25.1. Routine Vacuuming</a></p>"
    },
    {
        "title": "Hot Standby",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A hot standby is a PostgreSQL replica server that can accept read-only queries while continuously applying WAL records from the primary. This provides both high availability (for fast failover) and read scalability (by distributing read workload). It's a key component of PostgreSQL's native replication solutions.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Hot Standby was introduced in PostgreSQL 9.0, allowing read queries on a standby for the first time. Subsequent versions have enhanced its capabilities with synchronous replication, cascading standbys, and replication slots.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/warm-standby.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 27. High Availability, Load Balancing, and Replication</a></p>"
    },
    {
        "title": "Cold Standby",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A cold standby is a backup PostgreSQL server that is not running and does not continuously receive updates from the primary. It typically involves periodically restoring a full backup from the primary. While simpler to set up, it has a higher Recovery Point Objective (RPO) and Recovery Time Objective (RTO) compared to hot or warm standbys, meaning more data loss and longer downtime in case of a primary failure.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>This is a traditional backup strategy that predates streaming replication. While less advanced than hot standbys, it remains a viable option for less critical systems or as a last resort recovery method.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/backup-file.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">25.2. File System Level Backup</a></p>"
    },
    {
        "title": "Logical Decoding",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Logical decoding is a mechanism that extracts changes from PostgreSQL's WAL in a logical, easy-to-understand format (e.g., SQL statements, JSON). It's the foundation for logical replication, change data capture (CDC) tools, and integrating PostgreSQL with external systems like message queues or data warehouses, providing a stream of committed data modifications.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Logical decoding was introduced in PostgreSQL 9.4 and has been steadily improved. It enabled the development of built-in logical replication in PostgreSQL 10 and a rich ecosystem of external CDC tools.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/logical-replication-architecture.html#LOGICAL-REPLICATION-LOGICAL-DECODING\" target=\"_blank\" class=\"text-accent-dark hover:underline\">31.1. Logical Replication Architecture - Logical Decoding</a></p>"
    },
    {
        "title": "Publication",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In PostgreSQL's logical replication, a publication is a set of changes generated from a table or a group of tables on the primary (publisher) server. It defines which DML operations (INSERT, UPDATE, DELETE, TRUNCATE) are to be replicated. A publication is consumed by one or more subscriptions on a subscriber server.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Publications were introduced as part of the built-in logical replication feature in PostgreSQL 10. Their capabilities have been extended in subsequent versions to include `TRUNCATE` replication and more flexible table selection.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/logical-replication-publication.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">31.2. Publications</a></p>"
    },
    {
        "title": "Subscription",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>In PostgreSQL's logical replication, a subscription is an object on the standby (subscriber) server that connects to a publication on a publisher server. It receives the changes from the publication and applies them to local tables. Subscriptions can be configured to replicate all tables in a publication or a subset, and to apply changes to tables with different names or schemas.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Subscriptions were introduced as part of the built-in logical replication feature in PostgreSQL 10. They have been improved to handle various replication scenarios, including initial data synchronization and conflict resolution.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/logical-replication-subscription.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">31.3. Subscriptions</a></p>"
    },
    {
        "title": "Schema Migration",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Schema migration (or database migration) refers to the process of managing changes to a database schema over time, typically as an application evolves. It involves applying incremental, version-controlled changes (e.g., adding columns, modifying data types, creating new tables) to bring the database schema from one state to another. Tools like Flyway or Liquibase are commonly used for this.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>While not a core PostgreSQL feature itself, schema migration tools are essential for managing PostgreSQL databases in development and production. PostgreSQL's robust DDL transactionality (allowing `CREATE TABLE`, `ALTER TABLE` to be rolled back) makes schema migrations safer.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ddl-transactions.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">5.3. Transactions</a></p>"
    },
    {
        "title": "DDL (Data Definition Language)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>DDL (Data Definition Language) is a subset of SQL commands used to define, modify, and delete database objects and their structures. Common DDL commands include `CREATE` (e.g., `CREATE TABLE`, `CREATE INDEX`), `ALTER` (e.g., `ALTER TABLE`, `ALTER DATABASE`), and `DROP` (e.g., `DROP TABLE`, `DROP SCHEMA`). DDL statements are typically transactional in PostgreSQL.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>DDL commands are fundamental to SQL and PostgreSQL. New DDL commands are introduced with new features (e.g., `CREATE PUBLICATION` in PostgreSQL 10), and existing ones are enhanced (e.g., `ALTER TABLE` for partitioning).</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-commands.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">SQL Commands (DDL, DML, DCL)</a></p>"
    },
    {
        "title": "DML (Data Manipulation Language)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>DML (Data Manipulation Language) is a subset of SQL commands used to manage and manipulate data within database objects. Common DML commands include `SELECT` (retrieve data), `INSERT` (add new rows), `UPDATE` (modify existing rows), and `DELETE` (remove rows). DML operations are always transactional.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>DML commands are core to SQL and PostgreSQL. Enhancements like `INSERT ... ON CONFLICT` (UPSERT) in PostgreSQL 9.5 and improved `MERGE` statement in PostgreSQL 15 have expanded DML capabilities.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-commands.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">SQL Commands (DDL, DML, DCL)</a></p>"
    },
    {
        "title": "DCL (Data Control Language)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>DCL (Data Control Language) is a subset of SQL commands used to control access to data and database objects. The primary DCL commands are `GRANT` (to give privileges to roles) and `REVOKE` (to remove privileges from roles). DCL commands manage database security and authorization.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>DCL commands are fundamental to database security. PostgreSQL's role system and privilege management have been stable, with additions like predefined roles and enhanced `GRANT` options for new object types.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-grant.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">GRANT Documentation</a></p>"
    },
    {
        "title": "TCL (Transaction Control Language)",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>TCL (Transaction Control Language) is a subset of SQL commands used to manage transactions. The main TCL commands are `BEGIN` (start a transaction), `COMMIT` (save changes permanently), and `ROLLBACK` (undo changes). `SAVEPOINT` allows partial rollbacks within a transaction. TCL ensures data integrity and consistency.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>TCL commands are fundamental to transactional databases and have been consistent across all PostgreSQL versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/tutorial-transactions.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">3.4. Transactions</a></p>"
    },
    {
        "title": "GIN Fast Update",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>GIN indexes are highly efficient for queries but can be slow for updates (INSERT/UPDATE/DELETE) because each modification requires updating multiple entries in the index. The \"fast update\" technique for GIN indexes defers some of this work by writing new entries to a temporary, unsorted list (the \"pending list\") in memory, which is then merged into the main index during VACUUM or when the list grows too large. This improves write performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The GIN fast update technique was introduced in PostgreSQL 8.4 and has been refined over versions, making GIN indexes more viable for workloads with frequent updates.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/gin-intro.html#GIN-FAST-UPDATE\" target=\"_blank\" class=\"text-accent-dark hover:underline\">65.1. Introduction - GIN Fast Update</a></p>"
    },
    {
        "title": "BRIN Min/Max",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>BRIN (Block Range Index) indexes store summary information for ranges of data blocks. For ordered data types (like numbers or dates), this summary typically includes the minimum and maximum values found within that block range. When a query filters on such a column, the BRIN index can quickly eliminate entire block ranges that do not contain the desired values, reducing the amount of data to scan.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>BRIN indexes and their min/max summarization were introduced in PostgreSQL 9.5. They are particularly effective for large tables with naturally ordered data.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/brin-intro.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">67.1. BRIN Indexes</a></p>"
    },
    {
        "title": "SP-GiST Index Scan",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An SP-GiST index scan is an access method used by the query planner when a query can be satisfied by an SP-GiST index. This type of scan is efficient for queries involving specialized data types (like geometric data, hierarchical data, or phone numbers) where the SP-GiST index's tree structure allows for rapid traversal and filtering of relevant data points.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>SP-GiST indexes and their scan methods were introduced in PostgreSQL 9.2, expanding the types of queries that can be efficiently indexed.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/spgist.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 68. SP-GiST Indexes</a></p>"
    },
    {
        "title": "Index Only Scans",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An Index Only Scan is an optimization where PostgreSQL can retrieve all the necessary data for a query directly from an index, without needing to access the main table's heap. This is possible if all columns requested by the query (in `SELECT` list, `WHERE` clause, etc.) are present in the index and if the visibility map indicates that all tuples in the index are visible to the current transaction. This greatly reduces I/O.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Index Only Scans were introduced in PostgreSQL 9.2. Their effectiveness has been improved in subsequent versions with better visibility map management and the ability to use them in more scenarios.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/indexes-unique.html#INDEX-ONLY-SCANS\" target=\"_blank\" class=\"text-accent-dark hover:underline\">11.7. Unique Indexes - Index-Only Scans</a></p>"
    },
    {
        "title": "Expression Indexes",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An expression index is an index created on the result of an expression or function, rather than directly on a column. For example, you could create an index on `LOWER(email)` to speed up case-insensitive searches on an email column. This allows queries that use the same expression in their `WHERE` clause to utilize the index.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Expression indexes have been a feature for many versions. They are a powerful tool for optimizing queries that involve transformations or functions on column data.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/indexes-expressions.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">11.7. Indexes on Expressions</a></p>"
    },
    {
        "title": "Partial Indexes",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A partial index is an index created with a `WHERE` clause, so it only indexes a subset of the rows in a table. This makes the index smaller, faster to build, faster to scan, and reduces the overhead on write operations. They are useful for tables where only a small portion of the data is frequently queried (e.g., `WHERE status = 'active'`).</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Partial indexes have been a feature for many versions. They are a valuable optimization technique for specific query patterns and data distributions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/indexes-partial.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">11.8. Partial Indexes</a></p>"
    },
    {
        "title": "Collation",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Collation defines the rules for sorting and comparing text strings in a database. It determines the order of characters, case sensitivity, and accent sensitivity. PostgreSQL allows specifying collations at the database, column, or even expression level, enabling fine-grained control over text behavior according to different linguistic rules.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Collation support has been present for a long time. PostgreSQL 9.1 introduced explicit `COLLATE` clause. PostgreSQL 10 introduced `pg_collations` view. PostgreSQL 15 added support for ICU collations for more robust and up-to-date linguistic rules.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/collation.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">23.2. Collation Support</a></p>"
    },
    {
        "title": "Character Set",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A character set (or encoding) defines how characters are represented as bytes in a database. It determines the range of characters that can be stored and correctly interpreted. PostgreSQL supports various character sets, with UTF-8 being the recommended and most widely used encoding, as it can represent almost all characters from all languages.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Character set support is fundamental. UTF-8 has been the recommended default for many versions, ensuring broad international character support.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/multibyte.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">23.3. Character Set Support</a></p>"
    },
    {
        "title": "Encoding",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>Encoding refers to the specific scheme used to convert characters into a sequence of bytes for storage and transmission. In PostgreSQL, the database encoding determines how text data is stored on disk. It is closely related to character sets; for example, UTF-8 is a common encoding for the Unicode character set.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Database encoding is set at database creation time. While the concept is stable, performance for encoding conversions has been optimized over time.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/multibyte.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">23.3. Character Set Support</a></p>"
    },
    {
        "title": "Locale",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A locale in PostgreSQL defines language-specific and country-specific settings that affect operations like sorting order, character classification (e.g., uppercase/lowercase), and date/time formatting. It combines character set, collation, and other cultural conventions. Locales are typically set at database initialization (`initdb`) but can be overridden at session or object level.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Locale support has been present for many versions. PostgreSQL 15 introduced support for ICU collations, providing more up-to-date and flexible locale-aware sorting and comparison rules.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/locale.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">23.1. Locale Support</a></p>"
    },
    {
        "title": "Sequence",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A sequence is a database object that generates unique, sequential numbers. It is commonly used to generate primary key values for tables, ensuring that each new row gets a distinct identifier. Sequences can be configured with starting values, increments, minimum/maximum values, and cycling behavior.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Sequences are a long-standing feature. PostgreSQL 10 introduced `IDENTITY` columns as a SQL-standard compliant alternative to `SERIAL` types, which are internally based on sequences.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-createsequence.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">CREATE SEQUENCE Documentation</a></p>"
    },
    {
        "title": "SERIAL Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>SERIAL</code> (and its variants `SMALLSERIAL`, `BIGSERIAL`) is a pseudo-type in PostgreSQL that automatically creates an integer column with a default value generated from a sequence. It's a convenient shorthand for creating auto-incrementing primary keys. `SERIAL` is equivalent to `INTEGER NOT NULL DEFAULT nextval('sequence_name')`.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`SERIAL` types have been available for many versions. PostgreSQL 10 introduced `IDENTITY` columns as a more SQL-standard compliant and robust alternative to `SERIAL`.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-SERIAL\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.1. Numeric Types - Serial Types</a></p>"
    },
    {
        "title": "Identity Column",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>An identity column, introduced in PostgreSQL 10, is a SQL-standard compliant way to create auto-incrementing columns. Unlike `SERIAL` (which uses a sequence but allows manual insertion of values), `IDENTITY` columns enforce that values are always generated by the sequence unless `OVERRIDING SYSTEM VALUE` is explicitly specified. This provides stronger data integrity guarantees for auto-generated primary keys.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Identity columns were introduced in PostgreSQL 10 as a direct response to the SQL standard and provide a more robust auto-incrementing mechanism than the traditional `SERIAL` types.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/sql-createtable.html#SQL-CREATETABLE-IDENTITY\" target=\"_blank\" class=\"text-accent-dark hover:underline\">CREATE TABLE - Identity Column</a></p>"
    },
    {
        "title": "UUID Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `UUID` (Universally Unique Identifier) data type stores 128-bit quantities, typically used as unique identifiers across distributed systems. UUIDs are generated in a way that makes collisions (two identical UUIDs) extremely improbable. They are often used as primary keys when a globally unique identifier is required, without relying on a central sequence generator.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>The `UUID` data type has been available in PostgreSQL for many versions. Its use has grown with distributed systems architectures.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-uuid.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.13. UUID Type</a></p>"
    },
    {
        "title": "XML Type",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL provides an `XML` data type for storing XML data. It supports various functions and operators for parsing, querying (using XPath), and manipulating XML documents within the database. While `JSONB` is often preferred for new projects due to its native indexing capabilities, `XML` is useful for integrating with existing XML-based systems.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>XML support has been present for many versions. While its core functionality is stable, `JSONB` has seen more active development for semi-structured data handling in recent releases.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/datatype-xml.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">8.14. XML Type</a></p>"
    },
    {
        "title": "hstore Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `hstore` extension provides a data type for storing sets of key/value pairs within a single PostgreSQL column. It's useful for storing semi-structured data where the keys are strings and the values are also strings. `hstore` supports various operators and GIN/GiST indexes for efficient querying of the key/value data. It predates `JSONB` and is often used for simpler tag-like data.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`hstore` has been available as an extension for a long time. While `JSONB` (introduced later) offers more advanced features for complex JSON documents, `hstore` remains a lightweight and efficient choice for simpler key-value storage.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/hstore.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.11. hstore</a></p>"
    },
    {
        "title": "ltree Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `ltree` extension provides a data type for representing hierarchical tree-like structures (e.g., categories, organizational charts) and functions/operators for querying them efficiently. It allows storing paths as labels (e.g., 'Top.Category.Subcategory') and performing operations like finding ancestors, descendants, or checking for subpaths, often with GiST indexing for performance.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`ltree` is a community-contributed extension useful for specific hierarchical data models. Its functionality is stable and has been available for many PostgreSQL versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/ltree.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.13. ltree</a></p>"
    },
    {
        "title": "cube Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `cube` extension provides a data type for representing multi-dimensional cubes (hypercubes) and functions/operators for performing geometric operations on them, such as calculating distance or checking for overlap. It's useful for spatial data analysis in higher dimensions or for approximate nearest-neighbor searches.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`cube` is a community-contributed extension. Its functionality is stable and has been available for many PostgreSQL versions, primarily for specialized analytical use cases.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/cube.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.16. cube</a></p>"
    },
    {
        "title": "intarray Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `intarray` extension provides functions and operators for efficient manipulation of one-dimensional arrays of integers. It offers specialized operations like checking for array intersection, union, or containment, often with GIN indexes for improved performance compared to generic array operations on `integer[]` types.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`intarray` is a community-contributed extension that has been available for many versions. It provides optimized performance for integer array operations, especially for older PostgreSQL versions before generic array performance was as optimized.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/intarray.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.12. intarray</a></p>"
    },
    {
        "title": "pg_trgm Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `pg_trgm` extension provides functions and index support for text similarity searches based on trigrams (sequences of three characters). It's highly effective for fuzzy string matching, finding similar words, or implementing \"did you mean?\" functionality. It can be used with GiST or GIN indexes for fast similarity queries.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`pg_trgm` is a very popular and widely used extension. Its performance and algorithms have been continuously improved over many PostgreSQL versions, making it a go-to for text similarity.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/pgtrgm.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.30. pg_trgm</a></p>"
    },
    {
        "title": "pg_cron Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `pg_cron` extension allows you to schedule PostgreSQL commands directly within the database, similar to a cron job on an operating system. You can schedule SQL queries, PL/pgSQL functions, or even `VACUUM` commands to run at specified intervals. This simplifies database maintenance and automation.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`pg_cron` is a relatively newer community extension that provides a convenient way to schedule tasks directly in the database, avoiding external cron jobs. Its availability depends on the extension's version and compatibility with your PostgreSQL version.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://pgxn.org/dist/pg_cron/\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_cron PGXN Page</a></p>"
    },
    {
        "title": "pg_prewarm Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `pg_prewarm` extension provides functions to load relation data (tables or indexes) into the operating system's file system cache or the PostgreSQL buffer cache. This is useful for \"warming up\" the database after a restart or for ensuring critical data is in memory before a heavy workload begins, reducing initial query latency.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`pg_prewarm` was introduced as a core extension in PostgreSQL 9.4. It's a valuable tool for performance tuning and minimizing cold cache effects.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/pgprewarm.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.29. pg_prewarm</a></p>"
    },
    {
        "title": "pg_buffercache Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `pg_buffercache` extension provides a means for examining the contents and activity of PostgreSQL's shared buffer cache in real-time. It exposes a view (`pg_buffercache`) that shows which data blocks are currently in memory, their usage count, and other details. This is an invaluable tool for understanding and optimizing buffer cache utilization.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`pg_buffercache` is a core extension that has been available for many versions. It's essential for advanced performance monitoring and debugging cache-related issues.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/pgbuffercache.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.25. pg_buffercache</a></p>"
    },
    {
        "title": "pg_stat_statements Extension",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `pg_stat_statements` extension provides a way to track execution statistics of all SQL statements executed by a server. It aggregates data like total execution time, number of calls, I/O usage, and rows affected for each unique query. This is a critical tool for identifying slow queries and understanding overall database workload patterns.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`pg_stat_statements` is a widely used and essential extension. It has been continuously improved in each PostgreSQL version to provide more detailed metrics and better performance overhead.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/pgstatstatements.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.32. pg_stat_statements</a></p>"
    },
    {
        "title": "pg_dump",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_dump</code> is a utility for backing up a single PostgreSQL database. It creates a script file (either plain-text SQL or a custom format) containing SQL commands to recreate the database schema and data. It's commonly used for logical backups, migrations, or creating copies of databases.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>pg_dump</code> is a fundamental utility. It is continuously updated to support new PostgreSQL features and data types, ensuring compatibility across versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/app-pgdump.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_dump Documentation</a></p>"
    },
    {
        "title": "pg_restore",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_restore</code> is a utility for restoring a PostgreSQL database from an archive created by `pg_dump` in its custom or directory format. It allows for flexible restoration, such as restoring only specific tables, reordering objects, or restoring to a different database. It is much more versatile than simply running a plain SQL script.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>pg_restore</code> is a fundamental utility that evolves with `pg_dump` to support new archive formats and restoration options, ensuring robust backup and recovery capabilities.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/app-pgrestore.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_restore Documentation</a></p>"
    },
    {
        "title": "pg_basebackup",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br><code>pg_basebackup</code> is a utility used to take a base backup of a running PostgreSQL cluster. It creates a consistent snapshot of the data directory, which can then be used as a starting point for Point-In-Time Recovery (PITR) or for setting up a streaming replication standby server. It performs a physical backup, copying the actual data files.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br><code>pg_basebackup</code> was introduced in PostgreSQL 9.1 and has become the standard tool for physical backups and setting up replication. It has been improved with features like checksum verification and parallel compression.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/app-pgbasebackup.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">pg_basebackup Documentation</a></p>"
    },
    {
        "title": "Recursive CTE",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>A recursive Common Table Expression (CTE), defined with `WITH RECURSIVE`, allows a query to refer to its own output. This is essential for querying hierarchical or graph-like data structures, such as organizational charts, bill of materials, or network paths. It consists of an \"anchor member\" (the base case) and a \"recursive member\" (the iterative step).</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Recursive CTEs were introduced in PostgreSQL 8.4, providing a powerful SQL-standard way to handle recursive queries that previously required procedural code or complex self-joins.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/queries-with.html#id-1.5.6.10.6\" target=\"_blank\" class=\"text-accent-dark hover:underline\">7.8. WITH Queries (Common Table Expressions) - Recursive Queries</a></p>"
    },
    {
        "title": "Full Text Search",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostgreSQL provides built-in full-text search capabilities for natural language queries on text documents. It involves converting text into a `tsvector` (a sorted list of unique lexemes) and queries into a `tsquery` (a representation of words to search for). GIN or GiST indexes can be used on `tsvector` columns to accelerate searches.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>Full-text search features were introduced in PostgreSQL 8.3 and have been continuously improved with better language support, ranking algorithms, and performance optimizations.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/textsearch.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">Chapter 12. Full Text Search</a></p>"
    },
    {
        "title": "PostGIS",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>PostGIS is a powerful spatial extension for PostgreSQL that adds support for geographic objects (points, lines, polygons) and spatial functions. It enables storing, querying, and analyzing location-aware data within the database, making PostgreSQL a robust geospatial database. It leverages GiST indexes for efficient spatial queries.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>PostGIS is a widely adopted and actively developed extension. It continuously adds new spatial features, functions, and performance improvements, often in sync with new PostgreSQL versions.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://postgis.net/\" target=\"_blank\" class=\"text-accent-dark hover:underline\">PostGIS Official Website</a></p>"
    },
    {
        "title": "pg_stat_statements",
        "resolution": "<p><strong class=\"error-section-title\">Explanation:</strong><br>The `pg_stat_statements` extension provides a way to track execution statistics of all SQL statements executed by a server. It aggregates data like total execution time, number of calls, I/O usage, and rows affected for each unique query. This is a critical tool for identifying slow queries and understanding overall database workload patterns.</p><p><strong class=\"error-section-title\">Version Impact:</strong><br>`pg_stat_statements` is a widely used and essential extension. It has been continuously improved in each PostgreSQL version to provide more detailed metrics and better performance overhead.</p><p><strong class=\"error-section-title\">Reference:</strong><br><a href=\"https://www.postgresql.org/docs/current/pgstatstatements.html\" target=\"_blank\" class=\"text-accent-dark hover:underline\">F.32. pg_stat_statements</a></p>"
    }
                ]
            },
            'postgresql-installation-guide': {
                title: "PostgreSQL Installation Guide",
                intro: "This guide covers the steps for installing PostgreSQL on various operating systems.",
                issues: [
                  
                    {
                        title: "What is PostgreSQL?",
                        description: `
                            <p><strong class="error-section-title">Name:</strong> PostgreSQL</p>
                            <p><strong class="error-section-title">Description:</strong> PostgreSQL is a powerful, open-source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance. It supports both SQL (relational) and JSON (non-relational) querying. It is known for its strong adherence to SQL standards and its advanced features like ACID compliance, foreign keys, join, views, triggers, and stored procedures.</p>
                            <p><strong class="error-section-title">Key Features:</strong></p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li>Open-source and free to use</li>
                                <li>Object-relational database system</li>
                                <li>ACID compliant</li>
                                <li>Extensible and highly customizable</li>
                                <li>Supports a wide range of data types</li>
                                <li>Robust and reliable</li>
                                <li>Strong community support</li>
                            </ul>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Installation Methods: macOS",
                        description: `
                            <p><strong class="error-section-title">Homebrew (Recommended):</strong> Homebrew is a popular package manager for macOS that simplifies the installation of software.</p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li>Install Homebrew (if not already installed): <div class="code-block"><pre><code>/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"</code></pre></div></li>
                                <li>Update Homebrew: <div class="code-block"><pre><code>brew update</code></pre></div></li>
                                <li>Install PostgreSQL: <div class="code-block"><pre><code>brew install postgresql</code></pre></div></li>
                                <li>Start PostgreSQL service: <div class="code-block"><pre><code>brew services start postgresql</code></pre></div></li>
                                <li>Verify installation: <div class="code-block"><pre><code>psql -V</code></pre></div></li>
                            </ul>
                            <p><strong class="error-section-title">Postgres.app:</strong> A native macOS application that includes a PostgreSQL server. Easy to use for development.</p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li>Download Postgres.app from <a href="https://postgresapp.com/" target="_blank" class="text-accent-dark hover:underline">https://postgresapp.com/</a></li>
                                <li>Drag the app to your Applications folder.</li>
                                <li>Open Postgres.app and click 'Initialize' to create a new server.</li>
                                <li>Add the <code>psql</code> command-line tools to your PATH for easy access (instructions provided within the app).</li>
                            </ul>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Installation Methods: Windows",
                        description: `
                            <p><strong class="error-section-title">EnterpriseDB (EDB) Installer (Recommended):</strong> The official and most common way to install PostgreSQL on Windows, providing a comprehensive installer.</p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li>Download the installer from <a href="https://www.enterprisedb.com/downloads/postgres-postgresql-downloads" target="_blank" class="text-accent-dark hover:underline">https://www.enterprisedb.com/downloads/postgres-postgresql-downloads</a></li>
                                <li>Run the installer and follow the on-screen prompts.</li>
                                <li>Choose components to install (PostgreSQL Server, pgAdmin 4, Stack Builder, Command Line Tools).</li>
                                <li>Set a password for the 'postgres' superuser.</li>
                                <li>Select a data directory.</li>
                                <li>Choose a port number (default is 5432).</li>
                                <li>Complete the installation. Stack Builder can be used to install additional tools/drivers.</li>
                            </ul>
                            <p><strong class="error-section-title">WSL (Windows Subsystem for Linux):</strong> Install PostgreSQL within a Linux distribution running on WSL2, offering a more Linux-like environment.</p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li>Enable WSL and install a Linux distribution (e.g., Ubuntu) from the Microsoft Store.</li>
                                <li>Open your WSL terminal.</li>
                                <li>Follow the Linux installation steps for your chosen distribution (e.g., <div class="code-block"><pre><code>sudo apt update && sudo apt install postgresql postgresql-contrib</code></pre></div>).</li>
                            </ul>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Installation Methods: Linux",
                        description: `
                            <p><strong class="error-section-title">Package Manager (Recommended):</strong> The standard way to install software on Linux distributions, ensuring proper integration and updates.</p>
                            <p><strong>Debian/Ubuntu:</strong></p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li><div class="code-block"><pre><code>sudo apt update</code></pre></div></li>
                                <li><div class="code-block"><pre><code>sudo apt install postgresql postgresql-contrib</code></pre></div></li>
                                <li><div class="code-block"><pre><code>sudo systemctl start postgresql</code></pre></div></li>
                                <li><div class="code-block"><pre><code>sudo systemctl enable postgresql</code></pre></div></li>
                                <li>Switch to postgres user: <div class="code-block"><pre><code>sudo -i -u postgres</code></pre></div></li>
                                <li>Access psql prompt: <div class="code-block"><pre><code>psql</code></pre></div></li>
                                <li>Exit psql: <div class="code-block"><pre><code>\\q</code></pre></div></li>
                                <li>Exit postgres user: <div class="code-block"><pre><code>exit</code></pre></div></li>
                            </ul>
                            <p><strong>RHEL/CentOS/Fedora:</strong></p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li><div class="code-block"><pre><code>sudo dnf install postgresql-server postgresql-contrib</code></pre></div> (Fedora/RHEL 8+)</li>
                                <li><div class="code-block"><pre><code>sudo yum install postgresql-server postgresql-contrib</code></pre></div> (CentOS/RHEL 7)</li>
                                <li>Initialize database: <div class="code-block"><pre><code>sudo /usr/bin/postgresql-setup --initdb</code></pre></div></li>
                                <li><div class="code-block"><pre><code>sudo systemctl start postgresql</code></pre></div></li>
                                <li><div class="code-block"><pre><code>sudo systemctl enable postgresql</code></pre></div></li>
                                <li>Switch to postgres user: <div class="code-block"><pre><code>sudo -i -u postgres</code></pre></div></li>
                                <li>Access psql prompt: <div class="code-block"><pre><code>psql</code></pre></div></li>
                                <li>Exit psql: <div class="code-block"><pre><code>\\q</code></pre></div></li>
                                <li>Exit postgres user: <div class="code-block"><pre><code>exit</code></pre></div></li>
                            </ul>
                            <p><strong class="error-section-title">Source Code (Advanced):</strong> Compiling from source offers the most control but is generally not recommended for beginners.</p>
                            <ul class="list-disc ml-5 space-y-1">
                                <li>Download source from <a href="https://www.postgresql.org/download/" target="_blank" class="text-accent-dark hover:underline">https://www.postgresql.org/download/</a></li>
                                <li>Extract and configure: <div class="code-block"><pre><code>./configure</code></pre></div></li>
                                <li>Compile: <div class="code-block"><pre><code>make</code></pre></div></li>
                                <li>Install: <div class="code-block"><pre><code>sudo make install</code></pre></div></li>
                            </ul>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Common Installation Errors: General",
                        description: `
                            <p><strong class="error-section-title">Port 5432 already in use:</strong> Another application is using the default PostgreSQL port.</p>
                            <p><strong class="error-section-title">Solution:</strong> Change PostgreSQL's port in <code>postgresql.conf</code> (e.g., to 5433) or stop the conflicting application. On Windows, check for other PostgreSQL instances or database servers.</p>
                            <p><strong class="error-section-title">Password authentication failed for user 'postgres':</strong> Incorrect password when trying to connect.</p>
                            <p><strong class="error-section-title">Solution:</strong> Ensure you are using the correct password. Reset the password if necessary (often involves editing <code>pg_hba.conf</code> and restarting the server).</p>
                            <p><strong class="error-section-title">FATAL: database 'your_database_name' does not exist:</strong> Attempting to connect to a database that hasn't been created.</p>
                            <p><strong class="error-section-title">Solution:</strong> Create the database first using <div class="code-block"><pre><code>CREATE DATABASE your_database_name;</code></pre></div> while connected to the default 'postgres' database.</p>
                            <p><strong class="error-section-title">could not connect to server: Connection refused:</strong> The PostgreSQL server is not running, or firewall is blocking the connection.</p>
                            <p><strong class="error-section-title">Solution:</strong> Ensure the PostgreSQL service is running. Check firewall settings to allow connections on port 5432. Verify <code>listen_addresses</code> in <code>postgresql.conf</code> is set correctly (e.g., <code>'*'</code> or <code>localhost</code>).</p>
                            <p><strong class="error-section-title">FATAL: role 'your_username' does not exist:</strong> Attempting to connect with a user role that doesn't exist.</p>
                            <p><strong class="error-section-title">Solution:</strong> Create the user role using <div class="code-block"><pre><code>CREATE ROLE your_username WITH LOGIN PASSWORD 'your_password';</code></pre></div> (or <div class="code-block"><pre><code>CREATE USER your_username WITH PASSWORD 'your_password';</code></pre></div>).</p>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Common Installation Errors: macOS",
                        description: `
                            <p><strong class="error-section-title">Homebrew: \`Error: postgresql: the bottle needs the XCode Command Line Tools.\`:</strong> Missing Xcode Command Line Tools required by Homebrew.</p>
                            <p><strong class="error-section-title">Solution:</strong> Install them: <div class="code-block"><pre><code>xcode-select --install</code></pre></div></p>
                            <p><strong class="error-section-title">Postgres.app: 'Could not connect to server':</strong> The server isn't running or hasn't been initialized.</p>
                            <p><strong class="error-section-title">Solution:</strong> Open Postgres.app and ensure a server is running (green light) and initialized.</p>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Common Installation Errors: Windows",
                        description: `
                            <p><strong class="error-section-title">EDB Installer: 'Failed to run initdb':</strong> Permission issues or conflicting files during database initialization.</p>
                            <p><strong class="error-section-title">Solution:</strong> Run the installer as Administrator. Ensure the selected data directory is empty and has proper write permissions. Temporarily disable antivirus/firewall if it interferes.</p>
                            <p><strong class="error-section-title">EDB Installer: 'Service 'postgresql-x64-XX' failed to start':</strong> The PostgreSQL service failed to start after installation.</p>
                            <p><strong class="error-section-title">Solution:</strong> Check Windows Event Viewer for more details. Often related to port conflicts or permission issues. Try restarting your machine.</p>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    },
                    {
                        title: "Common Installation Errors: Linux",
                        description: `
                            <p><strong class="error-section-title">Package Manager: 'E: Unable to locate package postgresql':</strong> The package name is incorrect or repositories are not updated.</p>
                            <p><strong class="error-section-title">Solution:</strong> Ensure correct package name (<code>postgresql</code> or <code>postgresql-server</code>). Run <div class="code-block"><pre><code>sudo apt update</code></pre></div> (Debian/Ubuntu) or <div class="code-block"><pre><code>sudo yum update</code></pre></div> (RHEL/CentOS) to refresh package lists.</p>
                            <p><strong class="error-section-title">FATAL: Peer authentication failed for user \"postgres\":</strong> Default authentication method for local connections on Linux is 'peer', which uses OS usernames.</p>
                            <p><strong class="error-section-title">Solution:</strong> Connect as the <code>postgres</code> OS user: <div class="code-block"><pre><code>sudo -i -u postgres psql</code></pre></div>. Alternatively, modify <code>pg_hba.conf</code> to use <code>md5</code> authentication for local connections.</p>
                        `,
                        common_causes: "N/A",
                        resolution: "N/A"
                    }
                ]
            },
            'system-catalog-tables': {
                title: "PostgreSQL System Catalog Tables",
                intro: "PostgreSQL maintains a set of system catalog tables that store metadata about the database objects (tables, columns, indexes, functions, etc.) and their properties. These tables are crucial for the database's internal operations and can be queried by users to gain insights into the database's structure and activity.",
                issues: [

                ]
            },
            'connection-authentication': {
                title: "Connection & Authentication",
                intro: "This section addresses common issues related to connecting to PostgreSQL and authentication failures.",
                issues: [
                  {
    "title": "FATAL: password authentication failed for user 'postgres'",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER postgres WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'app_user'",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER app_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'admin_db'",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER admin_db WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'replication_user'",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER replication_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: role 'dev_user' does not exist",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE dev_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'reporting_user' does not exist",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE reporting_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'backup_user' does not exist",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE backup_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "could not connect to server: Connection refused (IP: 127.0.0.1, Port: 5432)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
  },
  {
    "title": "could not connect to server: Connection refused (IP: 192.168.1.100, Port: 5432)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "could not connect to server: Connection refused (IP: localhost, Port: 5433)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"10.0.0.5\", user \"app_user\", database \"production_db\"",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"172.16.0.20\", user \"reporting\", database \"analytics_db\"",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"192.168.1.1\", user \"dba\", database \"all\"",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: database 'my_app_db' does not exist",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE my_app_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: database 'test_db' does not exist",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE test_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: database 'staging_db' does not exist",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE staging_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "WARNING: password for user 'old_user' has expired",
    "description": "The password for the specified user has passed its validity period, as set by `VALID UNTIL`.",
    "common_causes": "Password validity period expired, not regularly updating passwords.",
    "resolution": "- Reset the user's password using `ALTER USER old_user WITH PASSWORD 'new_password' VALID UNTIL 'infinity';` or set a new expiry date."
  },
  {
    "title": "WARNING: password for user 'temp_user' has expired",
    "description": "The password for the specified user has passed its validity period, as set by `VALID UNTIL`.",
    "common_causes": "Password validity period expired, not regularly updating passwords.",
    "resolution": "- Reset the user's password using `ALTER USER temp_user WITH PASSWORD 'new_password' VALID UNTIL 'infinity';` or set a new expiry date."
  },
  {
    "title": "FATAL: Too many clients already",
    "description": "The PostgreSQL server has reached its maximum allowed number of concurrent connections.",
    "common_causes": "`max_connections` parameter is set too low, application connection leaks, connection pooling issues.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires restart).\n- Implement connection pooling in your application or use a connection pooler like PgBouncer.\n- Identify and fix application connection leaks."
  },
  {
    "title": "FATAL: SSL connection is required",
    "description": "The server's `pg_hba.conf` or `ssl_prefer_server_ciphers` setting requires SSL, but the client is attempting a non-SSL connection.",
    "common_causes": "Client not configured for SSL, `pg_hba.conf` has `hostssl` entry.",
    "resolution": "- Configure the client to use SSL (e.g., `sslmode=require` in connection string).\n- If not desired, change `pg_hba.conf` entries from `hostssl` to `host`."
  },
  {
    "title": "FATAL: data directory '/var/lib/postgresql/data' has wrong ownership",
    "description": "The data directory or its contents are not owned by the PostgreSQL operating system user.",
    "common_causes": "Manual file operations changing ownership, incorrect permissions after restore/migration.",
    "resolution": "- Change ownership of the data directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /var/lib/postgresql/data`).\n- Ensure correct permissions (`chmod -R 0700 /var/lib/postgresql/data`)."
  },
  {
    "title": "FATAL: data directory '/opt/pgdata' has wrong ownership",
    "description": "The data directory or its contents are not owned by the PostgreSQL operating system user.",
    "common_causes": "Manual file operations changing ownership, incorrect permissions after restore/migration.",
    "resolution": "- Change ownership of the data directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /opt/pgdata`).\n- Ensure correct permissions (`chmod -R 0700 /opt/pgdata`)."
  },
  {
    "title": "FATAL: could not create lock file '/var/lib/postgresql/data/postmaster.pid': Permission denied",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup.",
    "common_causes": "Incorrect permissions on the data directory, PostgreSQL user lacks write access.",
    "resolution": "- Ensure the PostgreSQL user has write permissions to the data directory (`chmod 0700 /var/lib/postgresql/data` and `chown postgres:postgres /var/lib/postgresql/data`)."
  },
  {
    "title": "FATAL: could not create lock file '/tmp/pg_temp/postmaster.pid': Permission denied",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup.",
    "common_causes": "Incorrect permissions on the data directory, PostgreSQL user lacks write access.",
    "resolution": "- Ensure the PostgreSQL user has write permissions to the data directory (`chmod 0700 /tmp/pg_temp` and `chown postgres:postgres /tmp/pg_temp`)."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'max_connections_limit'",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'shared_buffers_size'",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'wal_level_replica'",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: value \"100000\" for parameter \"max_connections\" is out of range",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: value \"10TB\" for parameter \"shared_buffers\" is out of range",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: value \"-5\" for parameter \"log_min_duration_statement\" is out of range",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: parameter \"shared_buffers\" cannot be changed now",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: parameter \"max_connections\" cannot be changed now",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: parameter \"wal_level\" cannot be changed now",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: could not load configuration file \"postgresql.conf\": Permission denied",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `postgresql.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 postgresql.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_hba.conf\": Permission denied",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `pg_hba.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 pg_hba.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_ident.conf\": Permission denied",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `pg_ident.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 pg_ident.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_hba.conf\": read error",
    "description": "PostgreSQL encountered an error while reading a configuration file, often due to corruption or disk issues.",
    "common_causes": "Disk error, corrupted file, non-standard characters in file.",
    "resolution": "- Check disk health.\n- Examine `pg_hba.conf` for hidden or non-printable characters.\n- Restore from a backup if corrupted."
  },
  {
    "title": "FATAL: could not load configuration file \"postgresql.conf\": read error",
    "description": "PostgreSQL encountered an error while reading a configuration file, often due to corruption or disk issues.",
    "common_causes": "Disk error, corrupted file, non-standard characters in file.",
    "resolution": "- Check disk health.\n- Examine `postgresql.conf` for hidden or non-printable characters.\n- Restore from a backup if corrupted."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device",
    "description": "PostgreSQL failed to allocate necessary shared memory, usually during startup.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall`.\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create socket: Too many open files",
    "description": "The system has run out of file descriptors, preventing new connections or operations.",
    "common_causes": "`ulimit -n` is too low for the PostgreSQL user, many active connections/files.",
    "resolution": "- Increase `ulimit -n` for the PostgreSQL user in `limits.conf` or equivalent system configuration.\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not translate host name \"db-server-prod\" to address: Name or service not known",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: could not translate host name \"replica-node\" to address: Name or service not known",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: could not translate host name \"app-host\" to address: Name or service not known",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: invalid locale name \"en_US.UTF-8\"",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: invalid locale name \"fr_FR.utf8\"",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: invalid locale name \"C\"",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: could not create directory \"/var/lib/postgresql/data/pg_wal\": No space left on device",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: could not create directory \"/tmp/pg_temp_files\": No space left on device",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: could not create directory \"/var/log/postgresql\": No space left on device",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: The database system is starting up",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its starting up process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: The database system is shutting down",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its shutting down process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: The database system is in recovery mode",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its in recovery mode process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: SSL connection not allowed: no SSL library support",
    "description": "The server is configured to require SSL connections, but the client or server installation lacks SSL library support.",
    "common_causes": "PostgreSQL compiled without SSL support, `ssl` parameter enabled without necessary libraries.",
    "resolution": "- Recompile PostgreSQL with SSL support (e.g., `--with-openssl`).\n- Alternatively, disable SSL requirement in `postgresql.conf` if not needed (not recommended for production)."
  },
  {
    "title": "FATAL: invalid SSL connection attempt",
    "description": "An SSL handshake failed, often due to mismatched certificates or incorrect SSL settings.",
    "common_causes": "Invalid SSL certificates, incorrect `sslmode`, firewall interfering with SSL ports.",
    "resolution": "- Verify server and client SSL certificates.\n- Check `sslmode` in the connection string (e.g., `verify-full`, `verify-ca`, `require`).\n- Ensure firewalls allow SSL traffic."
  },
  {
    "title": "ERROR: PAM authentication failed for user \"system_user\"",
    "description": "PostgreSQL attempted to authenticate the user via PAM (Pluggable Authentication Modules), but PAM reported a failure.",
    "common_causes": "Incorrect PAM configuration on the server, user not found in PAM, password mismatch in PAM.",
    "resolution": "- Check PAM configuration files (e.g., `/etc/pam.d/postgresql`).\n- Verify the user exists in the OS and has correct PAM settings.\n- Ensure passwords are synchronized if using system passwords."
  },
  {
    "title": "ERROR: PAM authentication failed for user \"web_app_user\"",
    "description": "PostgreSQL attempted to authenticate the user via PAM (Pluggable Authentication Modules), but PAM reported a failure.",
    "common_causes": "Incorrect PAM configuration on the server, user not found in PAM, password mismatch in PAM.",
    "resolution": "- Check PAM configuration files (e.g., `/etc/pam.d/postgresql`).\n- Verify the user exists in the OS and has correct PAM settings.\n- Ensure passwords are synchronized if using system passwords."
  },
  {
    "title": "FATAL: hot standby not enabled in postgresql.conf",
    "description": "A standby server is attempting to connect or stream WAL, but `hot_standby` is not enabled.",
    "common_causes": "`hot_standby = off` in `postgresql.conf` on the standby.",
    "resolution": "- Set `hot_standby = on` in the standby's `postgresql.conf` and restart PostgreSQL."
  },
  {
    "title": "FATAL: data directory is not empty but contains no \"PG_VERSION\" file",
    "description": "PostgreSQL tries to initialize a data directory but finds it non-empty without a `PG_VERSION` file, indicating it's not a valid data directory.",
    "common_causes": "Attempting `initdb` on an existing directory, corrupted data directory.",
    "resolution": "- Ensure `initdb` is run on an *empty* directory.\n- If it's an existing data directory, check its integrity.\n- Do not run `initdb` on a populated data directory unless you intend to erase it."
  },
  {
    "title": "FATAL: could not create child process: Resource temporarily unavailable",
    "description": "The operating system cannot fork a new process for a client connection.",
    "common_causes": "System running out of memory, too many processes, `ulimit -u` too low.",
    "resolution": "- Check system memory (`free -h`) and process count.\n- Increase `ulimit -u` (max user processes) for the PostgreSQL user."
  },
  {
    "title": "FATAL: max_prepared_transactions must be less than max_connections",
    "description": "The `max_prepared_transactions` parameter is configured incorrectly relative to `max_connections`.",
    "common_causes": "Misconfiguration in `postgresql.conf`.",
    "resolution": "- Ensure `max_prepared_transactions` is less than or equal to `max_connections` (and typically `max_connections` + `max_worker_processes`).\n- Adjust values in `postgresql.conf` and restart."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied",
    "description": "PostgreSQL cannot read the SSL private key file due to incorrect permissions.",
    "common_causes": "Private key file not readable by PostgreSQL user.",
    "resolution": "- Ensure the `server.key` file is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not access private key file \"client.key\": Permission denied",
    "description": "PostgreSQL cannot read the SSL private key file due to incorrect permissions.",
    "common_causes": "Private key file not readable by PostgreSQL user.",
    "resolution": "- Ensure the `client.key` file is owned by the PostgreSQL user and has strict permissions (`chmod 0600 client.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory",
    "description": "PostgreSQL cannot find the SSL certificate file.",
    "common_causes": "Incorrect path to `server.crt`, file missing.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure the `server.crt` file exists at that location."
  },
  {
    "title": "FATAL: could not load server certificate file \"ca.crt\": No such file or directory",
    "description": "PostgreSQL cannot find the SSL certificate file.",
    "common_causes": "Incorrect path to `ca.crt`, file missing.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure the `ca.crt` file exists at that location."
  },
  {
    "title": "FATAL: connection requires a valid client certificate",
    "description": "The server is configured to require client certificates for authentication, but the client did not provide one or it was invalid.",
    "common_causes": "`clientcert=1` in `pg_hba.conf`, client not sending certificate.",
    "resolution": "- Configure the client to provide a valid SSL client certificate, or change the `pg_hba.conf` entry if client certificate authentication is not desired."
  },
  {
    "title": "FATAL: system time changed unexpectedly",
    "description": "PostgreSQL detected a significant change in the system clock, which can disrupt internal operations.",
    "common_causes": "Manual time change, NTP daemon not synchronized, VM time drift.",
    "resolution": "- Ensure `ntpd` or `chronyd` is running and properly synchronized.\n- Avoid manual time changes while PostgreSQL is running.\n- For VMs, ensure host time synchronization is enabled."
  },
  {
    "title": "FATAL: replication connection could not be established because of conflict",
    "description": "A replication connection failed due to conflicts, typically on the primary for a streaming replication standby.",
    "common_causes": "Conflicting transactions on the primary, long-running queries blocking WAL replay on standby.",
    "resolution": "- Adjust `wal_sender_timeout` on primary.\n- Check for long-running queries on primary.\n- Increase `max_wal_senders`."
  },
  {
    "title": "FATAL: password authentication failed for user \"guest\" (client IP address: 1.2.3.4)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user \"unknown\" (client IP address: 203.0.113.10)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user \"monitor\" (client IP address: 192.0.2.5)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user 'postgres' (Instance 55)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER postgres WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'app_user' (Instance 56)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER app_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'admin_db' (Instance 57)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER admin_db WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'replication_user' (Instance 58)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER replication_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: role 'dev_user' does not exist (Instance 59)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE dev_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'reporting_user' does not exist (Instance 60)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE reporting_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'backup_user' does not exist (Instance 61)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE backup_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "could not connect to server: Connection refused (IP: 127.0.0.1, Port: 5432) (Instance 62)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "could not connect to server: Connection refused (IP: 192.168.1.100, Port: 5432) (Instance 63)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "could not connect to server: Connection refused (IP: localhost, Port: 5433) (Instance 64)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"10.0.0.5\", user \"app_user\", database \"production_db\" (Instance 65)",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"172.16.0.20\", user \"reporting\", database \"analytics_db\" (Instance 66)",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"192.168.1.1\", user \"dba\", database \"all\" (Instance 67)",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: database 'my_app_db' does not exist (Instance 68)",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE my_app_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: database 'test_db' does not exist (Instance 69)",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE test_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: database 'staging_db' does not exist (Instance 70)",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE staging_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "WARNING: password for user 'old_user' has expired (Instance 71)",
    "description": "The password for the specified user has passed its validity period, as set by `VALID UNTIL`.",
    "common_causes": "Password validity period expired, not regularly updating passwords.",
    "resolution": "- Reset the user's password using `ALTER USER old_user WITH PASSWORD 'new_password' VALID UNTIL 'infinity';` or set a new expiry date."
  },
  {
    "title": "WARNING: password for user 'temp_user' has expired (Instance 72)",
    "description": "The password for the specified user has passed its validity period, as set by `VALID UNTIL`.",
    "common_causes": "Password validity period expired, not regularly updating passwords.",
    "resolution": "- Reset the user's password using `ALTER USER temp_user WITH PASSWORD 'new_password' VALID UNTIL 'infinity';` or set a new expiry date."
  },
  {
    "title": "FATAL: Too many clients already (Instance 73)",
    "description": "The PostgreSQL server has reached its maximum allowed number of concurrent connections.",
    "common_causes": "`max_connections` parameter is set too low, application connection leaks, connection pooling issues.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires restart).\n- Implement connection pooling in your application or use a connection pooler like PgBouncer.\n- Identify and fix application connection leaks."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 74)",
    "description": "The server's `pg_hba.conf` or `ssl_prefer_server_ciphers` setting requires SSL, but the client is attempting a non-SSL connection.",
    "common_causes": "Client not configured for SSL, `pg_hba.conf` has `hostssl` entry.",
    "resolution": "- Configure the client to use SSL (e.g., `sslmode=require` in connection string).\n- If not desired, change `pg_hba.conf` entries from `hostssl` to `host`."
  },
  {
    "title": "FATAL: data directory '/var/lib/postgresql/data' has wrong ownership (Instance 75)",
    "description": "The data directory or its contents are not owned by the PostgreSQL operating system user.",
    "common_causes": "Manual file operations changing ownership, incorrect permissions after restore/migration.",
    "resolution": "- Change ownership of the data directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /var/lib/postgresql/data`).\n- Ensure correct permissions (`chmod -R 0700 /var/lib/postgresql/data`)."
  },
  {
    "title": "FATAL: data directory '/opt/pgdata' has wrong ownership (Instance 76)",
    "description": "The data directory or its contents are not owned by the PostgreSQL operating system user.",
    "common_causes": "Manual file operations changing ownership, incorrect permissions after restore/migration.",
    "resolution": "- Change ownership of the data directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /opt/pgdata`).\n- Ensure correct permissions (`chmod -R 0700 /opt/pgdata`)."
  },
  {
    "title": "FATAL: could not create lock file '/var/lib/postgresql/data/postmaster.pid': Permission denied (Instance 77)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup.",
    "common_causes": "Incorrect permissions on the data directory, PostgreSQL user lacks write access.",
    "resolution": "- Ensure the PostgreSQL user has write permissions to the data directory (`chmod 0700 /var/lib/postgresql/data` and `chown postgres:postgres /var/lib/postgresql/data`)."
  },
  {
    "title": "FATAL: could not create lock file '/tmp/pg_temp/postmaster.pid': Permission denied (Instance 78)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup.",
    "common_causes": "Incorrect permissions on the data directory, PostgreSQL user lacks write access.",
    "resolution": "- Ensure the PostgreSQL user has write permissions to the data directory (`chmod 0700 /tmp/pg_temp` and `chown postgres:postgres /tmp/pg_temp`)."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'max_connections_limit' (Instance 79)",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'shared_buffers_size' (Instance 80)",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'wal_level_replica' (Instance 81)",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: value \"100000\" for parameter \"max_connections\" is out of range (Instance 82)",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: value \"10TB\" for parameter \"shared_buffers\" is out of range (Instance 83)",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: value \"-5\" for parameter \"log_min_duration_statement\" is out of range (Instance 84)",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: parameter \"shared_buffers\" cannot be changed now (Instance 85)",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: parameter \"max_connections\" cannot be changed now (Instance 86)",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: parameter \"wal_level\" cannot be changed now (Instance 87)",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: could not load configuration file \"postgresql.conf\": Permission denied (Instance 88)",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `postgresql.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 postgresql.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_hba.conf\": Permission denied (Instance 89)",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `pg_hba.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 pg_hba.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_ident.conf\": Permission denied (Instance 90)",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `pg_ident.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 pg_ident.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_hba.conf\": read error (Instance 91)",
    "description": "PostgreSQL encountered an error while reading a configuration file, often due to corruption or disk issues.",
    "common_causes": "Disk error, corrupted file, non-standard characters in file.",
    "resolution": "- Check disk health.\n- Examine `pg_hba.conf` for hidden or non-printable characters.\n- Restore from a backup if corrupted."
  },
  {
    "title": "FATAL: could not load configuration file \"postgresql.conf\": read error (Instance 92)",
    "description": "PostgreSQL encountered an error while reading a configuration file, often due to corruption or disk issues.",
    "common_causes": "Disk error, corrupted file, non-standard characters in file.",
    "resolution": "- Check disk health.\n- Examine `postgresql.conf` for hidden or non-printable characters.\n- Restore from a backup if corrupted."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 93)",
    "description": "PostgreSQL failed to allocate necessary shared memory, usually during startup.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall`.\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create socket: Too many open files (Instance 94)",
    "description": "The system has run out of file descriptors, preventing new connections or operations.",
    "common_causes": "`ulimit -n` is too low for the PostgreSQL user, many active connections/files.",
    "resolution": "- Increase `ulimit -n` for the PostgreSQL user in `limits.conf` or equivalent system configuration.\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not translate host name \"db-server-prod\" to address: Name or service not known (Instance 95)",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: could not translate host name \"replica-node\" to address: Name or service not known (Instance 96)",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: could not translate host name \"app-host\" to address: Name or service not known (Instance 97)",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: invalid locale name \"en_US.UTF-8\" (Instance 98)",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: invalid locale name \"fr_FR.utf8\" (Instance 99)",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: invalid locale name \"C\" (Instance 100)",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: could not create directory \"/var/lib/postgresql/data/pg_wal\": No space left on device (Instance 101)",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: could not create directory \"/tmp/pg_temp_files\": No space left on device (Instance 102)",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: could not create directory \"/var/log/postgresql\": No space left on device (Instance 103)",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: The database system is starting up (Instance 104)",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its starting up process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: The database system is shutting down (Instance 105)",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its shutting down process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: The database system is in recovery mode (Instance 106)",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its in recovery mode process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: SSL connection not allowed: no SSL library support (Instance 107)",
    "description": "The server is configured to require SSL connections, but the client or server installation lacks SSL library support.",
    "common_causes": "PostgreSQL compiled without SSL support, `ssl` parameter enabled without necessary libraries.",
    "resolution": "- Recompile PostgreSQL with SSL support (e.g., `--with-openssl`).\n- Alternatively, disable SSL requirement in `postgresql.conf` if not needed (not recommended for production)."
  },
  {
    "title": "FATAL: invalid SSL connection attempt (Instance 108)",
    "description": "An SSL handshake failed, often due to mismatched certificates or incorrect SSL settings.",
    "common_causes": "Invalid SSL certificates, incorrect `sslmode`, firewall interfering with SSL ports.",
    "resolution": "- Verify server and client SSL certificates.\n- Check `sslmode` in the connection string (e.g., `verify-full`, `verify-ca`, `require`).\n- Ensure firewalls allow SSL traffic."
  },
  {
    "title": "ERROR: PAM authentication failed for user \"system_user\" (Instance 109)",
    "description": "PostgreSQL attempted to authenticate the user via PAM (Pluggable Authentication Modules), but PAM reported a failure.",
    "common_causes": "Incorrect PAM configuration on the server, user not found in PAM, password mismatch in PAM.",
    "resolution": "- Check PAM configuration files (e.g., `/etc/pam.d/postgresql`).\n- Verify the user exists in the OS and has correct PAM settings.\n- Ensure passwords are synchronized if using system passwords."
  },
  {
    "title": "ERROR: PAM authentication failed for user \"web_app_user\" (Instance 110)",
    "description": "PostgreSQL attempted to authenticate the user via PAM (Pluggable Authentication Modules), but PAM reported a failure.",
    "common_causes": "Incorrect PAM configuration on the server, user not found in PAM, password mismatch in PAM.",
    "resolution": "- Check PAM configuration files (e.g., `/etc/pam.d/postgresql`).\n- Verify the user exists in the OS and has correct PAM settings.\n- Ensure passwords areynchronized if using system passwords."
  },
  {
    "title": "FATAL: hot standby not enabled in postgresql.conf (Instance 111)",
    "description": "A standby server is attempting to connect or stream WAL, but `hot_standby` is not enabled.",
    "common_causes": "`hot_standby = off` in `postgresql.conf` on the standby.",
    "resolution": "- Set `hot_standby = on` in the standby's `postgresql.conf` and restart PostgreSQL."
  },
  {
    "title": "FATAL: data directory is not empty but contains no \"PG_VERSION\" file (Instance 112)",
    "description": "PostgreSQL tries to initialize a data directory but finds it non-empty without a `PG_VERSION` file, indicating it's not a valid data directory.",
    "common_causes": "Attempting `initdb` on an existing directory, corrupted data directory.",
    "resolution": "- Ensure `initdb` is run on an *empty* directory.\n- If it's an existing data directory, check its integrity.\n- Do not run `initdb` on a populated data directory unless you intend to erase it."
  },
  {
    "title": "FATAL: could not create child process: Resource temporarily unavailable (Instance 113)",
    "description": "The operating system cannot fork a new process for a client connection.",
    "common_causes": "System running out of memory, too many processes, `ulimit -u` too low.",
    "resolution": "- Check system memory (`free -h`) and process count.\n- Increase `ulimit -u` (max user processes) for the PostgreSQL user."
  },
  {
    "title": "FATAL: max_prepared_transactions must be less than max_connections (Instance 114)",
    "description": "The `max_prepared_transactions` parameter is configured incorrectly relative to `max_connections`.",
    "common_causes": "Misconfiguration in `postgresql.conf`.",
    "resolution": "- Ensure `max_prepared_transactions` is less than or equal to `max_connections` (and typically `max_connections` + `max_worker_processes`).\n- Adjust values in `postgresql.conf` and restart."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 115)",
    "description": "PostgreSQL cannot read the SSL private key file due to incorrect permissions.",
    "common_causes": "Private key file not readable by PostgreSQL user.",
    "resolution": "- Ensure the `server.key` file is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not access private key file \"client.key\": Permission denied (Instance 116)",
    "description": "PostgreSQL cannot read the SSL private key file due to incorrect permissions.",
    "common_causes": "Private key file not readable by PostgreSQL user.",
    "resolution": "- Ensure the `client.key` file is owned by the PostgreSQL user and has strict permissions (`chmod 0600 client.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 117)",
    "description": "PostgreSQL cannot find the SSL certificate file.",
    "common_causes": "Incorrect path to `server.crt`, file missing.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure the `server.crt` file exists at that location."
  },
  {
    "title": "FATAL: could not load server certificate file \"ca.crt\": No such file or directory (Instance 118)",
    "description": "PostgreSQL cannot find the SSL certificate file.",
    "common_causes": "Incorrect path to `ca.crt`, file missing.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure the `ca.crt` file exists at that location."
  },
  {
    "title": "FATAL: connection requires a valid client certificate (Instance 119)",
    "description": "The server is configured to require client certificates for authentication, but the client did not provide one or it was invalid.",
    "common_causes": "`clientcert=1` in `pg_hba.conf`, client not sending certificate.",
    "resolution": "- Configure the client to provide a valid SSL client certificate, or change the `pg_hba.conf` entry if client certificate authentication is not desired."
  },
  {
    "title": "FATAL: system time changed unexpectedly (Instance 120)",
    "description": "PostgreSQL detected a significant change in the system clock, which can disrupt internal operations.",
    "common_causes": "Manual time change, NTP daemon not synchronized, VM time drift.",
    "resolution": "- Ensure `ntpd` or `chronyd` is running and properly synchronized.\n- Avoid manual time changes while PostgreSQL is running.\n- For VMs, ensure host time synchronization is enabled."
  },
  {
    "title": "FATAL: replication connection could not be established because of conflict (Instance 121)",
    "description": "A replication connection failed due to conflicts, typically on the primary for a streaming replication standby.",
    "common_causes": "Conflicting transactions on the primary, long-running queries blocking WAL replay on standby.",
    "resolution": "- Adjust `wal_sender_timeout` on primary.\n- Check for long-running queries on primary.\n- Increase `max_wal_senders`."
  },
  {
    "title": "FATAL: password authentication failed for user \"guest\" (client IP address: 1.2.3.4) (Instance 122)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user \"unknown\" (client IP address: 203.0.113.10) (Instance 123)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user \"monitor\" (client IP address: 192.0.2.5) (Instance 124)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user 'postgres' (Instance 125)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER postgres WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'app_user' (Instance 126)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER app_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'admin_db' (Instance 127)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER admin_db WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'replication_user' (Instance 128)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER replication_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: role 'dev_user' does not exist (Instance 129)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE dev_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'reporting_user' does not exist (Instance 130)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE reporting_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'backup_user' does not exist (Instance 131)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE backup_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "could not connect to server: Connection refused (IP: 127.0.0.1, Port: 5432) (Instance 132)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "could not connect to server: Connection refused (IP: 192.168.1.100, Port: 5432) (Instance 133)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "could not connect to server: Connection refused (IP: localhost, Port: 5433) (Instance 134)",
    "description": "The client tried to connect, but the server actively refused the connection, indicating no process is listening on the specified port/address.",
    "common_causes": "PostgreSQL server is not running, firewall blocking the connection, incorrect host/port in connection string.",
    "resolution": "- Check if PostgreSQL is running (`sudo systemctl status postgresql` or similar).\n- Verify firewall rules (`ufw status`, `iptables -L`).\n- Ensure correct host and port (`-h`, `-p` in `psql`) are used in the connection string."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"10.0.0.5\", user \"app_user\", database \"production_db\" (Instance 135)",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"172.16.0.20\", user \"reporting\", database \"analytics_db\" (Instance 136)",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"192.168.1.1\", user \"dba\", database \"all\" (Instance 137)",
    "description": "The `pg_hba.conf` file on the server does not contain a rule that permits the incoming connection based on host, user, and database.",
    "common_causes": "Missing or incorrect entry in `pg_hba.conf`, incorrect authentication method specified.",
    "resolution": "- Edit `pg_hba.conf` on the server to add a rule that matches the client's IP, username, database, and desired authentication method (e.g., `host all all 0.0.0.0/0 md5`).\n- Reload PostgreSQL configuration: `pg_ctl reload` or `sudo systemctl reload postgresql`."
  },
  {
    "title": "FATAL: database 'my_app_db' does not exist (Instance 138)",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE my_app_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: database 'test_db' does not exist (Instance 139)",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE test_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: database 'staging_db' does not exist (Instance 140)",
    "description": "The client is attempting to connect to a database that does not exist on the server.",
    "common_causes": "Typo in database name, database not created yet, connecting to the wrong instance.",
    "resolution": "- Verify the database name.\n- Create the database if it doesn't exist: `CREATE DATABASE staging_db;`.\n- Ensure connecting to the correct PostgreSQL instance."
  },
  {
    "title": "WARNING: password for user 'old_user' has expired (Instance 141)",
    "description": "The password for the specified user has passed its validity period, as set by `VALID UNTIL`.",
    "common_causes": "Password validity period expired, not regularly updating passwords.",
    "resolution": "- Reset the user's password using `ALTER USER old_user WITH PASSWORD 'new_password' VALID UNTIL 'infinity';` or set a new expiry date."
  },
  {
    "title": "WARNING: password for user 'temp_user' has expired (Instance 142)",
    "description": "The password for the specified user has passed its validity period, as set by `VALID UNTIL`.",
    "common_causes": "Password validity period expired, not regularly updating passwords.",
    "resolution": "- Reset the user's password using `ALTER USER temp_user WITH PASSWORD 'new_password' VALID UNTIL 'infinity';` or set a new expiry date."
  },
  {
    "title": "FATAL: Too many clients already (Instance 143)",
    "description": "The PostgreSQL server has reached its maximum allowed number of concurrent connections.",
    "common_causes": "`max_connections` parameter is set too low, application connection leaks, connection pooling issues.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires restart).\n- Implement connection pooling in your application or use a connection pooler like PgBouncer.\n- Identify and fix application connection leaks."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 144)",
    "description": "The server's `pg_hba.conf` or `ssl_prefer_server_ciphers` setting requires SSL, but the client is attempting a non-SSL connection.",
    "common_causes": "Client not configured for SSL, `pg_hba.conf` has `hostssl` entry.",
    "resolution": "- Configure the client to use SSL (e.g., `sslmode=require` in connection string).\n- If not desired, change `pg_hba.conf` entries from `hostssl` to `host`."
  },
  {
    "title": "FATAL: data directory '/var/lib/postgresql/data' has wrong ownership (Instance 145)",
    "description": "The data directory or its contents are not owned by the PostgreSQL operating system user.",
    "common_causes": "Manual file operations changing ownership, incorrect permissions after restore/migration.",
    "resolution": "- Change ownership of the data directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /var/lib/postgresql/data`).\n- Ensure correct permissions (`chmod -R 0700 /var/lib/postgresql/data`)."
  },
  {
    "title": "FATAL: data directory '/opt/pgdata' has wrong ownership (Instance 146)",
    "description": "The data directory or its contents are not owned by the PostgreSQL operating system user.",
    "common_causes": "Manual file operations changing ownership, incorrect permissions after restore/migration.",
    "resolution": "- Change ownership of the data directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /opt/pgdata`).\n- Ensure correct permissions (`chmod -R 0700 /opt/pgdata`)."
  },
  {
    "title": "FATAL: could not create lock file '/var/lib/postgresql/data/postmaster.pid': Permission denied (Instance 147)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup.",
    "common_causes": "Incorrect permissions on the data directory, PostgreSQL user lacks write access.",
    "resolution": "- Ensure the PostgreSQL user has write permissions to the data directory (`chmod 0700 /var/lib/postgresql/data` and `chown postgres:postgres /var/lib/postgresql/data`)."
  },
  {
    "title": "FATAL: could not create lock file '/tmp/pg_temp/postmaster.pid': Permission denied (Instance 148)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup.",
    "common_causes": "Incorrect permissions on the data directory, PostgreSQL user lacks write access.",
    "resolution": "- Ensure the PostgreSQL user has write permissions to the data directory (`chmod 0700 /tmp/pg_temp` and `chown postgres:postgres /tmp/pg_temp`)."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'max_connections_limit' (Instance 149)",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'shared_buffers_size' (Instance 150)",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: unrecognized key/value for option: 'wal_level_replica' (Instance 151)",
    "description": "An unknown or misspelled option was found in `postgresql.conf` or a connection string.",
    "common_causes": "Typo in configuration, deprecated parameter, old config file used with new PostgreSQL version.",
    "resolution": "- Correct the typo.\n- Consult PostgreSQL documentation for valid parameters for your version.\n- Remove deprecated options."
  },
  {
    "title": "FATAL: value \"100000\" for parameter \"max_connections\" is out of range (Instance 152)",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: value \"10TB\" for parameter \"shared_buffers\" is out of range (Instance 153)",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: value \"-5\" for parameter \"log_min_duration_statement\" is out of range (Instance 154)",
    "description": "A configuration parameter in `postgresql.conf` has a value outside its permissible range.",
    "common_causes": "Typo, incorrect unit (e.g., MB vs GB), misunderstanding of parameter limits.",
    "resolution": "- Correct the value in `postgresql.conf` according to PostgreSQL documentation.\n- Ensure correct units are used (e.g., `128MB`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: parameter \"shared_buffers\" cannot be changed now (Instance 155)",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: parameter \"max_connections\" cannot be changed now (Instance 156)",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: parameter \"wal_level\" cannot be changed now (Instance 157)",
    "description": "An attempt was made to change a parameter that requires a server restart, but only a configuration reload was done, or it was changed using `ALTER SYSTEM` when it requires a restart.",
    "common_causes": "Trying to apply a `postmaster` or `restart` scoped parameter without a full server restart.",
    "resolution": "- Fully restart the PostgreSQL server after changing the parameter in `postgresql.conf`.\n- For `ALTER SYSTEM`, note if it requires a restart."
  },
  {
    "title": "FATAL: could not load configuration file \"postgresql.conf\": Permission denied (Instance 158)",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `postgresql.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 postgresql.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_hba.conf\": Permission denied (Instance 159)",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `pg_hba.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 pg_hba.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_ident.conf\": Permission denied (Instance 160)",
    "description": "PostgreSQL cannot read its main configuration file.",
    "common_causes": "Incorrect file permissions or ownership for the configuration file.",
    "resolution": "- Ensure `pg_ident.conf` is owned by the PostgreSQL user and has appropriate read permissions (`chmod 0600 pg_ident.conf`)."
  },
  {
    "title": "FATAL: could not load configuration file \"pg_hba.conf\": read error (Instance 161)",
    "description": "PostgreSQL encountered an error while reading a configuration file, often due to corruption or disk issues.",
    "common_causes": "Disk error, corrupted file, non-standard characters in file.",
    "resolution": "- Check disk health.\n- Examine `pg_hba.conf` for hidden or non-printable characters.\n- Restore from a backup if corrupted."
  },
  {
    "title": "FATAL: could not load configuration file \"postgresql.conf\": read error (Instance 162)",
    "description": "PostgreSQL encountered an error while reading a configuration file, often due to corruption or disk issues.",
    "common_causes": "Disk error, corrupted file, non-standard characters in file.",
    "resolution": "- Check disk health.\n- Examine `postgresql.conf` for hidden or non-printable characters.\n- Restore from a backup if corrupted."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 163)",
    "description": "PostgreSQL failed to allocate necessary shared memory, usually during startup.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall`.\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create socket: Too many open files (Instance 164)",
    "description": "The system has run out of file descriptors, preventing new connections or operations.",
    "common_causes": "`ulimit -n` is too low for the PostgreSQL user, many active connections/files.",
    "resolution": "- Increase `ulimit -n` for the PostgreSQL user in `limits.conf` or equivalent system configuration.\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not translate host name \"db-server-prod\" to address: Name or service not known (Instance 165)",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: could not translate host name \"replica-node\" to address: Name or service not known (Instance 166)",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: could not translate host name \"app-host\" to address: Name or service not known (Instance 167)",
    "description": "The client or server cannot resolve a hostname to an IP address.",
    "common_causes": "DNS resolution failure, incorrect hostname, network configuration issues.",
    "resolution": "- Check DNS settings (`/etc/resolv.conf`).\n- Verify hostname is correct and resolvable.\n- Use IP addresses instead of hostnames in `pg_hba.conf` and connection strings if DNS is unstable."
  },
  {
    "title": "FATAL: invalid locale name \"en_US.UTF-8\" (Instance 168)",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: invalid locale name \"fr_FR.utf8\" (Instance 169)",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: invalid locale name \"C\" (Instance 170)",
    "description": "The locale specified during database creation or connection is not recognized by the operating system.",
    "common_causes": "Incorrect locale string, locale not installed on the OS.",
    "resolution": "- Install the required locale on the operating system.\n- Use `locale -a` to list available locales.\n- Specify a valid locale in `initdb` or database creation."
  },
  {
    "title": "FATAL: could not create directory \"/var/lib/postgresql/data/pg_wal\": No space left on device (Instance 171)",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: could not create directory \"/tmp/pg_temp_files\": No space left on device (Instance 172)",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: could not create directory \"/var/log/postgresql\": No space left on device (Instance 173)",
    "description": "PostgreSQL cannot create new directories (e.g., for temporary files, WAL segments) due to full disk space.",
    "common_causes": "Disk full.",
    "resolution": "- Free up disk space on the volume where the PostgreSQL data directory resides.\n- Identify and delete unnecessary files (logs, old backups)."
  },
  {
    "title": "FATAL: The database system is starting up (Instance 174)",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its starting up process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: The database system is shutting down (Instance 175)",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its shutting down process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: The database system is in recovery mode (Instance 176)",
    "description": "The client tried to connect while PostgreSQL is in a transitional state.",
    "common_causes": "Server just started, recovering from a crash/shutdown, or is a standby/replica.",
    "resolution": "- Wait for the PostgreSQL server to fully complete its in recovery mode process before attempting to connect.\n- Check server logs for progress."
  },
  {
    "title": "FATAL: SSL connection not allowed: no SSL library support (Instance 177)",
    "description": "The server is configured to require SSL connections, but the client or server installation lacks SSL library support.",
    "common_causes": "PostgreSQL compiled without SSL support, `ssl` parameter enabled without necessary libraries.",
    "resolution": "- Recompile PostgreSQL with SSL support (e.g., `--with-openssl`).\n- Alternatively, disable SSL requirement in `postgresql.conf` if not needed (not recommended for production)."
  },
  {
    "title": "FATAL: invalid SSL connection attempt (Instance 178)",
    "description": "An SSL handshake failed, often due to mismatched certificates or incorrect SSL settings.",
    "common_causes": "Invalid SSL certificates, incorrect `sslmode`, firewall interfering with SSL ports.",
    "resolution": "- Verify server and client SSL certificates.\n- Check `sslmode` in the connection string (e.g., `verify-full`, `verify-ca`, `require`).\n- Ensure firewalls allow SSL traffic."
  },
  {
    "title": "ERROR: PAM authentication failed for user \"system_user\" (Instance 179)",
    "description": "PostgreSQL attempted to authenticate the user via PAM (Pluggable Authentication Modules), but PAM reported a failure.",
    "common_causes": "Incorrect PAM configuration on the server, user not found in PAM, password mismatch in PAM.",
    "resolution": "- Check PAM configuration files (e.g., `/etc/pam.d/postgresql`).\n- Verify the user exists in the OS and has correct PAM settings.\n- Ensure passwords are synchronized if using system passwords."
  },
  {
    "title": "ERROR: PAM authentication failed for user \"web_app_user\" (Instance 180)",
    "description": "PostgreSQL attempted to authenticate the user via PAM (Pluggable Authentication Modules), but PAM reported a failure.",
    "common_causes": "Incorrect PAM configuration on the server, user not found in PAM, password mismatch in PAM.",
    "resolution": "- Check PAM configuration files (e.g., `/etc/pam.d/postgresql`).\n- Verify the user exists in the OS and has correct PAM settings.\n- Ensure passwords are synchronized if using system passwords."
  },
  {
    "title": "FATAL: hot standby not enabled in postgresql.conf (Instance 181)",
    "description": "A standby server is attempting to connect or stream WAL, but `hot_standby` is not enabled.",
    "common_causes": "`hot_standby = off` in `postgresql.conf` on the standby.",
    "resolution": "- Set `hot_standby = on` in the standby's `postgresql.conf` and restart PostgreSQL."
  },
  {
    "title": "FATAL: data directory is not empty but contains no \"PG_VERSION\" file (Instance 182)",
    "description": "PostgreSQL tries to initialize a data directory but finds it non-empty without a `PG_VERSION` file, indicating it's not a valid data directory.",
    "common_causes": "Attempting `initdb` on an existing directory, corrupted data directory.",
    "resolution": "- Ensure `initdb` is run on an *empty* directory.\n- If it's an existing data directory, check its integrity.\n- Do not run `initdb` on a populated data directory unless you intend to erase it."
  },
  {
    "title": "FATAL: could not create child process: Resource temporarily unavailable (Instance 183)",
    "description": "The operating system cannot fork a new process for a client connection.",
    "common_causes": "System running out of memory, too many processes, `ulimit -u` too low.",
    "resolution": "- Check system memory (`free -h`) and process count.\n- Increase `ulimit -u` (max user processes) for the PostgreSQL user."
  },
  {
    "title": "FATAL: max_prepared_transactions must be less than max_connections (Instance 184)",
    "description": "The `max_prepared_transactions` parameter is configured incorrectly relative to `max_connections`.",
    "common_causes": "Misconfiguration in `postgresql.conf`.",
    "resolution": "- Ensure `max_prepared_transactions` is less than or equal to `max_connections` (and typically `max_connections` + `max_worker_processes`).\n- Adjust values in `postgresql.conf` and restart."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 185)",
    "description": "PostgreSQL cannot read the SSL private key file due to incorrect permissions.",
    "common_causes": "Private key file not readable by PostgreSQL user.",
    "resolution": "- Ensure the `server.key` file is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not access private key file \"client.key\": Permission denied (Instance 186)",
    "description": "PostgreSQL cannot read the SSL private key file due to incorrect permissions.",
    "common_causes": "Private key file not readable by PostgreSQL user.",
    "resolution": "- Ensure the `client.key` file is owned by the PostgreSQL user and has strict permissions (`chmod 0600 client.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 187)",
    "description": "PostgreSQL cannot find the SSL certificate file.",
    "common_causes": "Incorrect path to `server.crt`, file missing.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure the `server.crt` file exists at that location."
  },
  {
    "title": "FATAL: could not load server certificate file \"ca.crt\": No such file or directory (Instance 188)",
    "description": "PostgreSQL cannot find the SSL certificate file.",
    "common_causes": "Incorrect path to `ca.crt`, file missing.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure the `ca.crt` file exists at that location."
  },
  {
    "title": "FATAL: connection requires a valid client certificate (Instance 189)",
    "description": "The server is configured to require client certificates for authentication, but the client did not provide one or it was invalid.",
    "common_causes": "`clientcert=1` in `pg_hba.conf`, client not sending certificate.",
    "resolution": "- Configure the client to provide a valid SSL client certificate, or change the `pg_hba.conf` entry if client certificate authentication is not desired."
  },
  {
    "title": "FATAL: system time changed unexpectedly (Instance 190)",
    "description": "PostgreSQL detected a significant change in the system clock, which can disrupt internal operations.",
    "common_causes": "Manual time change, NTP daemon not synchronized, VM time drift.",
    "resolution": "- Ensure `ntpd` or `chronyd` is running and properly synchronized.\n- Avoid manual time changes while PostgreSQL is running.\n- For VMs, ensure host time synchronization is enabled."
  },
  {
    "title": "FATAL: replication connection could not be established because of conflict (Instance 191)",
    "description": "A replication connection failed due to conflicts, typically on the primary for a streaming replication standby.",
    "common_causes": "Conflicting transactions on the primary, long-running queries blocking WAL replay on standby.",
    "resolution": "- Adjust `wal_sender_timeout` on primary.\n- Check for long-running queries on primary.\n- Increase `max_wal_senders`."
  },
  {
    "title": "FATAL: password authentication failed for user \"guest\" (client IP address: 1.2.3.4) (Instance 192)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user \"unknown\" (client IP address: 203.0.113.10) (Instance 193)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user \"monitor\" (client IP address: 192.0.2.5) (Instance 194)",
    "description": "Similar to other password failures, but explicitly shows the client IP, which is useful for security auditing.",
    "common_causes": "Incorrect password, brute-force attack.",
    "resolution": "- Verify password.\n- Review `pg_hba.conf`.\n- Investigate suspicious IP addresses in server logs for potential attack."
  },
  {
    "title": "FATAL: password authentication failed for user 'postgres' (Instance 195)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER postgres WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'app_user' (Instance 196)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER app_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'admin_db' (Instance 197)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER admin_db WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: password authentication failed for user 'replication_user' (Instance 198)",
    "description": "The client provided an incorrect password for the specified user during connection.",
    "common_causes": "Typo in password, forgotten password, incorrect password in connection string/tool configuration.",
    "resolution": "- Double-check the password.\n- If forgotten, reset it using `ALTER USER replication_user WITH PASSWORD 'new_password';` (as a superuser).\n- Ensure the client application sends the correct password."
  },
  {
    "title": "FATAL: role 'dev_user' does not exist (Instance 199)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE dev_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  },
  {
    "title": "FATAL: role 'reporting_user' does not exist (Instance 200)",
    "description": "The username (role) specified in the connection attempt does not exist in the PostgreSQL database.",
    "common_causes": "Typo in username, user role not created yet, connecting to the wrong database/cluster.",
    "resolution": "- Verify the username.\n- Create the user role if it doesn't exist: `CREATE ROLE reporting_user WITH LOGIN PASSWORD 'your_password';`.\n- Ensure you're connecting to the correct PostgreSQL instance."
  }
                ]
            },
            'locking-concurrency': {
                title: "Locking & Concurrency",
                intro: "This section covers problems arising from database locking, deadlocks, and concurrent access.",
                issues: [ {
    "title": "Deadlock Detected",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 11)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 12)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 13)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 14)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 15)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 16)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 17)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 18)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 19)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 20)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 21)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 22)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 23)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 24)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 25)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 26)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 27)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 28)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 29)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 30)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 31)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 32)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 33)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 34)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 35)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 36)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 37)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 38)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 39)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 40)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 41)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 42)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 43)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 44)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 45)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 46)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 47)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 48)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 49)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 50)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 51)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 52)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 53)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 54)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 55)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 56)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 57)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 58)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 59)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 60)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 61)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 62)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 63)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 64)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 65)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 66)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 67)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 68)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 69)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 70)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 71)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 72)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 73)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 74)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 75)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 76)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 77)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 78)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 79)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 80)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 81)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 82)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 83)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 84)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 85)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 86)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 87)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 88)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 89)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 90)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 91)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 92)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 93)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 94)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 95)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 96)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 97)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 98)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 99)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 100)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 101)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 102)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 103)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 104)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 105)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 106)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 107)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 108)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 109)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 110)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 111)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 112)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 113)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 114)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 115)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 116)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 117)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 118)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 119)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 120)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 121)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 122)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 123)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 124)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 125)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 126)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 127)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 128)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 129)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 130)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 131)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 132)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 133)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 134)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 135)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 136)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 137)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 138)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 139)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 140)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 141)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 142)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 143)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 144)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 145)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 146)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 147)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 148)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 149)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 150)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 151)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 152)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 153)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 154)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 155)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 156)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 157)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 158)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 159)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 160)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 161)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 162)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 163)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 164)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 165)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 166)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 167)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 168)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 169)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 170)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 171)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 172)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 173)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 174)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 175)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 176)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 177)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 178)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 179)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 180)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 181)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 182)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 183)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 184)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 185)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 186)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 187)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 188)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 189)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 190)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  },
  {
    "title": "Deadlock Detected (Instance 191)",
    "description": "Two or more transactions are waiting for each other to release locks, resulting in a deadlock.",
    "common_causes": "Application transaction patterns causing contention, long-running transactions, complex update statements without proper ordering.",
    "resolution": "- Analyze application transaction patterns to reduce contention.\n- Implement retry logic in your application for deadlocked transactions.\n- Identify long-running transactions and optimize them.\n- Check the `log_lock_waits` and `deadlock_timeout` parameters in `postgresql.conf`."
  },
  {
    "title": "Lock wait timeout exceeded (Instance 192)",
    "description": "A transaction waited too long to acquire a lock and timed out.",
    "common_causes": "Long-held locks by other transactions, inefficient queries trying to acquire locks, low `lock_timeout` setting.",
    "resolution": "- Identify the queries holding locks using `pg_locks` view.\n- Optimize queries or increase `lock_timeout` (with caution).\n- Review transaction isolation levels."
  },
  {
    "title": "Frequent Row Exclusivity Locks (Instance 193)",
    "description": "High contention on rows due to frequent updates or deletes, slowing down write operations.",
    "common_causes": "Inefficient DML statements, lack of proper indexing for write operations, high transaction volume on specific rows.",
    "resolution": "- Optimize DML statements.\n- Consider using `SELECT FOR UPDATE NOWAIT` in application logic to avoid waiting indefinitely.\n- Improve indexing to reduce the number of rows scanned and locked."
  },
  {
    "title": "Serialization failure (Instance 194)",
    "description": "A transaction failed because a concurrent serializable transaction modified data that the current transaction also read, violating serializability.",
    "common_causes": "Using `SERIALIZABLE` isolation level with concurrent writes, lack of proper transaction design.",
    "resolution": "- Implement retry logic for `SERIALIZABLE` transactions.\n- Re-evaluate if `SERIALIZABLE` is strictly necessary; `REPEATABLE READ` or `READ COMMITTED` might suffice.\n- Optimize transactions to reduce read/write conflicts."
  },
  {
    "title": "Could not obtain lock on row (Instance 195)",
    "description": "A statement attempted to acquire a lock on a row but was unable to do so because another transaction already holds a conflicting lock.",
    "common_causes": "Concurrent updates/deletes on the same row, long-running transactions holding row locks.",
    "resolution": "- Identify the transaction holding the lock using `pg_locks`.\n- Optimize queries to minimize lock duration.\n- Consider `SELECT FOR UPDATE NOWAIT` or `SKIP LOCKED`."
  },
  {
    "title": "Transaction aborted due to concurrent update (Instance 196)",
    "description": "A transaction was rolled back because a concurrent transaction modified a row that the current transaction had already read and was attempting to update.",
    "common_causes": "Concurrent updates, typically with `READ COMMITTED` isolation level, where a row is updated by another transaction after being read by the current one.",
    "resolution": "- Implement retry logic in the application.\n- Review transaction boundaries to ensure operations are atomic and short-lived.\n- Consider `SELECT FOR UPDATE` if strong consistency is needed."
  },
  {
    "title": "Too many concurrent connections for replication (Instance 197)",
    "description": "The number of active replication connections has exceeded the `max_wal_senders` limit.",
    "common_causes": "`max_wal_senders` is set too low, too many standby servers or replication slots.",
    "resolution": "- Increase `max_wal_senders` in `postgresql.conf` (requires restart).\n- Review the number of active standby servers and replication slots."
  },
  {
    "title": "Idle in transaction connections blocking others (Instance 198)",
    "description": "Connections are holding open transactions for a long time without performing any work, blocking other queries from acquiring locks.",
    "common_causes": "Application code not committing/rolling back transactions promptly, user sessions left open.",
    "resolution": "- Identify and fix application code that leaves transactions open.\n- Set `idle_in_transaction_session_timeout` in `postgresql.conf` to automatically terminate such sessions.\n- Educate users on proper application usage."
  },
  {
    "title": "Advisory lock contention (Instance 199)",
    "description": "Multiple sessions are contending for the same PostgreSQL advisory lock, leading to delays.",
    "common_causes": "Application using advisory locks for coordination without proper handling of contention, long-held advisory locks.",
    "resolution": "- Review application logic using advisory locks.\n- Ensure advisory locks are released promptly.\n- Consider `pg_try_advisory_lock` for non-blocking attempts."
  },
  {
    "title": "Table-level lock contention (Instance 200)",
    "description": "Queries are experiencing delays due to contention for table-level locks (e.g., `ACCESS EXCLUSIVE`, `SHARE UPDATE EXCLUSIVE`).",
    "common_causes": "Frequent DDL operations, `VACUUM FULL`, `REINDEX`, or `ALTER TABLE` statements running concurrently with DML/DQL.",
    "resolution": "- Schedule DDL operations during off-peak hours.\n- Use `REINDEX CONCURRENTLY` and `ALTER TABLE ... ADD COLUMN ... DEFAULT ... NOT NULL` (in stages) to minimize lock times.\n- Optimize `VACUUM` settings to reduce the need for `VACUUM FULL`."
  }
]
            },
            'replication-ha': {
                title: "Replication & High Availability",
                intro: "Troubleshooting issues related to PostgreSQL replication (e.g., streaming replication, logical replication) and high availability setups.",
                issues: [
                  {
    "title": "Replication Lag",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  },
  {
    "title": "FATAL: could not load primary's timeline history file \"00000001.history\": No such file or directory",
    "description": "The standby is missing a timeline history file from the primary, indicating a divergence in WAL history.",
    "common_causes": "Manual intervention on WAL, primary's WAL archive incomplete, standby pointing to wrong timeline.",
    "resolution": "- Re-base the standby from a fresh backup of the primary.\n- Ensure consistent WAL archiving on the primary.\n- Avoid manual manipulation of WAL files."
  },
  {
    "title": "FATAL: standby is not in recovery",
    "description": "A command or connection requiring the standby to be in recovery mode was attempted, but it is not.",
    "common_causes": "`recovery_target_timeline` or `recovery_target_xid` not set correctly, standby promoted prematurely.",
    "resolution": "- Ensure `recovery.conf` (or `postgresql.conf` in newer versions) is correctly configured for recovery.\n- Verify the standby was started in recovery mode.\n- If the standby was promoted, it is no longer a standby and should be treated as a primary."
  },
  {
    "title": "FATAL: could not write to file \"pg_xlog/archive_status/000000010000000000000001.ready\": No space left on device",
    "description": "The primary cannot mark a WAL segment as ready for archiving due to full disk space in the archive status directory.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files.",
    "resolution": "- Free up disk space on the primary server.\n- Check the status of `archive_command` and ensure it is successfully moving WAL files to the archive location.\n- Investigate the archive destination for space issues."
  },
  {
    "title": "FATAL: archive command failed with exit code 1",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\"",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\"",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\"",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's.",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline.",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled.",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file.",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 29)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 30)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 31)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 32)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 33)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 34)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 35)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 36)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 37)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 38)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 39)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 40)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 41)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 42)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 43)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 44)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 45)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 46)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 47)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 48)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 49)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 50)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 51)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 52)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 53)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 54)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 55)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 56)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 57)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 58)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 59)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 60)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 61)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 62)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "Replication Lag (Instance 63)",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found (Instance 64)",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly (Instance 65)",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist (Instance 66)",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots (Instance 67)",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 68)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 69)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory (Instance 70)",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  },
  {
    "title": "FATAL: could not load primary's timeline history file \"00000001.history\": No such file or directory (Instance 71)",
    "description": "The standby is missing a timeline history file from the primary, indicating a divergence in WAL history.",
    "common_causes": "Manual intervention on WAL, primary's WAL archive incomplete, standby pointing to wrong timeline.",
    "resolution": "- Re-base the standby from a fresh backup of the primary.\n- Ensure consistent WAL archiving on the primary.\n- Avoid manual manipulation of WAL files."
  },
  {
    "title": "FATAL: standby is not in recovery (Instance 72)",
    "description": "A command or connection requiring the standby to be in recovery mode was attempted, but it is not.",
    "common_causes": "`recovery_target_timeline` or `recovery_target_xid` not set correctly, standby promoted prematurely.",
    "resolution": "- Ensure `recovery.conf` (or `postgresql.conf` in newer versions) is correctly configured for recovery.\n- Verify the standby was started in recovery mode.\n- If the standby was promoted, it is no longer a standby and should be treated as a primary."
  },
  {
    "title": "FATAL: could not write to file \"pg_xlog/archive_status/000000010000000000000001.ready\": No space left on device (Instance 73)",
    "description": "The primary cannot mark a WAL segment as ready for archiving due to full disk space in the archive status directory.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files.",
    "resolution": "- Free up disk space on the primary server.\n- Check the status of `archive_command` and ensure it is successfully moving WAL files to the archive location.\n- Investigate the archive destination for space issues."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 74)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 75)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 76)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 77)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 78)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 79)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 80)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 81)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 82)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 83)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 84)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 85)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 86)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 87)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 88)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "Replication Lag (Instance 89)",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found (Instance 90)",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly (Instance 91)",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist (Instance 92)",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots (Instance 93)",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 94)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 95)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory (Instance 96)",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  },
  {
    "title": "FATAL: could not load primary's timeline history file \"00000001.history\": No such file or directory (Instance 97)",
    "description": "The standby is missing a timeline history file from the primary, indicating a divergence in WAL history.",
    "common_causes": "Manual intervention on WAL, primary's WAL archive incomplete, standby pointing to wrong timeline.",
    "resolution": "- Re-base the standby from a fresh backup of the primary.\n- Ensure consistent WAL archiving on the primary.\n- Avoid manual manipulation of WAL files."
  },
  {
    "title": "FATAL: standby is not in recovery (Instance 98)",
    "description": "A command or connection requiring the standby to be in recovery mode was attempted, but it is not.",
    "common_causes": "`recovery_target_timeline` or `recovery_target_xid` not set correctly, standby promoted prematurely.",
    "resolution": "- Ensure `recovery.conf` (or `postgresql.conf` in newer versions) is correctly configured for recovery.\n- Verify the standby was started in recovery mode.\n- If the standby was promoted, it is no longer a standby and should be treated as a primary."
  },
  {
    "title": "FATAL: could not write to file \"pg_xlog/archive_status/000000010000000000000001.ready\": No space left on device (Instance 99)",
    "description": "The primary cannot mark a WAL segment as ready for archiving due to full disk space in the archive status directory.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files.",
    "resolution": "- Free up disk space on the primary server.\n- Check the status of `archive_command` and ensure it is successfully moving WAL files to the archive location.\n- Investigate the archive destination for space issues."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 100)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 101)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 102)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 103)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 104)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 105)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 106)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 107)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 108)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 109)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 110)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 111)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 112)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 113)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 114)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "Replication Lag (Instance 115)",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found (Instance 116)",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly (Instance 117)",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist (Instance 118)",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots (Instance 119)",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 120)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 121)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory (Instance 122)",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  },
  {
    "title": "FATAL: could not load primary's timeline history file \"00000001.history\": No such file or directory (Instance 123)",
    "description": "The standby is missing a timeline history file from the primary, indicating a divergence in WAL history.",
    "common_causes": "Manual intervention on WAL, primary's WAL archive incomplete, standby pointing to wrong timeline.",
    "resolution": "- Re-base the standby from a fresh backup of the primary.\n- Ensure consistent WAL archiving on the primary.\n- Avoid manual manipulation of WAL files."
  },
  {
    "title": "FATAL: standby is not in recovery (Instance 124)",
    "description": "A command or connection requiring the standby to be in recovery mode was attempted, but it is not.",
    "common_causes": "`recovery_target_timeline` or `recovery_target_xid` not set correctly, standby promoted prematurely.",
    "resolution": "- Ensure `recovery.conf` (or `postgresql.conf` in newer versions) is correctly configured for recovery.\n- Verify the standby was started in recovery mode.\n- If the standby was promoted, it is no longer a standby and should be treated as a primary."
  },
  {
    "title": "FATAL: could not write to file \"pg_xlog/archive_status/000000010000000000000001.ready\": No space left on device (Instance 125)",
    "description": "The primary cannot mark a WAL segment as ready for archiving due to full disk space in the archive status directory.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files.",
    "resolution": "- Free up disk space on the primary server.\n- Check the status of `archive_command` and ensure it is successfully moving WAL files to the archive location.\n- Investigate the archive destination for space issues."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 126)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 127)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 128)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 129)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 130)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 131)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 132)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 133)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 134)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 135)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 136)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 137)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 138)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 139)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 140)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "Replication Lag (Instance 141)",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found (Instance 142)",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly (Instance 143)",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist (Instance 144)",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots (Instance 145)",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 146)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 147)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory (Instance 148)",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  },
  {
    "title": "FATAL: could not load primary's timeline history file \"00000001.history\": No such file or directory (Instance 149)",
    "description": "The standby is missing a timeline history file from the primary, indicating a divergence in WAL history.",
    "common_causes": "Manual intervention on WAL, primary's WAL archive incomplete, standby pointing to wrong timeline.",
    "resolution": "- Re-base the standby from a fresh backup of the primary.\n- Ensure consistent WAL archiving on the primary.\n- Avoid manual manipulation of WAL files."
  },
  {
    "title": "FATAL: standby is not in recovery (Instance 150)",
    "description": "A command or connection requiring the standby to be in recovery mode was attempted, but it is not.",
    "common_causes": "`recovery_target_timeline` or `recovery_target_xid` not set correctly, standby promoted prematurely.",
    "resolution": "- Ensure `recovery.conf` (or `postgresql.conf` in newer versions) is correctly configured for recovery.\n- Verify the standby was started in recovery mode.\n- If the standby was promoted, it is no longer a standby and should be treated as a primary."
  },
  {
    "title": "FATAL: could not write to file \"pg_xlog/archive_status/000000010000000000000001.ready\": No space left on device (Instance 151)",
    "description": "The primary cannot mark a WAL segment as ready for archiving due to full disk space in the archive status directory.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files.",
    "resolution": "- Free up disk space on the primary server.\n- Check the status of `archive_command` and ensure it is successfully moving WAL files to the archive location.\n- Investigate the archive destination for space issues."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 152)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 153)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 154)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 155)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 156)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 157)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 158)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 159)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 160)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 161)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 162)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 163)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 164)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 165)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 166)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "Replication Lag (Instance 167)",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found (Instance 168)",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly (Instance 169)",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist (Instance 170)",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots (Instance 171)",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 172)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 173)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory (Instance 174)",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  },
  {
    "title": "FATAL: could not load primary's timeline history file \"00000001.history\": No such file or directory (Instance 175)",
    "description": "The standby is missing a timeline history file from the primary, indicating a divergence in WAL history.",
    "common_causes": "Manual intervention on WAL, primary's WAL archive incomplete, standby pointing to wrong timeline.",
    "resolution": "- Re-base the standby from a fresh backup of the primary.\n- Ensure consistent WAL archiving on the primary.\n- Avoid manual manipulation of WAL files."
  },
  {
    "title": "FATAL: standby is not in recovery (Instance 176)",
    "description": "A command or connection requiring the standby to be in recovery mode was attempted, but it is not.",
    "common_causes": "`recovery_target_timeline` or `recovery_target_xid` not set correctly, standby promoted prematurely.",
    "resolution": "- Ensure `recovery.conf` (or `postgresql.conf` in newer versions) is correctly configured for recovery.\n- Verify the standby was started in recovery mode.\n- If the standby was promoted, it is no longer a standby and should be treated as a primary."
  },
  {
    "title": "FATAL: could not write to file \"pg_xlog/archive_status/000000010000000000000001.ready\": No space left on device (Instance 177)",
    "description": "The primary cannot mark a WAL segment as ready for archiving due to full disk space in the archive status directory.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files.",
    "resolution": "- Free up disk space on the primary server.\n- Check the status of `archive_command` and ensure it is successfully moving WAL files to the archive location.\n- Investigate the archive destination for space issues."
  },
  {
    "title": "FATAL: archive command failed with exit code 1 (Instance 178)",
    "description": "The `archive_command` configured in `postgresql.conf` exited with a non-zero status, indicating a failure to archive a WAL segment.",
    "common_causes": "Incorrect `archive_command` script, permissions issues, network problems to archive destination, disk full at destination.",
    "resolution": "- Debug the `archive_command` script (run it manually to see errors).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive destination.\n- Verify network connectivity to the archive target.\n- Ensure there is enough disk space at the archive destination."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" does not exist (Instance 179)",
    "description": "A standby or logical decoding client tried to use a replication slot that does not exist.",
    "common_causes": "Typo in slot name, slot was dropped, slot not created on primary.",
    "resolution": "- Verify the replication slot name.\n- Create the replication slot on the primary if it's missing: `SELECT pg_create_physical_replication_slot('my_slot');` (for physical) or `SELECT pg_create_logical_replication_slot('my_slot', 'pgoutput');` (for logical).\n- Ensure the client is configured to use the correct slot."
  },
  {
    "title": "FATAL: replication slot \"my_slot\" is already in use (Instance 180)",
    "description": "A replication slot is already being used by another standby or logical decoding client.",
    "common_causes": "Multiple clients attempting to use the same slot, previous client session not properly closed.",
    "resolution": "- Ensure only one client is using a given replication slot at a time.\n- Check `pg_stat_replication` and `pg_replication_slots` to see which PID is holding the slot.\n- If an old session is stuck, terminate it (with caution)."
  },
  {
    "title": "FATAL: could not write to WAL file \"pg_wal/000000010000000000000001\": No space left on device (Instance 181)",
    "description": "The primary server cannot write new WAL records due to full disk space in the `pg_wal` directory.",
    "common_causes": "Disk full on the primary, `archive_command` failing to move WAL files, `wal_segment_size` too large.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Check `archive_command` status.\n- Consider reducing `wal_segment_size` (requires `initdb` for existing clusters, or a base backup for replicas)."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 182)",
    "description": "PostgreSQL cannot access a WAL file due to incorrect file permissions.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 183)",
    "description": "A WAL file expected by PostgreSQL (primary or standby) is missing.",
    "common_causes": "Accidental deletion of WAL files, disk corruption, incorrect `restore_command`.",
    "resolution": "- If on primary, check for recent disk issues or accidental deletions.\n- If on standby, ensure `restore_command` is correctly retrieving WAL files from the archive.\n- Re-base the standby from a fresh backup if files are irrecoverable."
  },
  {
    "title": "FATAL: terminating walreceiver due to administrator command (Instance 184)",
    "description": "The WAL receiver process on a standby was terminated by an explicit administrator command (e.g., `pg_ctl promote`).",
    "common_causes": "Standby promotion, manual termination for troubleshooting.",
    "resolution": "- This is often an expected message during a failover or manual intervention.\n- If unexpected, investigate who issued the command."
  },
  {
    "title": "FATAL: terminating connection due to timeout (Instance 185)",
    "description": "A replication connection was terminated because it was idle for too long, exceeding `wal_sender_timeout`.",
    "common_causes": "Network latency, primary not sending WAL data fast enough, standby not requesting WAL fast enough, low `wal_sender_timeout`.",
    "resolution": "- Increase `wal_sender_timeout` on the primary (with caution).\n- Investigate network performance between primary and standby.\n- Check standby's I/O and CPU for bottlenecks that slow down WAL application."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: too many connections for role \"replication_user\" (Instance 186)",
    "description": "The replication user on the primary has exceeded its `CONNECTION LIMIT` or the global `max_connections`.",
    "common_causes": "Too many standby servers, `replication_user` has a low `CONNECTION LIMIT`, `max_connections` too low.",
    "resolution": "- Increase `CONNECTION LIMIT` for the replication user: `ALTER ROLE replication_user CONNECTION LIMIT -1;` (for unlimited) or a higher number.\n- Increase `max_connections` in `postgresql.conf` on the primary (requires restart).\n- Review number of active standby connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: no pg_hba.conf entry for replication connection from host \"[IP]\" (Instance 187)",
    "description": "The primary's `pg_hba.conf` does not allow replication connections from the standby's IP address.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry for replication.",
    "resolution": "- Add a specific `pg_hba.conf` entry on the primary for the standby's IP and replication user (e.g., `host replication rep_user [standby_ip]/32 scram-sha-256`).\n- Reload PostgreSQL configuration."
  },
  {
    "title": "FATAL: could not connect to the primary server: FATAL: password authentication failed for user \"replication_user\" (Instance 188)",
    "description": "The standby provided an incorrect password for the replication user on the primary.",
    "common_causes": "Incorrect password in `primary_conninfo`, password changed on primary but not updated on standby.",
    "resolution": "- Verify and correct the password in `primary_conninfo` on the standby.\n- Ensure the replication user's password on the primary is correct."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The server's system identifier differs from the standby's. (Instance 189)",
    "description": "The standby is trying to replicate from a primary that has a different system identifier, meaning they are not from the same base backup.",
    "common_causes": "Standby created from a different primary, primary rebuilt from scratch, corrupted system identifier.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `pg_basebackup` is used correctly to create standbys."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: This standby cannot be used for streaming replication because it has a different timeline. (Instance 190)",
    "description": "The standby's timeline has diverged from the primary's, often due to a previous promotion or manual WAL application.",
    "common_causes": "Standby was promoted and then demoted, or manual WAL recovery was performed, leading to a new timeline.",
    "resolution": "- Re-base the standby from a fresh base backup of the current primary.\n- Ensure `recovery_target_timeline` is set correctly if attempting to follow a specific timeline."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: WAL streaming is not enabled. (Instance 191)",
    "description": "The primary server is not configured to allow streaming replication.",
    "common_causes": "`wal_level` is not `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- Set `wal_level = replica` (or `logical`) in `postgresql.conf` on the primary.\n- Set `max_wal_senders` to a non-zero value (e.g., 10) on the primary.\n- Restart the primary server."
  },
  {
    "title": "FATAL: could not connect to the primary server: DETAIL: The standby's data directory contains a `recovery.signal` file but not a `standby.signal` file. (Instance 192)",
    "description": "The standby is in a mixed state, indicating an incomplete or incorrect configuration for streaming replication.",
    "common_causes": "Manual file manipulation, incorrect `pg_basebackup` usage, partial promotion/demotion.",
    "resolution": "- Ensure the standby's data directory contains either `standby.signal` (for streaming) or no signal file (for a primary).\n- If it's intended to be a streaming standby, ensure `standby.signal` exists and `recovery.signal` does not.\n- Re-base from a fresh backup if configuration is complex."
  },
  {
    "title": "Replication Lag (Instance 193)",
    "description": "The standby server is falling behind the primary, indicating data inconsistency.",
    "common_causes": "Network bandwidth limitations, insufficient I/O capacity on standby, primary generating too much WAL, slow `restore_command`.",
    "resolution": "- Monitor replication lag using `pg_stat_replication`.\n- Check network bandwidth between primary and standby.\n- Ensure standby server has sufficient I/O capacity.\n- Tune `wal_level`, `max_wal_senders`, and `wal_keep_segments` on primary.\n- Tune `restore_command` or `primary_conninfo` on standby."
  },
  {
    "title": "WAL File Not Found (Instance 194)",
    "description": "The standby server cannot find a required WAL segment to continue replication.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small on primary, archive command failure, network issues preventing WAL transfer.",
    "resolution": "- Verify `wal_keep_segments` (or `wal_keep_size` in newer versions) on the primary is large enough.\n- Check archive command on primary is working correctly.\n- Manually copy missing WAL files or re-base the standby from a fresh backup."
  },
  {
    "title": "Standby Crashes Unexpectedly (Instance 195)",
    "description": "The replication standby server is crashing or restarting frequently.",
    "common_causes": "Resource exhaustion (memory, disk), data corruption on standby, issues with replication slot, software bugs.",
    "resolution": "- Review PostgreSQL logs on the standby for error messages.\n- Check system resources (memory, disk space) on the standby.\n- Verify consistency of data directory and WAL files.\n- If using a replication slot, ensure it is not causing issues."
  },
  {
    "title": "Could not connect to primary: FATAL: database \"replication\" does not exist (Instance 196)",
    "description": "The standby is trying to connect to a non-existent 'replication' database on the primary, or the primary's `pg_hba.conf` is misconfigured.",
    "common_causes": "Typo in `primary_conninfo`, `pg_hba.conf` on primary not allowing 'replication' database connections.",
    "resolution": "- Ensure `primary_conninfo` specifies a valid database (often `postgres` or the actual database being replicated).\n- Verify `pg_hba.conf` on the primary has an entry for the replication user and database (e.g., `host replication rep_user 0.0.0.0/0 scram-sha-256`)."
  },
  {
    "title": "FATAL: too many replication slots (Instance 197)",
    "description": "The number of active replication slots has exceeded the `max_replication_slots` limit.",
    "common_causes": "`max_replication_slots` is set too low, orphaned replication slots, excessive number of logical decoders.",
    "resolution": "- Increase `max_replication_slots` in `postgresql.conf` (requires restart).\n- Identify and drop unused or orphaned replication slots using `pg_drop_replication_slot()`.\n- Review logical decoding setup if applicable."
  },
  {
    "title": "FATAL: could not receive data from WAL stream: ERROR: requested WAL segment has already been removed (Instance 198)",
    "description": "The standby tried to fetch a WAL segment that is no longer available on the primary or in the archive.",
    "common_causes": "`wal_keep_segments` (or `wal_keep_size`) too small, archive recovery not keeping up, network interruption.",
    "resolution": "- Increase `wal_keep_segments` (or `wal_keep_size`) on the primary.\n- Improve network stability and throughput between primary and standby.\n- If archive recovery is used, ensure the archive is complete and accessible.\n- Re-base the standby from a fresh backup if the gap is too large."
  },
  {
    "title": "FATAL: could not send data to client: Broken pipe (Instance 199)",
    "description": "The primary server lost its connection to a standby, often due to network issues or standby termination.",
    "common_causes": "Network instability, standby server crash/shutdown, firewall issues.",
    "resolution": "- Check network connectivity between primary and standby.\n- Review standby server logs for reasons for disconnection.\n- Verify firewall rules are not prematurely closing connections."
  },
  {
    "title": "FATAL: could not connect to the primary server: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed: No such file or directory (Instance 200)",
    "description": "The standby cannot find the primary server's Unix domain socket, indicating the primary is not running or misconfigured for local connections.",
    "common_causes": "Primary server not running, incorrect `unix_socket_directories` on primary, `primary_conninfo` using wrong connection method.",
    "resolution": "- Ensure the primary server is running.\n- Verify `unix_socket_directories` in primary's `postgresql.conf`.\n- Adjust `primary_conninfo` to use TCP/IP if Unix sockets are not intended for replication."
  }
                ]
            },
            'backup-recovery': {
                title: "Backup & Recovery",
                intro: "Common problems encountered during database backup and recovery operations.",
                issues: [{
    "title": "pg_basebackup: could not connect to server",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\"",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\"",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 21)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 22)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 23)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 24)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 25)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 26)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 27)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 28)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 29)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 30)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 31)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 32)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 33)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 34)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 35)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 36)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 37)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 38)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 39)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 40)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 41)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 42)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 43)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 44)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 45)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 46)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 47)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 48)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 49)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 50)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 51)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 52)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 53)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 54)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 55)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 56)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 57)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 58)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 59)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 60)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 61)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 62)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 63)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 64)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 65)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 66)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 67)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 68)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 69)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 70)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 71)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 72)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 73)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 74)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 75)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 76)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 77)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 78)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 79)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 80)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 81)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 82)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 83)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 84)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 85)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 86)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 87)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 88)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 89)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 90)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 91)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 92)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 93)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 94)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 95)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 96)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 97)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 98)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 99)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 100)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 101)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 102)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 103)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 104)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 105)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 106)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 107)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 108)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 109)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 110)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 111)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 112)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 113)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 114)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 115)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 116)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 117)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 118)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 119)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 120)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 121)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 122)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 123)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 124)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 125)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 126)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 127)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 128)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 129)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 130)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 131)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 132)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 133)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 134)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 135)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 136)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 137)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 138)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 139)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 140)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 141)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 142)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 143)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 144)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 145)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 146)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 147)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 148)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 149)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 150)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 151)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 152)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 153)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 154)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 155)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 156)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 157)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 158)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 159)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 160)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 161)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 162)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 163)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 164)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 165)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 166)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 167)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 168)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 169)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 170)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 171)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 172)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 173)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 174)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 175)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 176)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 177)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 178)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 179)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 180)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  },
  {
    "title": "pg_basebackup: could not connect to server (Instance 181)",
    "description": "The `pg_basebackup` utility failed to establish a connection to the PostgreSQL primary server.",
    "common_causes": "Primary server not running, incorrect host/port, firewall blocking connection, incorrect `pg_hba.conf` entry on primary.",
    "resolution": "- Verify the primary PostgreSQL server is running.\n- Double-check the host and port in the `pg_basebackup` command.\n- Check firewall rules on both primary and backup servers.\n- Ensure `pg_hba.conf` on the primary allows replication connections from the backup server's IP."
  },
  {
    "title": "pg_basebackup: FATAL: replication user 'backup_user' authentication failed (Instance 182)",
    "description": "The `pg_basebackup` command failed because the provided username or password for the replication user was incorrect.",
    "common_causes": "Typo in username/password, incorrect password in connection string, user not created or lacks replication privileges.",
    "resolution": "- Verify the username and password used in `pg_basebackup`.\n- Ensure the `backup_user` exists and has `REPLICATION` privilege: `CREATE ROLE backup_user WITH LOGIN REPLICATION PASSWORD 'your_password';`."
  },
  {
    "title": "pg_basebackup: could not write to file: No space left on device (Instance 183)",
    "description": "The `pg_basebackup` operation failed because the destination disk for the backup ran out of space.",
    "common_causes": "Insufficient disk space on the backup target, estimated backup size underestimated.",
    "resolution": "- Free up disk space on the target volume.\n- Provide a larger disk or a different target location.\n- Monitor disk usage regularly."
  },
  {
    "title": "pg_basebackup: FATAL: WAL streaming is not enabled (Instance 184)",
    "description": "The primary server is not configured to allow streaming replication, which `pg_basebackup` relies on for consistent backups.",
    "common_causes": "`wal_level` is not set to `replica` (or higher) on the primary, `max_wal_senders` is 0.",
    "resolution": "- On the primary, set `wal_level = replica` (or `logical`) and `max_wal_senders` to a non-zero value (e.g., 5) in `postgresql.conf`.\n- Restart the primary PostgreSQL server for changes to take effect."
  },
  {
    "title": "pg_dump: permission denied for database \"my_db\" (Instance 185)",
    "description": "The user attempting to run `pg_dump` does not have sufficient privileges to access or dump the specified database.",
    "common_causes": "User lacks `CONNECT` privilege on the database, or `SELECT` privilege on tables.",
    "resolution": "- Grant `CONNECT` privilege to the user on the database: `GRANT CONNECT ON DATABASE my_db TO dump_user;`.\n- Grant `SELECT` privileges on relevant tables/schemas or use a superuser role for dumping."
  },
  {
    "title": "pg_dump: database \"non_existent_db\" does not exist (Instance 186)",
    "description": "The `pg_dump` command specified a database name that does not exist on the server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance.",
    "resolution": "- Verify the database name.\n- Ensure you are connected to the correct PostgreSQL server instance."
  },
  {
    "title": "pg_restore: FATAL: role \"old_user\" does not exist (Instance 187)",
    "description": "During `pg_restore`, a role (user) referenced in the backup file does not exist on the target database, and the `--no-owner` or `--no-privileges` flags were not used.",
    "common_causes": "Missing roles on target, restoring to a new environment without pre-creating users.",
    "resolution": "- Pre-create the necessary roles on the target database before restoring.\n- Use `pg_dump --no-owner --no-privileges` when creating the backup if ownership/privileges are not to be preserved.\n- Use `pg_restore --no-owner --no-privileges` during restore."
  },
  {
    "title": "pg_restore: ERROR: relation \"public.my_table\" already exists (Instance 188)",
    "description": "During `pg_restore`, an object (e.g., table, index) from the backup already exists in the target database.",
    "common_causes": "Restoring into a non-empty database, previous restore attempt failed mid-way.",
    "resolution": "- Drop the existing database or use a fresh, empty database for the restore.\n- Use `pg_restore --clean` to drop existing objects before recreating them (use with caution on production)."
  },
  {
    "title": "pg_restore: [archiver (db)] could not read from input file: end of file (Instance 189)",
    "description": "The `pg_restore` utility encountered an unexpected end of the backup file, indicating a truncated or corrupted dump.",
    "common_causes": "Incomplete backup file, corrupted storage, network transfer issues during backup.",
    "resolution": "- Verify the integrity of the backup file.\n- Re-create the backup if it's corrupted or incomplete.\n- Check storage and network for issues during backup creation."
  },
  {
    "title": "archive command failed with exit code 1 (Instance 190)",
    "description": "The `archive_command` configured in `postgresql.conf` failed to execute successfully, preventing WAL segments from being archived.",
    "common_causes": "Incorrect script path, permissions issues, disk full at archive destination, network problems to archive target.",
    "resolution": "- Debug the `archive_command` script (run it manually as the PostgreSQL user).\n- Check permissions for the PostgreSQL user to execute the command and write to the archive directory.\n- Ensure sufficient disk space at the archive destination.\n- Verify network connectivity to the archive target."
  },
  {
    "title": "could not write to file \"pg_wal/archive_status/000000010000000000000001.ready\": No space left on device (Instance 191)",
    "description": "PostgreSQL cannot mark a WAL segment as ready for archiving because the `pg_wal/archive_status` directory is full.",
    "common_causes": "Disk full on the primary's data directory, `archive_command` failing to move files out of the archive queue.",
    "resolution": "- Free up disk space on the primary server's data volume.\n- Investigate why the `archive_command` is failing or slow to move WAL files."
  },
  {
    "title": "FATAL: could not open shared memory segment: No space left on device (Instance 192)",
    "description": "PostgreSQL failed to allocate necessary shared memory during startup, often preventing recovery or normal operation.",
    "common_causes": "System's shared memory limits (`shmmax`, `shmall`) are too low, or actual physical memory is exhausted.",
    "resolution": "- Increase kernel parameters `shmmax` and `shmall` in `/etc/sysctl.conf` and apply changes (`sysctl -p`).\n- Check system memory usage (`free -h`).\n- Restart PostgreSQL."
  },
  {
    "title": "FATAL: could not create lock file \"/var/lib/postgresql/data/postmaster.pid\": Permission denied (Instance 193)",
    "description": "PostgreSQL cannot create its PID file in the data directory, preventing startup or recovery.",
    "common_causes": "Incorrect permissions or ownership on the data directory for the PostgreSQL user.",
    "resolution": "- Ensure the PostgreSQL user (`postgres`) has write permissions to the data directory (`/var/lib/postgresql/data`).\n- Correct ownership: `chown -R postgres:postgres /var/lib/postgresql/data`.\n- Correct permissions: `chmod -R 0700 /var/lib/postgresql/data`."
  },
  {
    "title": "FATAL: could not access private key file \"server.key\": Permission denied (Instance 194)",
    "description": "PostgreSQL cannot read the SSL private key file, which can prevent startup if SSL is required.",
    "common_causes": "Incorrect file permissions or ownership for the SSL key file.",
    "resolution": "- Ensure `server.key` is owned by the PostgreSQL user and has strict permissions (`chmod 0600 server.key`)."
  },
  {
    "title": "FATAL: could not load server certificate file \"server.crt\": No such file or directory (Instance 195)",
    "description": "PostgreSQL cannot find the SSL certificate file, preventing startup if SSL is required.",
    "common_causes": "Incorrect path to `server.crt` in `postgresql.conf`, file missing or moved.",
    "resolution": "- Verify the `ssl_cert_file` path in `postgresql.conf` and ensure `server.crt` exists at that location."
  },
  {
    "title": "FATAL: could not open file \"pg_wal/000000010000000000000001\": Permission denied (Instance 196)",
    "description": "During recovery or normal operation, PostgreSQL cannot read or write to a WAL file due to permission issues.",
    "common_causes": "Manual file operations changing permissions, incorrect ownership on `pg_wal` directory.",
    "resolution": "- Change ownership of the `pg_wal` directory and its contents to the PostgreSQL user (`chown -R postgres:postgres /path/to/data/pg_wal`).\n- Ensure correct permissions (`chmod -R 0700 /path/to/data/pg_wal`)."
  },
  {
    "title": "FATAL: could not stat file \"pg_wal/000000010000000000000001\": No such file or directory (Instance 197)",
    "description": "During recovery, PostgreSQL attempted to find a specific WAL file but it was missing from `pg_wal` or the archive.",
    "common_causes": "Missing WAL segments in archive, `restore_command` failure, accidental deletion of WAL files.",
    "resolution": "- Verify the `restore_command` is correctly configured and working.\n- Ensure all necessary WAL segments are present in the archive location.\n- If WAL files are truly lost, a new base backup might be required."
  },
  {
    "title": "FATAL: checksum mismatch in file \"base/16384/12345\" (Instance 198)",
    "description": "PostgreSQL detected a data corruption where the stored checksum for a block does not match the computed checksum.",
    "common_causes": "Hardware failure (disk, memory), file system corruption, software bug, incorrect data transfer.",
    "resolution": "- This indicates data corruption. If it's a standby, re-base it from the primary.\n- If on a primary, attempt recovery from the most recent good backup.\n- Check underlying hardware and file system for issues."
  },
  {
    "title": "FATAL: database system is in recovery mode (Instance 199)",
    "description": "A connection attempt was made to a PostgreSQL instance that is currently performing crash recovery or is a standby server.",
    "common_causes": "Attempting to connect to a server that is still starting up after a crash or a newly configured standby.",
    "resolution": "- Wait for the PostgreSQL server to complete its recovery process.\n- If it's a standby, ensure your application knows it's read-only or connect to the primary."
  },
  {
    "title": "FATAL: archive_mode must be enabled in postgresql.conf (Instance 200)",
    "description": "WAL archiving is required (e.g., for `pg_basebackup` or point-in-time recovery), but `archive_mode` is not enabled on the primary.",
    "common_causes": "`archive_mode` is set to `off` or `always` is not set when needed.",
    "resolution": "- Set `archive_mode = on` (or `always`) in `postgresql.conf` on the primary.\n- Restart the primary PostgreSQL server."
  }
]

            },
            'performance-optimization': {
                title: "Performance Optimization Issues",
                intro: "Solutions for general database performance bottlenecks, including resource utilization and configuration.",
                issues: 
                [
  {
    "title": "Slow Query Performance",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 11)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 12)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 13)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 14)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 15)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 16)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 17)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 18)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 19)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 20)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 21)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 22)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 23)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 24)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 25)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 26)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 27)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 28)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 29)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 30)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 31)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 32)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 33)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 34)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 35)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 36)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 37)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 38)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 39)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 40)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 41)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 42)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 43)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 44)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 45)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 46)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 47)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 48)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 49)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 50)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 51)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 52)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 53)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 54)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 55)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 56)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 57)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 58)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 59)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 60)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 61)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 62)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 63)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 64)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 65)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 66)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 67)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 68)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 69)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 70)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 71)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 72)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 73)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 74)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 75)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 76)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 77)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 78)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 79)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 80)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 81)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 82)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 83)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 84)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 85)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 86)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 87)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 88)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 89)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 90)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 91)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 92)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 93)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 94)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 95)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 96)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 97)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 98)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 99)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 100)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 101)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 102)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 103)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 104)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 105)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 106)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 107)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 108)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 109)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 110)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 111)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 112)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 113)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 114)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 115)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 116)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 117)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 118)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 119)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 120)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 121)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 122)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 123)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 124)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 125)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 126)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 127)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 128)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 129)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 130)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 131)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 132)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 133)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 134)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 135)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 136)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 137)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 138)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 139)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 140)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 141)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 142)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 143)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 144)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 145)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 146)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 147)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 148)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 149)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 150)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 151)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 152)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 153)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 154)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 155)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 156)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 157)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 158)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 159)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 160)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 161)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 162)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 163)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 164)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 165)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 166)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 167)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 168)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 169)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 170)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 171)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 172)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 173)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 174)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 175)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 176)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 177)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 178)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 179)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 180)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 181)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 182)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 183)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 184)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 185)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 186)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 187)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 188)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 189)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 190)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 191)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 192)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 193)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 194)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 195)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 196)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 197)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 198)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 199)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 200)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  }]
            },
            'performance-optimization': {
                title: "Performance Optimization",
                intro: "Issues and solutions related to slow queries, high resource usage, and general performance tuning.",
                issues: [
                 {
    "title": "Slow Query Performance",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 11)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 12)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 13)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 14)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 15)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 16)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 17)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 18)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 19)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 20)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 21)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 22)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 23)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 24)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 25)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 26)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 27)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 28)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 29)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 30)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 31)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 32)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 33)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 34)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 35)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 36)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 37)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 38)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 39)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 40)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 41)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 42)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 43)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 44)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 45)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 46)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 47)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 48)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 49)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 50)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 51)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 52)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 53)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 54)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 55)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 56)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 57)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 58)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 59)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 60)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 61)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 62)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 63)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 64)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 65)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 66)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 67)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 68)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 69)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 70)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 71)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 72)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 73)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 74)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 75)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 76)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 77)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 78)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 79)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 80)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 81)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 82)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 83)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 84)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 85)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 86)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 87)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 88)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 89)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 90)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 91)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 92)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 93)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 94)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 95)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 96)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 97)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 98)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 99)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 100)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 101)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 102)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 103)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 104)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 105)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 106)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 107)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 108)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 109)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 110)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 111)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 112)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 113)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 114)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 115)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 116)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 117)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 118)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 119)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 120)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 121)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 122)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 123)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 124)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 125)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 126)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 127)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 128)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 129)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 130)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 131)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 132)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 133)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 134)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 135)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 136)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 137)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 138)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 139)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 140)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 141)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 142)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 143)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 144)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 145)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 146)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 147)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 148)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 149)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 150)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 151)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 152)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 153)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 154)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 155)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 156)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 157)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 158)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 159)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 160)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 161)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 162)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 163)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 164)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 165)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 166)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 167)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 168)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 169)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 170)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 171)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 172)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 173)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 174)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 175)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 176)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 177)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 178)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 179)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 180)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 181)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 182)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 183)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 184)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 185)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 186)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 187)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 188)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 189)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 190)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  },
  {
    "title": "Slow Query Performance (Instance 191)",
    "description": "Queries are taking an unacceptably long time to execute, impacting application responsiveness.",
    "common_causes": "Missing or inefficient indexes, poor query planning, large data sets, high concurrency, inefficient JOINs, lack of `VACUUM`.",
    "resolution": "- Use `EXPLAIN ANALYZE` to understand query plans and identify bottlenecks.\n- Create appropriate indexes (B-tree, hash, GIN, GiST) on frequently queried columns.\n- Rewrite complex queries for better performance.\n- Ensure `autovacuum` is properly configured and running.\n- Consider partitioning large tables."
  },
  {
    "title": "High CPU Usage (Instance 192)",
    "description": "The PostgreSQL server process is consuming a high percentage of CPU resources.",
    "common_causes": "Inefficient queries, high number of concurrent connections, excessive sorting or aggregation, too many active `autovacuum` workers.",
    "resolution": "- Identify and optimize top CPU-consuming queries using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Reduce `max_connections` or implement connection pooling.\n- Tune `work_mem` and `maintenance_work_mem` to allow more operations in memory.\n- Adjust `autovacuum` settings (e.g., `autovacuum_max_workers`)."
  },
  {
    "title": "High I/O Usage (Instance 193)",
    "description": "The PostgreSQL server is performing excessive disk reads and writes, leading to slow performance.",
    "common_causes": "Missing indexes, inefficient table scans, insufficient `shared_buffers`, `temp_buffers`, or `work_mem`, frequent checkpointing, high WAL activity.",
    "resolution": "- Add missing indexes to avoid full table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for large sorts/hashes.\n- Tune `checkpoint_timeout` and `max_wal_size` to reduce checkpoint frequency.\n- Use faster storage (SSD/NVMe)."
  },
  {
    "title": "Insufficient Shared Buffers (Instance 194)",
    "description": "The `shared_buffers` setting is too low, leading to frequent disk I/O for data that could be cached.",
    "common_causes": "`shared_buffers` set to default or a value too small for the workload.",
    "resolution": "- Increase `shared_buffers` in `postgresql.conf` (typically 25% of system RAM, up to a few GB, requires restart).\n- Monitor `pg_stat_bgwriter` for `buffers_backend_fsync` and `buffers_alloc` to gauge effectiveness."
  },
  {
    "title": "Excessive Temporary Files (Instance 195)",
    "description": "PostgreSQL is frequently creating large temporary files on disk for sorting, hashing, or other operations.",
    "common_causes": "Complex queries with large sorts/aggregations, `work_mem` set too low, missing indexes for `ORDER BY` or `GROUP BY` clauses.",
    "resolution": "- Increase `work_mem` in `postgresql.conf` for sessions running large queries (can be set per-session).\n- Add indexes that support `ORDER BY` or `GROUP BY` operations.\n- Optimize queries to reduce the need for large sorts/hashes."
  },
  {
    "title": "Autovacuum Not Keeping Up (Instance 196)",
    "description": "Tables are experiencing bloat (excessive dead tuples) because `autovacuum` is not running frequently enough or effectively.",
    "common_causes": "Aggressive `autovacuum` settings, high update/delete workload, `autovacuum_max_workers` too low, `autovacuum_vacuum_cost_delay` too high.",
    "resolution": "- Monitor table bloat using `pg_stat_all_tables`.\n- Adjust `autovacuum_vacuum_scale_factor` and `autovacuum_vacuum_threshold`.\n- Increase `autovacuum_max_workers`.\n- Decrease `autovacuum_vacuum_cost_delay`.\n- Manually `VACUUM ANALYZE` bloated tables if necessary."
  },
  {
    "title": "Index Bloat (Instance 197)",
    "description": "Indexes are consuming excessive disk space and slowing down queries due to accumulated dead tuples.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not processing indexes effectively, `FILLFACTOR` too high.",
    "resolution": "- Monitor index bloat.\n- Rebuild bloated indexes using `REINDEX CONCURRENTLY`.\n- Adjust `autovacuum` settings for indexes.\n- Consider a lower `FILLFACTOR` for tables with high update activity."
  },
  {
    "title": "Connection Sprawl / Too Many Connections (Instance 198)",
    "description": "Applications are opening and closing too many connections, or holding connections idle, consuming server resources.",
    "common_causes": "Lack of connection pooling in application, `max_connections` set too high, `idle_in_transaction_session_timeout` not set.",
    "resolution": "- Implement a connection pooler (e.g., PgBouncer, application-level pooling).\n- Reduce `max_connections` to a reasonable level.\n- Set `idle_in_transaction_session_timeout` to terminate long-idle transactions."
  },
  {
    "title": "Inefficient Joins (Instance 199)",
    "description": "Queries involving multiple tables are performing poorly due to inefficient join strategies.",
    "common_causes": "Missing indexes on join columns, incorrect join order, outdated statistics, complex `WHERE` clauses.",
    "resolution": "- Create indexes on columns used in `JOIN` conditions.\n- Ensure statistics are up-to-date (`ANALYZE` or `autovacuum`).\n- Review `EXPLAIN ANALYZE` output to understand join methods (Nested Loop, Hash Join, Merge Join) and their costs.\n- Consider rewriting queries or adding hints (with caution) for specific join orders."
  },
  {
    "title": "Outdated Statistics (Instance 200)",
    "description": "The query planner is making suboptimal decisions because the statistics about data distribution are old or inaccurate.",
    "common_causes": "Infrequent `ANALYZE` runs, `autovacuum` not analyzing tables, large data changes without corresponding `ANALYZE`.",
    "resolution": "- Ensure `autovacuum` is configured to run `ANALYZE` regularly.\n- Manually run `ANALYZE` on tables that have undergone significant data changes.\n- Increase `default_statistics_target` for more detailed statistics (at a cost of more space)."
  }
                ]
            },
            'query-indexing': {
                title: "Query & Indexing",
                intro: "Errors and best practices concerning SQL queries, query planning, and index usage.",
                issues: [
                  {
    "title": "Slow Query Execution",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY`",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 11)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 12)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 13)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 14)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 15)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 16)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 17)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 18)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 19)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 20)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 21)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 22)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 23)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 24)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 25)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 26)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 27)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 28)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 29)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 30)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 31)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 32)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 33)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 34)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 35)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 36)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 37)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 38)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 39)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 40)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 41)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 42)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 43)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 44)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 45)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 46)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 47)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 48)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 49)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 50)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 51)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 52)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 53)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 54)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 55)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 56)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 57)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 58)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 59)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 60)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 61)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 62)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 63)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 64)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 65)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 66)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 67)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 68)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 69)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 70)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 71)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 72)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 73)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 74)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 75)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 76)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 77)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 78)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 79)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 80)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 81)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 82)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 83)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 84)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 85)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 86)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 87)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 88)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 89)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 90)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 91)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 92)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 93)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 94)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 95)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 96)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 97)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 98)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 99)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 100)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 101)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 102)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 103)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 104)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 105)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 106)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 107)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 108)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 109)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 110)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 111)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 112)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 113)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 114)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 115)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 116)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 117)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 118)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 119)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 120)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 121)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 122)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 123)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 124)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 125)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 126)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 127)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 128)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 129)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 130)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 131)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 132)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 133)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 134)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 135)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 136)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 137)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 138)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 139)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 140)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 141)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 142)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 143)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 144)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 145)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 146)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 147)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 148)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 149)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 150)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 151)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 152)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 153)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 154)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 155)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 156)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 157)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 158)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 159)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 160)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 161)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 162)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 163)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 164)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 165)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 166)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 167)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 168)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 169)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 170)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 171)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 172)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 173)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 174)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 175)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 176)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 177)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 178)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 179)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 180)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 181)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 182)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 183)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 184)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 185)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 186)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 187)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 188)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 189)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 190)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  },
  {
    "title": "Slow Query Execution (Instance 191)",
    "description": "Queries are taking an excessive amount of time to return results, leading to application performance degradation.",
    "common_causes": "Missing or inappropriate indexes, inefficient query plans, large data sets, high concurrency, table scans instead of index scans, inefficient `JOIN` operations.",
    "resolution": "- Use `EXPLAIN ANALYZE` to inspect the query plan and identify bottlenecks (e.g., full table scans, expensive sorts).\n- Create B-tree indexes on columns used in `WHERE` clauses, `JOIN` conditions, `ORDER BY`, and `GROUP BY`.\n- Consider specialized indexes like GIN for full-text search or GiST for geometric/spatial data.\n- Rewrite complex queries to be more efficient, breaking them into smaller parts if necessary.\n- Ensure `autovacuum` is running regularly to keep table statistics up-to-date and prevent table bloat."
  },
  {
    "title": "Index Not Used (Sequential Scan) (Instance 192)",
    "description": "Despite the presence of an index, PostgreSQL's query planner chooses a sequential scan over an index scan.",
    "common_causes": "Outdated statistics, small table size (planner deems sequential faster), `WHERE` clause conditions not selective enough, data type mismatches, use of functions on indexed columns, `LIKE` patterns starting with a wildcard.",
    "resolution": "- Run `ANALYZE` on the table to update statistics.\n- For small tables, a sequential scan might genuinely be faster; consider if an index is truly needed.\n- Ensure `WHERE` clauses are selective enough (e.g., `> 10%` of rows might trigger sequential scan).\n- Avoid applying functions to indexed columns in `WHERE` clauses (consider functional indexes).\n- Use `LIKE 'prefix%'` for index usage; `LIKE '%suffix'` or `LIKE '%middle%'` typically prevent index use (consider trigram indexes)."
  },
  {
    "title": "Bloated Indexes (Instance 193)",
    "description": "Indexes are consuming significantly more disk space than expected and can lead to slower index scans.",
    "common_causes": "High update/delete activity on indexed columns, `autovacuum` not keeping up with changes, high `FILLFACTOR` on indexes.",
    "resolution": "- Monitor index bloat using `pg_stat_user_indexes` and `pg_relation_size`.\n- Run `REINDEX CONCURRENTLY` on bloated indexes to rebuild them without blocking writes.\n- Adjust `autovacuum` settings (e.g., `autovacuum_vacuum_cost_delay`, `autovacuum_vacuum_scale_factor`) to be more aggressive.\n- Consider lowering `FILLFACTOR` for indexes on highly volatile tables (requires rebuild)."
  },
  {
    "title": "High Disk I/O from Queries (Instance 194)",
    "description": "Queries are causing excessive disk reads and writes, leading to system slowdowns.",
    "common_causes": "Lack of proper indexing, insufficient `shared_buffers` or `work_mem`, frequent full table scans, inefficient query patterns.",
    "resolution": "- Identify queries with high I/O using `pg_stat_statements` or `EXPLAIN ANALYZE`.\n- Implement appropriate indexes to reduce table scans.\n- Increase `shared_buffers` to cache more data in memory.\n- Increase `work_mem` for complex queries that perform large sorts or hash operations to keep them in memory."
  },
  {
    "title": "Inefficient Subqueries or CTEs (Instance 195)",
    "description": "Queries using subqueries or Common Table Expressions (CTEs) are performing poorly.",
    "common_causes": "Subqueries/CTEs not being materialized or optimized as expected by the planner, redundant calculations, lack of proper indexing for intermediate results.",
    "resolution": "- Use `EXPLAIN ANALYZE` to see if subqueries/CTEs are being materialized when not desired, or vice versa.\n- Experiment with `WITH ... AS (MATERIALIZED ...)` or `WITH ... AS (NOT MATERIALIZED ...)` to guide the planner.\n- Rewrite subqueries as `JOIN`s if appropriate, as joins are often more optimized.\n- Ensure indexes are available for conditions within subqueries or CTEs."
  },
  {
    "title": "Full Table Scans on Large Tables (Instance 196)",
    "description": "Queries are performing full scans on large tables, which is very inefficient and slow.",
    "common_causes": "Missing or inappropriate indexes for `WHERE` clause, non-selective `WHERE` conditions, data type mismatches, `OR` conditions preventing index usage.",
    "resolution": "- Create indexes on columns used in `WHERE` clauses.\n- Ensure `WHERE` conditions are selective enough to benefit from an index.\n- Avoid `OR` conditions on different columns; consider `UNION ALL` or separate queries if necessary, or a multi-column index.\n- Cast data types explicitly if there's a mismatch (e.g., `column::text = 'value'`)."
  },
  {
    "title": "Slow `COUNT(*)` on Large Tables (Instance 197)",
    "description": "Counting all rows in a large table is very slow.",
    "common_causes": "PostgreSQL's MVCC architecture requires scanning for visible tuples, no fast path for `COUNT(*)` on dirty tables.",
    "resolution": "- For approximate counts, use `SELECT reltuples FROM pg_class WHERE relname = 'your_table_name';` (less accurate but fast).\n- Maintain a separate counter table updated by triggers (for highly accurate, real-time counts).\n- For specific conditions, ensure indexes are used: `SELECT COUNT(*) FROM your_table WHERE condition;`."
  },
  {
    "title": "Inefficient `ORDER BY` or `GROUP BY` (Instance 198)",
    "description": "Queries with `ORDER BY` or `GROUP BY` clauses are slow, often involving large disk sorts.",
    "common_causes": "Missing indexes on the sorting/grouping columns, `work_mem` too low, complex expressions in `ORDER BY`/`GROUP BY`.",
    "resolution": "- Create composite indexes that include the columns in `ORDER BY` or `GROUP BY` clauses.\n- Increase `work_mem` to allow larger sorts to happen in memory.\n- Simplify expressions in `ORDER BY`/`GROUP BY` or create functional indexes if expressions are common."
  },
  {
    "title": "High `temp_buffers` Usage (Instance 199)",
    "description": "Queries are using a lot of temporary buffers, indicating large temporary files for non-shared data.",
    "common_causes": "Large temporary tables, complex queries requiring significant temporary storage, `temp_buffers` setting is too low.",
    "resolution": "- Increase `temp_buffers` in `postgresql.conf` for sessions that frequently create large temporary tables.\n- Optimize queries to reduce the need for large temporary tables.\n- Consider using `UNLOGGED` tables for temporary data if durability is not critical."
  },
  {
    "title": "Inefficient `LIKE` Queries (Instance 200)",
    "description": "Queries using the `LIKE` operator are slow, especially with leading wildcards.",
    "common_causes": "Inability to use standard B-tree indexes with leading wildcards, lack of appropriate specialized indexes.",
    "resolution": "- For `LIKE 'prefix%'`, ensure a standard B-tree index exists on the column.\n- For `LIKE '%suffix'` or `LIKE '%middle%'`, consider creating a `GIN` or `GiST` index with the `pg_trgm` extension (trigram index).\n- Use `ILIKE` for case-insensitive searches; for performance, ensure a `COLLATE` clause or functional index is used if not using `pg_trgm`."
  }
                ]
            },
            'security-access-control': {
                title: "Security & Access Control",
                intro: "Problems related to user permissions, roles, and securing your PostgreSQL instance.",
                issues: [
                  {
    "title": "FATAL: password authentication failed for user \"username\"",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\"",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\"",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\"",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\"",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\"",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\"",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\"",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\"",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 1)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 2)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 3)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 4)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 5)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 6)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 7)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 8)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 9)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 10)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 11)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 12)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 13)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 14)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 15)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 16)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 17)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 18)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 19)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 20)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 21)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 22)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 23)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 24)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 25)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 26)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 27)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 28)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 29)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 30)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 31)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 32)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 33)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 34)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 35)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 36)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 37)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 38)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 39)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 40)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 41)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 42)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 43)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 44)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 45)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 46)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 47)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 48)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 49)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 50)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 51)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 52)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 53)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 54)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 55)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 56)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 57)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 58)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 59)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 60)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 61)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 62)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 63)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 64)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 65)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 66)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 67)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 68)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 69)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 70)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 71)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 72)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 73)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 74)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 75)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 76)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 77)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 78)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 79)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 80)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 81)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 82)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 83)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 84)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 85)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 86)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 87)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 88)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 89)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 90)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 91)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 92)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 93)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 94)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 95)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 96)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 97)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 98)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 99)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 100)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 101)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 102)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 103)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 104)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 105)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 106)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 107)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 108)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 109)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 110)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 111)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 112)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 113)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 114)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 115)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 116)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 117)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 118)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 119)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 120)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 121)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 122)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 123)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 124)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 125)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 126)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 127)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 128)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 129)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 130)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 131)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 132)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 133)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 134)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 135)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 136)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 137)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 138)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 139)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 140)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 141)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 142)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 143)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 144)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 145)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 146)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 147)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 148)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 149)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 150)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 151)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 152)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 153)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 154)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 155)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 156)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 157)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 158)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 159)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 160)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 161)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 162)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 163)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 164)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 165)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 166)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 167)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 168)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 169)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 170)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 171)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 172)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 173)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 174)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 175)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 176)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 177)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 178)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 179)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 180)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 181)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 182)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 183)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 184)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 185)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 186)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "ERROR: permission denied for schema \"schema_name\" (Instance 187)",
    "description": "The connected user does not have the necessary privileges to access objects within a specific schema.",
    "common_causes": "User not granted `USAGE` privilege on the schema, or `CREATE` privilege if trying to create objects.",
    "resolution": "- Grant `USAGE` privilege on the schema: `GRANT USAGE ON SCHEMA schema_name TO username;`.\n- If the user needs to create objects in the schema: `GRANT CREATE ON SCHEMA schema_name TO username;`."
  },
  {
    "title": "ERROR: permission denied for table \"table_name\" (Instance 188)",
    "description": "The connected user does not have the necessary privileges to perform the requested operation (e.g., `SELECT`, `INSERT`, `UPDATE`, `DELETE`) on a specific table.",
    "common_causes": "User lacks specific DML/DDL privileges on the table.",
    "resolution": "- Grant the required privilege(s) on the table: `GRANT SELECT, INSERT, UPDATE, DELETE ON TABLE table_name TO username;`.\n- For all tables in a schema: `GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO username;` (and for future tables: `ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL PRIVILEGES ON TABLES TO username;`)."
  },
  {
    "title": "ERROR: must be superuser to alter role \"role_name\" (Instance 189)",
    "description": "A non-superuser attempted to modify the attributes of a role (user or group role).",
    "common_causes": "Attempting to change a role's password, privileges, or membership without superuser rights.",
    "resolution": "- Perform the `ALTER ROLE` operation as a PostgreSQL superuser (e.g., `postgres`).\n- Grant the user superuser privileges (use with extreme caution): `ALTER USER username WITH SUPERUSER;`."
  },
  {
    "title": "ERROR: role \"role_name\" does not exist (Instance 190)",
    "description": "A command referenced a role (user or group role) that does not exist in the database system.",
    "common_causes": "Typo in role name, attempting to drop/alter a non-existent role.",
    "resolution": "- Verify the role name is correct.\n- Check existing roles: `\\du` in `psql`.\n- If the role needs to be created: `CREATE ROLE role_name;` or `CREATE USER user_name;`."
  },
  {
    "title": "FATAL: Peer authentication failed for user \"username\" (Instance 191)",
    "description": "When using `peer` authentication, the operating system user attempting to connect does not match the PostgreSQL user.",
    "common_causes": "OS username does not match PostgreSQL username, incorrect `pg_hba.conf` entry for `peer` authentication.",
    "resolution": "- Ensure the operating system user running the client application has the same name as the PostgreSQL user.\n- Alternatively, change the `pg_hba.conf` entry for that connection to a different authentication method (e.g., `md5`, `scram-sha-256`)."
  },
  {
    "title": "FATAL: Ident authentication failed for user \"username\" (Instance 192)",
    "description": "When using `ident` authentication, the ident server reported a different username than the one requested by PostgreSQL.",
    "common_causes": "Ident server misconfiguration, OS username mismatch, `pg_hba.conf` incorrect.",
    "resolution": "- Verify the ident server is correctly configured and running on the client machine.\n- Ensure the OS username matches the PostgreSQL username.\n- Consider switching to `md5` or `scram-sha-256` authentication if `ident` is problematic."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates row-level security policy \"policy_name\" (Instance 193)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row did not satisfy an active Row-Level Security (RLS) policy.",
    "common_causes": "Data being inserted/updated does not meet the criteria defined by the RLS policy for the current user.",
    "resolution": "- Review the RLS policy definition (`ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; CREATE POLICY policy_name ON table_name ...`).\n- Ensure the data being inserted/updated conforms to the policy for the current user.\n- Adjust the RLS policy if it's too restrictive or unintended."
  },
  {
    "title": "ERROR: cannot drop role role_name because other objects depend on it (Instance 194)",
    "description": "Attempting to drop a role (user) that still owns database objects (tables, sequences, functions, etc.).",
    "common_causes": "Role owns objects, role has privileges granted on objects, role is a member of other roles.",
    "resolution": "- Reassign ownership of all objects owned by the role to another role: `REASSIGN OWNED BY old_role TO new_role;`.\n- Revoke all privileges granted by the role: `DROP OWNED BY old_role;`.\n- Then, `DROP ROLE old_role;`."
  },
  {
    "title": "FATAL: SSL connection is required (Instance 195)",
    "description": "The PostgreSQL server is configured to only accept SSL connections, but the client attempted a non-SSL connection.",
    "common_causes": "`ssl = on` and `ssl_prefer_server_ciphers = on` in `postgresql.conf`, and `hostssl` in `pg_hba.conf` without a matching `host` entry.",
    "resolution": "- Configure the client to use SSL for the connection.\n- Or, if not strictly required, adjust `pg_hba.conf` to allow non-SSL connections for specific hosts/users (e.g., add a `host` entry instead of `hostssl`).\n- Or, set `ssl = off` in `postgresql.conf` (not recommended for production)."
  },
  {
    "title": "ERROR: cannot change ownership of table \"table_name\" (Instance 196)",
    "description": "A user attempted to change the owner of a table without sufficient privileges.",
    "common_causes": "Only the superuser, the current owner, or a member of the current owner's role can change ownership.",
    "resolution": "- Log in as the superuser or the current owner of the table.\n- Use `ALTER TABLE table_name OWNER TO new_owner;`."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 197)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "FATAL: no pg_hba.conf entry for host \"[IP_ADDRESS]\", user \"username\", database \"database_name\", SSL off/on (Instance 198)",
    "description": "The PostgreSQL server cannot find a matching entry in its `pg_hba.conf` file to allow a connection from the specified host, user, and database with the given SSL status.",
    "common_causes": "Missing or incorrect `pg_hba.conf` entry, incorrect IP address, wrong database name, incorrect user, or SSL mismatch.",
    "resolution": "- Edit `pg_hba.conf` to add a rule that matches the connection attempt. Example for local access: `host all all 127.0.0.1/32 md5`.\n- For remote access: `host all all 0.0.0.0/0 md5` (for all IPs, use with caution) or `host all all [client_IP]/32 md5`.\n- Ensure the authentication method (e.g., `md5`, `scram-sha-256`, `trust`, `peer`) is appropriate.\n- Verify SSL status (on/off) matches the client's attempt and the `pg_hba.conf` entry."
  },
  {
    "title": "FATAL: database \"database_name\" does not exist (Instance 199)",
    "description": "The client attempted to connect to a database that does not exist on the PostgreSQL server.",
    "common_causes": "Typo in database name, connecting to the wrong PostgreSQL instance, database not yet created.",
    "resolution": "- Verify the database name is correct.\n- Ensure the database exists: `CREATE DATABASE database_name;`.\n- Confirm the client is connecting to the intended PostgreSQL server."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 200)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, user not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  }
                ]
            },
            'data-integrity-consistency': {
                title: "Data Integrity & Consistency",
                intro: "Issues that compromise the integrity or consistency of data within the database.",
                issues: [
                  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\"",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\"",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\"",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 11)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 12)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 13)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 14)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 15)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 16)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 17)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 18)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 19)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 20)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 21)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 22)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 23)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 24)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 25)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 26)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 27)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 28)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 29)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 30)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 31)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 32)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 33)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 34)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 35)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 36)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 37)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 38)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 39)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 40)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 41)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 42)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 43)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 44)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 45)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 46)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 47)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 48)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 49)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 50)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 51)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 52)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 53)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 54)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 55)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 56)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 57)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 58)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 59)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 60)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 61)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 62)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 63)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 64)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 65)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 66)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 67)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 68)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 69)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 70)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 71)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 72)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 73)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 74)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 75)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 76)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 77)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 78)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 79)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 80)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 81)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 82)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 83)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 84)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 85)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 86)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 87)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 88)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 89)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 90)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 91)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 92)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 93)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 94)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 95)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 96)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 97)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 98)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 99)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 100)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 101)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 102)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 103)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 104)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 105)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 106)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 107)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 108)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 109)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 110)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 111)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 112)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 113)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 114)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 115)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 116)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 117)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 118)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 119)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 120)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 121)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 122)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 123)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 124)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 125)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 126)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 127)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 128)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 129)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 130)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 131)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 132)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 133)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 134)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 135)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 136)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 137)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 138)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 139)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 140)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 141)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 142)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 143)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 144)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 145)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 146)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 147)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 148)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 149)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 150)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 151)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 152)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 153)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 154)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 155)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 156)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 157)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 158)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 159)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 160)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 161)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 162)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 163)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 164)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 165)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 166)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 167)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 168)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 169)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 170)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 171)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 172)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 173)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 174)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 175)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 176)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 177)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 178)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 179)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 180)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 181)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 182)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 183)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 184)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 185)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 186)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 187)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 188)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 189)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 190)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  },
  {
    "title": "ERROR: duplicate key value violates unique constraint \"constraint_name\" (Instance 191)",
    "description": "An attempt was made to insert or update a row that would result in a duplicate value in a column (or set of columns) that has a unique constraint.",
    "common_causes": "Attempting to insert a row with an existing primary key or unique key value, concurrent transactions inserting the same value, application logic not checking for uniqueness before insert.",
    "resolution": "- Before inserting, check if the value already exists (`SELECT EXISTS(...)`).\n- For `INSERT` statements, use `INSERT ... ON CONFLICT DO UPDATE` (UPSERT) or `INSERT ... ON CONFLICT DO NOTHING`.\n- Ensure application logic handles concurrent inserts gracefully (e.g., retries).\n- If data is truly duplicated, identify and remove the duplicate entries."
  },
  {
    "title": "ERROR: insert or update on table \"table_name\" violates foreign key constraint \"constraint_name\" (Instance 192)",
    "description": "An attempt to insert or update a row failed because a foreign key value does not exist in the referenced primary/unique key of the parent table.",
    "common_causes": "Referencing a non-existent parent record, incorrect data entry, parent record deleted without CASCADE action, data loading issues.",
    "resolution": "- Ensure the referenced value exists in the parent table before inserting/updating the child table.\n- Check for typos or incorrect data in the foreign key column.\n- If a parent record was deleted, consider using `ON DELETE CASCADE` or `ON DELETE SET NULL` on the foreign key constraint if appropriate for your data model.\n- For bulk data loads, ensure parent data is loaded before child data."
  },
  {
    "title": "ERROR: new row for relation \"table_name\" violates check constraint \"constraint_name\" (Instance 193)",
    "description": "An `INSERT` or `UPDATE` operation was blocked because the new row's data did not satisfy a defined `CHECK` constraint.",
    "common_causes": "Data violating the specified condition (e.g., `price > 0`, `status IN ('active', 'inactive')`).",
    "resolution": "- Review the `CHECK` constraint definition (`ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);`).\n- Correct the data being inserted/updated to comply with the constraint.\n- If the constraint is too restrictive, consider altering or dropping it (with caution)."
  },
  {
    "title": "ERROR: null value in column \"column_name\" violates not-null constraint (Instance 194)",
    "description": "An attempt was made to insert or update a row with a `NULL` value in a column that is defined as `NOT NULL`.",
    "common_causes": "Omitting a required column in an `INSERT` statement, explicitly setting a `NOT NULL` column to `NULL`, or a `DEFAULT` value not being applied correctly.",
    "resolution": "- Provide a non-`NULL` value for the specified column in your `INSERT` or `UPDATE` statement.\n- If the column should allow `NULL`s, alter the table: `ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;`.\n- If a default value is intended, ensure it's defined and the column is omitted from the `INSERT` list for it to apply."
  },
  {
    "title": "ERROR: value too long for type character varying(N) (Instance 195)",
    "description": "An attempt was made to insert a string value that exceeds the maximum length defined for a `VARCHAR(N)` or `CHAR(N)` column.",
    "common_causes": "Inserting data longer than the column's defined capacity, data migration issues.",
    "resolution": "- Truncate the string value to fit within the column's limit before insertion.\n- Increase the column's length if longer values are legitimately expected: `ALTER TABLE table_name ALTER COLUMN column_name TYPE VARCHAR(new_N);`.\n- Consider using `TEXT` type if string length is highly variable and potentially very long (no length limit)."
  },
  {
    "title": "ERROR: invalid input syntax for type integer/numeric/date/timestamp (Instance 196)",
    "description": "An attempt was made to insert or update data with a value that cannot be converted to the target column's data type.",
    "common_causes": "Passing a string to an integer column, incorrect date/time format, non-numeric characters in a numeric field.",
    "resolution": "- Ensure the data being inserted/updated matches the target column's data type.\n- For dates/timestamps, use standard formats (e.g., `YYYY-MM-DD`, `YYYY-MM-DD HH:MI:SS`) or explicitly cast using `TO_DATE()` or `TO_TIMESTAMP()`.\n- For numeric types, ensure only valid numeric characters are provided."
  },
  {
    "title": "ERROR: deadlock detected (Instance 197)",
    "description": "Two or more transactions are waiting for locks held by each other, resulting in a deadlock. PostgreSQL automatically detects and aborts one of the transactions.",
    "common_causes": "Concurrent transactions accessing the same resources in a different order, long-running transactions, unindexed foreign key updates/deletes.",
    "resolution": "- Analyze transaction logs to identify the tables/rows involved in deadlocks.\n- Ensure transactions acquire locks on resources in a consistent order.\n- Keep transactions short and commit/rollback frequently.\n- Add indexes to foreign key columns, especially if they are frequently updated or deleted.\n- Use `SELECT FOR UPDATE` or `FOR SHARE` to explicitly lock rows in a consistent order."
  },
  {
    "title": "ERROR: current transaction is aborted, commands ignored until end of transaction block (Instance 198)",
    "description": "A previous error occurred within the current transaction, causing the transaction to enter an aborted state. Subsequent commands within the same transaction block will be ignored until a `ROLLBACK` or `COMMIT`.",
    "common_causes": "Any SQL error (e.g., constraint violation, syntax error) within a transaction block.",
    "resolution": "- Identify and fix the root cause of the initial error.\n- After an error, explicitly `ROLLBACK` the transaction to clear the aborted state and start a new transaction.\n- Implement proper error handling in your application to catch and manage transaction errors."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 199)",
    "description": "A query or DML statement referenced a table or view that does not exist in the current database or schema.",
    "common_causes": "Typo in table/view name, incorrect schema search path, table not yet created, connecting to the wrong database.",
    "resolution": "- Verify the table/view name is spelled correctly.\n- Check the current schema search path: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the correct database."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 200)",
    "description": "A query or DML statement referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, incorrect table referenced.",
    "resolution": "- Verify the column name is spelled correctly.\n- Check the table definition (`\\d table_name` in `psql`) to confirm the column's existence and spelling.\n- Ensure you are referencing the correct table."
  }
                ]
            },
            'upgrade-migration': {
                title: "Upgrade & Migration",
                intro: "Challenges and solutions when upgrading PostgreSQL versions or migrating data.",
                issues: [
                  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 1)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 2)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 3)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 4)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 5)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 6)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 7)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 8)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 9)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 10)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 11)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 12)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 13)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 14)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 15)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 16)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 17)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 18)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 19)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 20)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 21)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 22)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 23)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 24)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 25)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 26)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 27)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 28)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 29)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 30)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 31)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 32)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 33)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 34)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 35)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 36)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 37)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 38)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 39)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 40)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 41)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 42)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 43)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 44)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 45)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 46)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 47)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 48)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 49)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 50)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 51)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 52)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 53)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 54)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 55)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 56)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 57)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 58)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 59)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 60)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 61)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 62)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 63)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 64)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 65)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 66)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 67)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 68)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 69)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 70)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 71)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 72)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 73)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 74)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 75)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 76)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 77)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 78)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 79)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 80)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 81)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 82)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 83)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 84)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 85)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 86)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 87)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 88)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 89)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 90)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 91)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 92)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 93)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 94)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 95)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 96)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 97)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 98)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 99)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 100)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 101)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 102)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 103)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 104)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 105)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 106)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 107)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 108)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 109)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 110)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 111)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 112)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 113)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 114)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 115)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 116)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 117)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 118)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 119)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 120)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 121)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 122)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 123)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 124)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 125)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 126)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 127)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 128)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 129)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 130)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 131)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 132)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 133)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 134)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 135)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 136)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 137)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 138)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 139)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 140)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 141)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 142)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 143)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 144)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 145)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 146)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 147)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 148)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 149)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 150)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 151)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 152)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 153)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 154)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 155)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 156)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 157)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 158)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 159)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 160)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 161)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 162)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 163)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 164)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 165)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 166)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 167)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 168)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 169)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 170)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 171)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 172)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 173)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 174)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 175)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 176)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 177)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 178)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 179)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 180)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 181)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 182)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 183)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 184)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 185)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 186)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 187)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 188)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 189)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 190)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  },
  {
    "title": "ERROR: old and new cluster cannot share a data directory (Instance 191)",
    "description": "This error occurs during `pg_upgrade` when the old and new PostgreSQL data directories are the same, which is not allowed.",
    "common_causes": "Misconfiguration of `pg_upgrade` command, attempting an in-place upgrade without separate data directories.",
    "resolution": "- Ensure `pg_upgrade` is run with distinct `--old-datadir` and `--new-datadir` paths.\n- If performing an in-place upgrade, ensure you have backed up the old cluster and are moving data to a new, empty directory for the new version."
  },
  {
    "title": "ERROR: database encoding mismatch (Instance 192)",
    "description": "This error indicates that the encoding of a database in the old cluster does not match the encoding expected by the new cluster, or a global encoding issue.",
    "common_causes": "Databases created with different encodings in the old cluster, new cluster initialized with a different default encoding.",
    "resolution": "- Identify databases with different encodings: `SELECT datname, pg_encoding_to_char(encoding) FROM pg_database;`.\n- For `pg_upgrade`, all databases must have compatible encodings. If not, dump and restore individual databases with the correct encoding after the upgrade.\n- Ensure the new cluster's default encoding is set correctly during `initdb` if you want a consistent encoding."
  },
  {
    "title": "ERROR: extension \"extension_name\" is not installed in the new cluster (Instance 193)",
    "description": "An extension used in the old PostgreSQL cluster is not available or installed in the new cluster during an upgrade or restore.",
    "common_causes": "Extension not compiled/installed for the new PostgreSQL version, extension not enabled in `shared_preload_libraries`, or `CREATE EXTENSION` not run.",
    "resolution": "- Install the required extension for the new PostgreSQL version (e.g., via `apt-get`, `yum`, or compiling from source).\n- Ensure the extension is listed in `shared_preload_libraries` in `postgresql.conf` if it's a preload library.\n- Run `CREATE EXTENSION extension_name;` in the relevant databases in the new cluster."
  },
  {
    "title": "ERROR: could not open relation with OID XXXXX (Instance 194)",
    "description": "This low-level error often occurs during `pg_dump` or `pg_restore` if there's data corruption or missing files in the old cluster.",
    "common_causes": "Corrupt data files, missing table/index files, issues with the underlying file system.",
    "resolution": "- Check PostgreSQL logs for more specific errors related to corruption.\n- Run `VACUUM FULL` or `REINDEX` on suspicious tables/indexes in the old cluster.\n- If corruption is severe, you might need to try to recover from a backup or use `pg_dump --data-only` for specific tables to salvage data."
  },
  {
    "title": "FATAL: could not load library \"$libdir/library_name.so\": No such file or directory (Instance 195)",
    "description": "PostgreSQL cannot find a shared library (e.g., an extension or a custom module) that it's configured to load.",
    "common_causes": "Library not copied to the new installation's `lib` directory, `shared_preload_libraries` pointing to a non-existent library, incorrect `LD_LIBRARY_PATH`.",
    "resolution": "- Ensure the `.so` or `.dll` file for the library is correctly placed in the new PostgreSQL installation's `lib` directory or a path included in `dynamic_library_path`.\n- Verify `shared_preload_libraries` in `postgresql.conf` points to existing libraries.\n- Check system `LD_LIBRARY_PATH` or equivalent environment variables if custom paths are used."
  },
  {
    "title": "ERROR: permission denied to create extension \"extension_name\" (Instance 196)",
    "description": "The user attempting to create an extension in the new cluster lacks the necessary privileges.",
    "common_causes": "Non-superuser attempting to create an extension, or the user hasn't been granted `CREATE` privilege on the database.",
    "resolution": "- Connect as a superuser (e.g., `postgres`) to create the extension.\n- Or, grant `CREATE` privilege on the database to the user: `GRANT CREATE ON DATABASE database_name TO username;`.\n- Some extensions also require specific superuser privileges to install."
  },
  {
    "title": "ERROR: column \"column_name\" has type character varying but expression is of type text (Instance 197)",
    "description": "A type mismatch error during data migration (e.g., `pg_restore`) where the source column's data type is not directly compatible with the target column's data type, or implicit casting fails.",
    "common_causes": "Schema changes between old and new versions, manual schema modifications before restore, or `pg_dump` not handling type conversions gracefully.",
    "resolution": "- Adjust the target column's data type in the new schema to match the source (e.g., change `VARCHAR(N)` to `TEXT` if the source is `TEXT` or `VARCHAR` with varying length).\n- If the types are truly incompatible, you might need to transform data during the migration using `COPY` with `FROM STDIN` and custom scripts, or `pg_dump --data-only` and manual `INSERT` statements with explicit casts."
  },
  {
    "title": "FATAL: data directory \"/path/to/data\" has wrong ownership (Instance 198)",
    "description": "The PostgreSQL data directory is not owned by the correct operating system user (typically `postgres`).",
    "common_causes": "Manual file system operations changing ownership, incorrect permissions set during installation or migration.",
    "resolution": "- Change the ownership of the data directory and its contents to the `postgres` user: `sudo chown -R postgres:postgres /path/to/data`.\n- Ensure appropriate permissions (e.g., `700`) are set: `sudo chmod -R 0700 /path/to/data`."
  },
  {
    "title": "ERROR: could not connect to server: Connection refused (Instance 199)",
    "description": "The client (e.g., `pg_upgrade`, `pg_dump`, `psql`) cannot establish a connection to the PostgreSQL server.",
    "common_causes": "Server not running, incorrect host/port, firewall blocking connection, `listen_addresses` not configured correctly, `pg_hba.conf` preventing connection.",
    "resolution": "- Ensure the PostgreSQL server is running.\n- Verify host and port in connection string/command.\n- Check firewall rules on both client and server.\n- In `postgresql.conf`, ensure `listen_addresses` includes the IP address the client is connecting to (e.g., `*` for all interfaces).\n- Check `pg_hba.conf` for appropriate entries allowing the connection."
  },
  {
    "title": "ERROR: schema \"schema_name\" already exists (Instance 200)",
    "description": "During a `pg_restore` operation, the schema being restored already exists in the target database, and the restore command doesn't handle existing objects.",
    "common_causes": "Restoring a dump into a non-empty database, or a schema was manually created before restore.",
    "resolution": "- Drop the existing schema before restoring: `DROP SCHEMA schema_name CASCADE;` (use with caution).\n- Use `pg_restore --clean` to drop existing objects before recreating them (requires `pg_dump --clean` or `pg_dump --create` to be compatible).\n- Restore into an empty database."
  }
                ]
            },
            'troubleshooting-debugging': {
                title: "Troubleshooting & Debugging",
                intro: "General techniques and common pitfalls in diagnosing PostgreSQL problems.",
                issues: [{
    "title": "ERROR: out of shared memory",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 5)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\"",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\"",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\"",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 11)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 12)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 13)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 14)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 15)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 16)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 17)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 18)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 19)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 20)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 21)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 22)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 23)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 24)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 25)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 26)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 27)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 28)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 29)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 30)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 31)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 32)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 33)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 34)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 35)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 36)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 37)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 38)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 39)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 40)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 41)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 42)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 43)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 44)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 45)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 46)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 47)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 48)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 49)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 50)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 51)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 52)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 53)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 54)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 55)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 56)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 57)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 58)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 59)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 60)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 61)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 62)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 63)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 64)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 65)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 66)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 67)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 68)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 69)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 70)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 71)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 72)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 73)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 74)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 75)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 76)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 77)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 78)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 79)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 80)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 81)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 82)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 83)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 84)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 85)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 86)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 87)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 88)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 89)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 90)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 91)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 92)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 93)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 94)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 95)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 96)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 97)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 98)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 99)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 100)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 101)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 102)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 103)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 104)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 105)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 106)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 107)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 108)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 109)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 110)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 111)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 112)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 113)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 114)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 115)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 116)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 117)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 118)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 119)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 120)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 121)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 122)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 123)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 124)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 125)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 126)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 127)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 128)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 129)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 130)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 131)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 132)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 133)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 134)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 135)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 136)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 137)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 138)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 139)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 140)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 141)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 142)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 143)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 144)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 145)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 146)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 147)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 148)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 149)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 150)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 151)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 152)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 153)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 154)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 155)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 156)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 157)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 158)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 159)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 160)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 161)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 162)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 163)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 164)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 165)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 166)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 167)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 168)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 169)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 170)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 171)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 172)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 173)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 174)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 175)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 176)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 177)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 178)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 179)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 180)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 181)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 182)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 183)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 184)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 185)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 186)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 187)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 188)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 189)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 190)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  },
  {
    "title": "ERROR: out of shared memory (Instance 191)",
    "description": "PostgreSQL is unable to allocate enough shared memory for its operations, often leading to server startup failures or query execution issues.",
    "common_causes": "Insufficient `shared_buffers` or `work_mem` settings in `postgresql.conf`, system-level shared memory limits (e.g., `kernel.shmmax`, `kernel.shmall` on Linux) are too low, or too many concurrent connections.",
    "resolution": "- Adjust `shared_buffers` and `work_mem` in `postgresql.conf` to lower values, or increase system shared memory limits if the server has enough RAM.\n- For Linux, increase `kernel.shmmax` and `kernel.shmall` (and `shmmni`) in `/etc/sysctl.conf` and apply with `sudo sysctl -p`.\n- Reduce `max_connections` if too many connections are consuming memory.\n- Restart PostgreSQL after changes."
  },
  {
    "title": "FATAL: remaining connection slots are reserved for non-replication superuser connections (Instance 192)",
    "description": "All regular connection slots are in use, and only superusers can connect to perform administrative tasks.",
    "common_causes": "High number of active connections, `max_connections` setting is too low for the workload, or connection leaks in applications.",
    "resolution": "- Increase `max_connections` in `postgresql.conf` (requires server restart).\n- Identify and terminate idle or long-running connections if they are not needed.\n- Review application connection pooling and ensure connections are properly closed.\n- Connect as a superuser to troubleshoot and manage connections."
  },
  {
    "title": "ERROR: could not access file \"$libdir/library_name.so\": No such file or directory (Instance 193)",
    "description": "PostgreSQL cannot find a specified shared library, often an extension or a custom function library.",
    "common_causes": "Library file is missing, moved, or has incorrect permissions; `dynamic_library_path` or `shared_preload_libraries` configured incorrectly.",
    "resolution": "- Verify the library file (`.so` on Linux, `.dll` on Windows) exists at the specified path (`$libdir` refers to the PostgreSQL library directory).\n- Check permissions to ensure the `postgres` user can read the file.\n- Correct `dynamic_library_path` or `shared_preload_libraries` in `postgresql.conf` if the path is wrong.\n- Reinstall the extension if necessary."
  },
  {
    "title": "LOG: could not receive data from client: Connection reset by peer (Instance 194)",
    "description": "The PostgreSQL server detected that the client abruptly closed the connection without proper shutdown, often due to network issues or client application crashes.",
    "common_causes": "Client application crash, network instability, client-side firewall blocking connections, client timeout before server response.",
    "resolution": "- Investigate the client application logs for errors or crashes.\n- Check network connectivity and stability between the client and server.\n- Review client-side firewall rules.\n- Adjust application timeouts or server `statement_timeout` if long-running queries are being prematurely terminated."
  },
  {
    "title": "LOG: checkpoint complete: wrote X buffers (Y%) in Z seconds (Instance 195)",
    "description": "This is a normal log message indicating a checkpoint completed, but frequent or very long checkpoints can indicate performance issues.",
    "common_causes": "High write activity, `checkpoint_timeout` is too short, `max_wal_size` is too small, or slow I/O subsystem.",
    "resolution": "- If checkpoints are too frequent, increase `checkpoint_timeout` and `max_wal_size` in `postgresql.conf`.\n- Monitor I/O performance of the disk where WAL and data directories reside.\n- Optimize queries and application logic to reduce write amplification."
  },
  {
    "title": "ERROR: relation \"table_name\" does not exist (Instance 196)",
    "description": "A query or command referenced a table that does not exist in the current database or schema.",
    "common_causes": "Typo in table name, incorrect schema search path, table not yet created, or connecting to the wrong database.",
    "resolution": "- Verify the table name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the `search_path` setting: `SHOW search_path;`.\n- Qualify the table name with its schema: `SELECT * FROM schema_name.table_name;`.\n- Ensure the table has been created in the intended database and schema."
  },
  {
    "title": "ERROR: column \"column_name\" does not exist (Instance 197)",
    "description": "A query or command referenced a column that does not exist in the specified table.",
    "common_causes": "Typo in column name, column not added to the table, or referencing the wrong table.",
    "resolution": "- Verify the column name is spelled correctly (case-sensitivity matters in some configurations).\n- Check the table definition using `\\d table_name` in `psql` to confirm the column's existence and spelling.\n- Ensure you are querying the correct table."
  },
  {
    "title": "ERROR: syntax error at or near \"keyword\" (Instance 198)",
    "description": "The SQL query contains a grammatical error, preventing PostgreSQL from parsing it correctly.",
    "common_causes": "Typo, missing comma, incorrect keyword usage, mismatched parentheses, or using a reserved keyword as an identifier without quoting.",
    "resolution": "- Carefully review the SQL statement around the indicated error location.\n- Check for missing commas, parentheses, or incorrect syntax for the specific SQL command.\n- If using a reserved keyword as an identifier, enclose it in double quotes (e.g., `\"user\"`)."
  },
  {
    "title": "ERROR: permission denied for database \"database_name\" (Instance 199)",
    "description": "The connected user does not have the necessary privileges to connect to or access the specified database.",
    "common_causes": "User not granted `CONNECT` privilege on the database, or the user is not a member of a role with access.",
    "resolution": "- Grant `CONNECT` privilege to the user: `GRANT CONNECT ON DATABASE database_name TO username;`.\n- If the user needs more extensive access, consider granting membership to a role with appropriate privileges (e.g., `GRANT role_name TO username;`)."
  },
  {
    "title": "FATAL: password authentication failed for user \"username\" (Instance 200)",
    "description": "The provided password for the specified user is incorrect, preventing successful login.",
    "common_causes": "Incorrect password, typo in password, user does not exist, or `pg_hba.conf` entry is incorrect or too restrictive.",
    "resolution": "- Verify the username and password are correct.\n- Check `pg_hba.conf` on the PostgreSQL server to ensure the correct authentication method is configured for the user and client IP (e.g., `md5`, `scram-sha-256`).\n- If the user doesn't exist, create it: `CREATE USER username WITH PASSWORD 'new_password';`.\n- If the password needs resetting: `ALTER USER username WITH PASSWORD 'new_password';`."
  }]
            },
            'postgresql-architecture': {
                title: "PostgreSQL Architecture",
                intro: "Understanding the core components and processes of PostgreSQL.",
                issues: [
                  {
                        "title": "Logical Architecture",
                        "description": "The logical flow of a query within PostgreSQL follows a distinct lifecycle: Parser -> Planner -> Executor. Each stage plays a crucial role in processing SQL statements and retrieving results.",
                        "common_causes": "N/A",
                        "resolution": `
                            <p><strong class="error-section-title">Explanation:</strong><br>
                            The logical architecture describes how PostgreSQL processes a SQL query from the moment it's received until the results are returned. It involves three main phases:
                            <ul class="list-disc ml-5 space-y-1">
                                <li><strong>Parser:</strong> Takes the raw SQL query string and checks its syntax, converting it into a parse tree (a structured representation of the query).</li>
                                <li><strong>Planner/Optimizer:</strong> This is the "brain" of PostgreSQL. It takes the parse tree and generates the most efficient execution plan for the query. It considers available indexes, table statistics, and various join methods to decide the optimal way to fetch data.</li>
                                <li><strong>Executor:</strong> Once a plan is chosen, the executor carries it out. It interacts with the storage system to retrieve and process data according to the plan, returning the final result set to the client.</li>
                            </ul>
                            </p>
                            <div class="flex justify-center items-center my-4">
                                <svg width="400" height="150" viewBox="0 0 400 150" fill="none" xmlns="http://www.w3.org/2000/svg">
                                    <rect x="20" y="50" width="100" height="50" rx="8" fill="#E6FFFA" stroke="#2D9B91" stroke-width="2"/>
                                    <text x="70" y="80" text-anchor="middle" font-family="Inter, sans-serif" font-size="16" fill="#2B2D42">Parser</text>

                                    <path d="M120 75 H160" stroke="#2D9B91" stroke-width="2" marker-end="url(#arrowhead)"/>
                                    <text x="140" y="65" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#5B6A78">Parse Tree</text>

                                    <rect x="180" y="50" width="100" height="50" rx="8" fill="#E6FFFA" stroke="#2D9B91" stroke-width="2"/>
                                    <text x="230" y="80" text-anchor="middle" font-family="Inter, sans-serif" font-size="16" fill="#2B2D42">Planner</text>

                                    <path d="M280 75 H320" stroke="#2D9B91" stroke-width="2" marker-end="url(#arrowhead)"/>
                                    <text x="300" y="65" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#5B6A78">Execution Plan</text>

                                    <rect x="340" y="50" width="100" height="50" rx="8" fill="#E6FFFA" stroke="#2D9B91" stroke-width="2"/>
                                    <text x="390" y="80" text-anchor="middle" font-family="Inter, sans-serif" font-size="16" fill="#2B2D42">Executor</text>

                                    <defs>
                                        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
                                            <polygon points="0 0, 10 3.5, 0 7" fill="#2D9B91" />
                                        </marker>
                                    </defs>
                                </svg>
                            </div>
                        `
                    },
                    {
                        "title": "Physical Storage",
                        "description": "PostgreSQL manages data on disk using several key components: the data directory, Write-Ahead Log (WAL) files, heap files, and the visibility map. These components ensure data durability, consistency, and efficient access.",
                        "common_causes": "N/A",
                        "resolution": `
                            <p><strong class="error-section-title">Explanation:</strong><br>
                            PostgreSQL's physical storage layer is designed for robustness and performance:
                            <ul class="list-disc ml-5 space-y-1">
                                <li><strong>Data Directory (PGDATA):</strong> This is the root directory where all of a PostgreSQL cluster's data is stored. It contains configuration files (like <code>postgresql.conf</code>, <code>pg_hba.conf</code>), and subdirectories for tablespaces, WAL files, and actual database files.</li>
                                <li><strong>Write-Ahead Log (WAL):</strong> Before any data changes are written to the main data files (heap files), they are first recorded in the WAL. This ensures data integrity and durability; in case of a crash, changes can be recovered from the WAL. It's also fundamental for replication.</li>
                                <li><strong>Heap Files:</strong> These are the actual files where table data (rows or "tuples") are stored. Each table has its own heap file. Due to MVCC, updates and deletes create new versions of rows, which means old versions remain in heap files until <code>VACUUM</code> cleans them up.</li>
                                <li><strong>Visibility Map:</strong> A per-table data structure that tracks which pages in the heap file contain only "all-visible" tuples (tuples visible to all current and future transactions). This helps <code>VACUUM</code> and index-only scans work more efficiently by avoiding unnecessary page scans.</li>
                            </ul>
                            </p>
                            <div class="flex justify-center items-center my-4">
                                <svg width="500" height="200" viewBox="0 0 500 200" fill="none" xmlns="http://www.w3.org/2000/svg">
                                    <!-- Disk Icon -->
                                    <circle cx="250" cy="100" r="80" stroke="#5B6A78" stroke-width="2" fill="#F8F9FA"/>
                                    <circle cx="250" cy="100" r="20" stroke="#5B6A78" stroke-width="2" fill="#E2E8F0"/>
                                    <line x1="170" y1="100" x2="330" y2="100" stroke="#5B6A78" stroke-width="1"/>
                                    <text x="250" y="105" text-anchor="middle" font-family="Inter, sans-serif" font-size="14" fill="#2B2D42">Storage</text>

                                    <!-- Data Directory -->
                                    <rect x="50" y="20" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="100" y="45" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Data Dir</text>
                                    <path d="M100 60 V80 L220 80" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <!-- WAL Files -->
                                    <rect x="50" y="140" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="100" y="165" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">WAL Files</text>
                                    <path d="M100 140 V120 L220 120" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <!-- Heap Files -->
                                    <rect x="350" y="20" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="400" y="45" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Heap Files</text>
                                    <path d="M400 60 V80 L280 80" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <!-- Visibility Map -->
                                    <rect x="350" y="140" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="400" y="165" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Visibility Map</text>
                                    <path d="M400 140 V120 L280 120" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <defs>
                                        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
                                            <polygon points="0 0, 10 3.5, 0 7" fill="#2D9B91" />
                                        </marker>
                                    </defs>
                                </svg>
                            </div>
                        `
                    },
                    {
                        "title": "Background Processes",
                        "description": "Several background processes operate continuously to maintain the health, performance, and integrity of a PostgreSQL database. These include the Checkpointer, WAL Writer, Autovacuum, and Archiver.",
                        "common_causes": "N/A",
                        "resolution": `
                            <p><strong class="error-section-title">Explanation:</strong><br>
                            PostgreSQL relies on several background processes to manage various tasks:
                            <ul class="list-disc ml-5 space-y-1">
                                <li><strong>Checkpointer:</strong> Periodically writes all dirty (modified) data pages from shared memory to disk. This process helps ensure data durability and limits the amount of WAL that needs to be replayed during crash recovery.</li>
                                <li><strong>WAL Writer:</strong> Ensures that WAL records are written to disk. While user processes might write some WAL, the WAL writer ensures that all pending WAL records are flushed to disk at regular intervals, adhering to durability guarantees.</li>
                                <li><strong>Autovacuum:</strong> A suite of processes that automatically reclaim space occupied by dead tuples (old versions of rows) and update statistics used by the query planner. It's crucial for preventing table bloat and maintaining query performance.</li>
                                <li><strong>Archiver:</strong> When WAL archiving is enabled, this process copies completed WAL files to a designated archive location. This is essential for point-in-time recovery and setting up standby servers.</li>
                            </ul>
                            </p>
                            <div class="flex justify-center items-center my-4">
                                <svg width="600" height="180" viewBox="0 0 600 180" fill="none" xmlns="http://www.w3.org/2000/svg">
                                    <!-- Shared Buffers -->
                                    <rect x="250" y="10" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="300" y="35" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Shared Buffers</text>

                                    <!-- WAL -->
                                    <rect x="250" y="130" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="300" y="155" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">WAL</text>

                                    <!-- Processes -->
                                    <rect x="20" y="70" width="100" height="40" rx="5" fill="#EDF7F6" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="70" y="95" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Checkpointer</text>
                                    <path d="M120 90 H240 M240 90 V50" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <rect x="160" y="70" width="100" height="40" rx="5" fill="#EDF7F6" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="210" y="95" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">WAL Writer</text>
                                    <path d="M260 90 H280 V130" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <rect x="340" y="70" width="100" height="40" rx="5" fill="#EDF7F6" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="390" y="95" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Autovacuum</text>
                                    <path d="M340 90 H280 V50" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <rect x="480" y="70" width="100" height="40" rx="5" fill="#EDF7F6" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="530" y="95" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Archiver</text>
                                    <path d="M480 90 H360 V130" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <defs>
                                        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
                                            <polygon points="0 0, 10 3.5, 0 7" fill="#2D9B91" />
                                        </marker>
                                    </defs>
                                </svg>
                            </div>
                        `
                    },
                    {
                        "title": "Concurrency",
                        "description": "PostgreSQL handles concurrent transactions using Multi-Version Concurrency Control (MVCC), row locking, and shared buffers. These mechanisms allow multiple users to access and modify data simultaneously without interfering with each other.",
                        "common_causes": "N/A",
                        "resolution": `
                            <p><strong class="error-section-title">Explanation:</strong><br>
                            Concurrency control ensures that multiple transactions can access the database simultaneously without corrupting data or seeing inconsistent states:
                            <ul class="list-disc ml-5 space-y-1">
                                <li><strong>Multi-Version Concurrency Control (MVCC):</strong> PostgreSQL's primary concurrency mechanism. Instead of locking rows for reads, it creates new versions of rows on update/delete. Each transaction sees a consistent "snapshot" of the database as it existed when the transaction began, preventing readers from blocking writers and vice-versa.</li>
                                <li><strong>Row Locking:</strong> While MVCC handles read-write conflicts, PostgreSQL still uses explicit and implicit locks for write operations (INSERT, UPDATE, DELETE) to prevent multiple transactions from modifying the *same* row concurrently. These locks are granular (row-level) to minimize contention.</li>
                                <li><strong>Shared Buffers:</strong> A portion of RAM used by PostgreSQL to cache frequently accessed data pages. When a process needs data, it first checks shared buffers. If the page is there, a disk read is avoided, significantly improving performance. Concurrency mechanisms ensure consistent access to these shared memory structures.</li>
                            </ul>
                            </p>
                            <div class="flex justify-center items-center my-4">
                                <svg width="600" height="200" viewBox="0 0 600 200" fill="none" xmlns="http://www.w3.org/2000/svg">
                                    <!-- Database -->
                                    <rect x="250" y="75" width="100" height="50" rx="8" fill="#F8F9FA" stroke="#2B2D42" stroke-width="2"/>
                                    <text x="300" y="105" text-anchor="middle" font-family="Inter, sans-serif" font-size="16" fill="#2B2D42">Database</text>

                                    <!-- MVCC -->
                                    <rect x="100" y="10" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="150" y="35" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">MVCC</text>
                                    <path d="M150 50 V75 M150 75 H250" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <!-- Row Locking -->
                                    <rect x="100" y="150" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="150" y="175" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Row Locking</text>
                                    <path d="M150 150 V125 M150 125 H250" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <!-- Shared Buffers -->
                                    <rect x="400" y="80" width="100" height="40" rx="5" fill="#E6FFFA" stroke="#2D9B91" stroke-width="1"/>
                                    <text x="450" y="105" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Shared Buffers</text>
                                    <path d="M350 100 H400" stroke="#2D9B91" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <!-- Transactions -->
                                    <rect x="0" y="80" width="80" height="30" rx="5" fill="#EDF7F6" stroke="#5B6A78" stroke-width="1"/>
                                    <text x="40" y="100" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Txn 1</text>
                                    <path d="M80 95 H100" stroke="#5B6A78" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <rect x="520" y="80" width="80" height="30" rx="5" fill="#EDF7F6" stroke="#5B6A78" stroke-width="1"/>
                                    <text x="560" y="100" text-anchor="middle" font-family="Inter, sans-serif" font-size="12" fill="#2B2D42">Txn 2</text>
                                    <path d="M520 95 H500" stroke="#5B6A78" stroke-width="1.5" marker-end="url(#arrowhead)"/>

                                    <defs>
                                        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
                                            <polygon points="0 0, 10 3.5, 0 7" fill="#2D9B91" />
                                        </marker>
                                    </defs>
                                </svg>
                            </div>
                        `
                    }
                ]
            },
            'indexes': {
                title: "Indexes",
                intro: "Detailed information about different types of indexes in PostgreSQL and their usage.",
                issues: [
                  {
                        "title": "What are Indexes?",
                        "description": "In PostgreSQL, an **index** is a special lookup table that the database search engine can use to speed up data retrieval. Think of it like the index at the back of a book. Instead of reading the entire book to find a specific topic, you can look up the topic in the index, find the page number, and go directly to that page. Similarly, a database index allows PostgreSQL to quickly locate data without scanning every row in a table.\n\nWhen you create an index on one or more columns of a table, PostgreSQL creates a data structure (typically a B-tree) that stores the values of those columns along with pointers to the corresponding rows in the table. When a query is executed that involves the indexed columns, PostgreSQL can use the index to find the relevant rows much faster.",
                        "common_causes": "N/A",
                        "resolution": "N/A"
                    },
                    {
                        "title": "Why Use Indexes? ",
                        "description": "While indexes offer performance benefits, they also come with overhead. PostgreSQL needs to update the index whenever data in the indexed columns changes (inserts, updates, deletes). Therefore, it's essential to use them strategically:",
                        "common_causes": "N/A",
                        "resolution": "- **Faster Data Retrieval:** The primary benefit is significantly faster execution of SELECT queries, especially those with WHERE clauses, JOIN conditions, ORDER BY clauses, and GROUP BY clauses.\n- **Improved Query Performance:** By reducing the number of disk I/O operations required to find data, indexes can drastically improve the overall performance of your applications.\n- **Enforcement of Uniqueness:** UNIQUE constraints and PRIMARY KEY constraints automatically create unique indexes, ensuring that no duplicate values are entered into the indexed columns."
                    },
                    {
                        "title": "When to Use Indexes? ",
                        "description": "While indexes offer performance benefits, they also come with overhead. PostgreSQL needs to update the index whenever data in the indexed columns changes (inserts, updates, deletes). Therefore, it's essential to use them strategically:",
                        "common_causes": "N/A",
                        "resolution": "- **Columns frequently used in WHERE clauses:** If you often filter data based on a specific column, an index on that column will speed up your queries.\n- **Columns used in JOIN conditions:** Indexes on columns used for joining tables (e.g., foreign keys) can significantly accelerate joins.\n- **Columns used in ORDER BY or GROUP BY clauses:** Indexes can help PostgreSQL sort or group data more efficiently, sometimes avoiding a full sort operation.\n- **Columns with high cardinality:** Columns with many distinct values (e.g., email_address, product_id) are good candidates for indexing.\n- **Columns frequently updated/inserted:** If a table experiences frequent write operations, be mindful of the overhead. Too many indexes can slow down writes."
                    },
                    {
                        "title": "Types of Indexes in PostgreSQL ",
                        "description": "PostgreSQL supports several index types, with **B-tree** being the most common and default type.",
                        "common_causes": "N/A",
                        "resolution": "- **B-tree (Balanced Tree):** The default and most versatile index type. Excellent for equality and range queries (=, <, >, <=, >=, BETWEEN). Suitable for most data types.\n- **Hash:** Can only be used for equality comparisons (=). Generally, B-tree indexes are preferred due to better performance and more features.\n- **GiST (Generalized Search Tree):** Used for indexing complex data types and operations, such as geometric data, full-text search, and geographic information systems (GIS).\n- **SP-GiST (Space-Partitioned GiST):** Similar to GiST but optimized for certain types of unbalanced data structures.\n- **GIN (Generalized Inverted Index):** Ideal for indexing columns that contain multiple values within a single column, like arrays or JSONB documents, or for full-text search.\n- **BRIN (Block Range INdex):** Best for very large tables where data is naturally ordered (e.g., time-series data). It indexes ranges of pages rather than individual rows."
                    },
                    {
                        "title": "Creating Indexes: Examples with Copyable Text ",
                        "description": "Let's assume we have a table called `products`:\n```sql\nCREATE TABLE products (\n    product_id SERIAL PRIMARY KEY,\n    product_name VARCHAR(255) NOT NULL,\n    category VARCHAR(100),\n    price DECIMAL(10, 2),\n    stock_quantity INT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\nINSERT INTO products (product_name, category, price, stock_quantity) VALUES\n('Laptop Pro', 'Electronics', 1200.00, 50),\n('Mechanical Keyboard', 'Peripherals', 150.00, 200),\n('Wireless Mouse', 'Peripherals', 30.00, 500),\n('4K Monitor', 'Electronics', 450.00, 80),\n('Ergonomic Chair', 'Office Furniture', 300.00, 100),\n('Smartphone X', 'Electronics', 800.00, 120),\n('Desk Lamp', 'Office Furniture', 45.00, 300),\n('Noise-Cancelling Headphones', 'Audio', 250.00, 90),\n('Gaming PC', 'Electronics', 2000.00, 30),\n('Webcam HD', 'Peripherals', 60.00, 150);\n```",
                        "common_causes": "N/A",
                        "resolution": "1. <strong>Creating a B-tree Index (Most Common)</strong>\nYou'd typically create a B-tree index on columns used in WHERE clauses for faster filtering.\nExample: Indexing the `category` column to speed up queries that filter by product category.\n```sql\nCREATE INDEX idx_products_category ON products (category);\n```\n<strong>Explanation:</strong>\n`CREATE INDEX`: The command to create an index.\n`idx_products_category`: The name of the index. It's a good practice to use a naming convention like idx_tablename_columnname.\n`ON products`: Specifies the table on which the index is being created.\n`(category)`: The column(s) to be indexed.\nNow, if you run a query like `SELECT * FROM products WHERE category = 'Electronics';`, PostgreSQL can use `idx_products_category` to quickly find matching rows.\n\n2. <strong>Creating a Unique Index</strong>\nA unique index ensures that all values in the indexed column(s) are unique. It also speeds up queries.\nExample: Ensuring that `product_name` is unique in the products table (if `product_id` weren't already a PRIMARY KEY).\n```sql\nCREATE UNIQUE INDEX idx_products_unique_product_name ON products (product_name);\n```\n<strong>Explanation:</strong>\n`UNIQUE`: This keyword ensures that no two rows can have the same value in the `product_name` column. If you try to insert a product with an existing name, it will result in an error.\n\n3. <strong>Creating a Multi-Column (Composite) Index</strong>\nA composite index involves more than one column. It's useful when your queries frequently filter or sort on multiple columns together. The order of columns in a composite index matters.\nExample: Indexing `category` and `price` together to speed up queries like \"find electronics products under a certain price.\"\n```sql\nCREATE INDEX idx_products_category_price ON products (category, price);\n```\n<strong>Explanation:</strong>\nThis index can be used for queries filtering on `category` alone, or on both `category` and `price`.\nIt would be efficient for `SELECT * FROM products WHERE category = 'Electronics' AND price < 500;`.\nHowever, it would generally **not** be used efficiently for queries filtering only on `price` (e.g., `WHERE price < 500`), because `category` is the leading column.\n\n4. <strong>Creating an Index with an Operator Class</strong>\nFor certain data types or custom operators, you might need to specify an operator class. For example, for text searches using `text_pattern_ops`.\nExample: Indexing `product_name` for efficient pattern matching using `LIKE` (e.g., `product_name LIKE 'Laptop%'`).\n```sql\nCREATE INDEX idx_products_product_name_pattern ON products (product_name text_pattern_ops);\n```\n<strong>Explanation:</strong>\n`text_pattern_ops`: This operator class is specifically designed to optimize pattern matching operations (`LIKE`, `~`) on text columns, particularly when the pattern has a leading non-wildcard string.\n\n5. <strong>Creating a GIN Index for Full-Text Search or JSONB</strong>\nGIN indexes are excellent for array columns, JSONB columns, and full-text search.\nExample: Suppose you add a `tags` column (array of text) to your products table and want to search efficiently within it.\n```sql\nALTER TABLE products ADD COLUMN tags TEXT[];\nUPDATE products SET tags = ARRAY['electronics', 'portable'] WHERE product_name = 'Laptop Pro';\nUPDATE products SET tags = ARRAY['office', 'ergonomic'] WHERE product_name = 'Ergonomic Chair';\nUPDATE products SET tags = ARRAY['audio', 'wireless'] WHERE product_name = 'Noise-Cancelling Headphones';\nCREATE INDEX idx_products_tags ON products USING GIN (tags);\n```\nNow you can efficiently query for products containing specific tags:\n```sql\nSELECT * FROM products WHERE 'electronics' = ANY(tags);\n```"
                    },
                    {
                        "title": "Dropping Indexes ",
                        "description": "If an index is no longer needed or is causing performance issues (e.g., slowing down writes too much), you can drop it.",
                        "common_causes": "N/A",
                        "resolution": "```sql\nDROP INDEX idx_products_category;\n```\nCaution: Dropping an index will remove its performance benefits for queries that previously used it."
                    },
                    {
                        "title": "Verifying Indexes ",
                        "description": "You can check which indexes exist on a table using `\\d+` in psql or by querying the `pg_indexes` catalog view.",
                        "common_causes": "N/A",
                        "resolution": "- <strong>Using `\\d+` in psql:</strong>\n```sql\n\\d+ products\n```\nThis will show details about the products table, including its indexes.\n\n- <strong>Querying `pg_indexes`:</strong>\n```sql\nSELECT\n       tablename,\n       indexname,\n       indexdef\n   FROM\n       pg_indexes\n   WHERE\n       tablename = 'products';\n```\nThis query will list the name, definition, and table for all indexes on the products table."
                    },
                    {
                        "title": "Conclusion",
                        "description": "Indexes are a fundamental component of database performance optimization in PostgreSQL. By understanding their types, benefits, and when to use them, you can significantly improve the speed and efficiency of your database queries. Always monitor your query performance (using `EXPLAIN ANALYZE`) to determine if indexes are being used effectively and to identify areas for further optimization.",
                        "common_causes": "N/A",
                        "resolution": "N/A"
                    }
                ]
            },
            'joins': {
                title: "Joins",
                intro: "Explanation and examples of various SQL JOIN operations in PostgreSQL.",
                issues: [ {
                        "title": "Types of Joins in PostgreSQL",
                        "description": "PostgreSQL supports the standard SQL join types, each serving a specific purpose for combining data:\n\n- <strong>INNER JOIN:</strong> An `INNER JOIN` returns only the rows where there's a match in both tables based on the specified join condition. Rows without a match in either table are excluded. It's the most common type of join and is often the default behavior if you simply use `JOIN` without specifying a type.\n- <strong>LEFT JOIN (or LEFT OUTER JOIN):</strong> A `LEFT JOIN` returns all rows from the *left* table (the first table mentioned in the `FROM` clause) and the matching rows from the *right* table. If a row in the left table has no match in the right table, `NULL` values are returned for the columns from the right table.\n- <strong>RIGHT JOIN (or RIGHT OUTER JOIN):</strong> A `RIGHT JOIN` returns all rows from the *right* table (the table specified after `RIGHT JOIN`) and the matching rows from the *left* table. If a row in the right table has no match in the left table, `NULL` values are returned for the columns from the left table.\n- <strong>FULL JOIN (or FULL OUTER JOIN):</strong> A `FULL JOIN` returns all rows when there's a match in either the left or the right table. It combines the results of both `LEFT JOIN` and `RIGHT JOIN`. If a row in one table has no match in the other, `NULL` values are returned for the columns from the non-matching table.\n- <strong>CROSS JOIN:</strong> A `CROSS JOIN` returns the Cartesian product of the rows from the joined tables. This means every row from the first table is combined with every row from the second table, without requiring a join condition. This type of join can produce a very large result set and is less commonly used for data retrieval compared to other join types.",
                        "common_causes": "N/A",
                        "resolution": "N/A"
                    },
                   
                    {
                        "title": "1. INNER JOIN Example",
                        "description": "To get customers who have placed orders:",
                        "common_causes": "N/A",
                        "resolution": "### SQL:\n```sql\nSELECT\n    c.customer_name,\n    o.order_id,\n    o.order_date\nFROM\n    customers AS c\nINNER JOIN\n    orders AS o ON c.customer_id = o.customer_id;\n```\n### Expected Result:\n<table class=\"data-table\">\n    <thead>\n        <tr>\n            <th>customer_name</th>\n            <th>order_id</th>\n            <th>order_date</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr><td>Alice</td><td>101</td><td>2024-01-15</td></tr>\n        <tr><td>Bob</td><td>102</td><td>2024-01-20</td></tr>\n        <tr><td>Alice</td><td>103</td><td>2024-02-01</td></tr>\n    </tbody>\n</table>"
                    },
                   {
                        "title": "2. LEFT JOIN Example",
                        "description": "To get all customers and their orders (if any):",
                        "common_causes": "N/A",
                        "resolution": "### SQL:\n```sql\nSELECT\n    c.customer_name,\n    o.order_id,\n    o.order_date\nFROM\n    customers AS c\nLEFT JOIN\n    orders AS o ON c.customer_id = o.customer_id;\n```\n### Expected Result:\n<table class=\"data-table\">\n    <thead>\n        <tr>\n            <th>customer_name</th>\n            <th>order_id</th>\n            <th>order_date</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr><td>Alice</td><td>101</td><td>2024-01-15</td></tr>\n        <tr><td>Bob</td><td>102</td><td>2024-01-20</td></tr>\n        <tr><td>Charlie</td><td>NULL</td><td>NULL</td></tr>\n        <tr><td>Alice</td><td>103</td><td>2024-02-01</td></tr>\n    </tbody>\n</table>"
                    },
                    {
                        "title": "3. RIGHT JOIN Example",
                        "description": "To get all orders and the customer who placed them (if any):",
                        "common_causes": "N/A",
                        "resolution": "### SQL:\n```sql\nSELECT\n    c.customer_name,\n    o.order_id,\n    o.order_date\nFROM\n    customers AS c\nRIGHT JOIN\n    orders AS o ON c.customer_id = o.customer_id;\n```\n### Expected Result:\n<table class=\"data-table\">\n    <thead>\n        <tr>\n            <th>customer_name</th>\n            <th>order_id</th>\n            <th>order_date</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr><td>Alice</td><td>101</td><td>2024-01-15</td></tr>\n        <tr><td>Bob</td><td>102</td><td>2024-01-20</td></tr>\n        <tr><td>Alice</td><td>103</td><td>2024-02-01</td></tr>\n        <tr><td>NULL</td><td>104</td><td>2024-02-10</td></tr>\n    </tbody>\n</table>"
                    },
                    {
                        "title": "4. FULL JOIN Example",
                        "description": "To get all customers and all orders, showing matches where they exist, and `NULL` where they don't:",
                        "common_causes": "N/A",
                        "resolution": "### SQL:\n```sql\nSELECT\n    c.customer_name,\n    o.order_id,\n    o.order_date\nFROM\n    customers AS c\nFULL JOIN\n    orders AS o ON c.customer_id = o.customer_id;\n```\n### Expected Result:\n<table class=\"data-table\">\n    <thead>\n        <tr>\n            <th>customer_name</th>\n            <th>order_id</th>\n            <th>order_date</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr><td>Alice</td><td>101</td><td>2024-01-15</td></tr>\n        <tr><td>Bob</td><td>102</td><td>2024-01-20</td></tr>\n        <tr><td>Charlie</td><td>NULL</td><td>NULL</td></tr>\n        <tr><td>Alice</td><td>103</td><td>2024-02-01</td></tr>\n        <tr><td>NULL</td><td>104</td><td>2024-02-10</td></tr>\n    </tbody>\n</table>"
                    },
                    {
                        "title": "5. CROSS JOIN Example",
                        "description": "To combine every customer with every order (this produces a Cartesian product and is generally used for specific scenarios, not typical data linking):",
                        "common_causes": "N/A",
                        "resolution": "### SQL:\n```sql\nSELECT\n    c.customer_name,\n    o.order_id\nFROM\n    customers AS c\nCROSS JOIN\n    orders AS o;\n```\n### Expected Result (partial):\n<table class=\"data-table\">\n    <thead>\n        <tr>\n            <th>customer_name</th>\n            <th>order_id</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr><td>Alice</td><td>101</td></tr>\n        <tr><td>Alice</td><td>102</td></tr>\n        <tr><td>Alice</td><td>103</td></tr>\n        <tr><td>Alice</td><td>104</td></tr>\n        <tr><td>Bob</td><td>101</td></tr>\n        <tr><td>...</td><td>...</td></tr>\n    </tbody>\n</table>"
                    }]
            }
        };
        
        // Populate the new category with data from Catalog.json
        catalogData.forEach(table => {
            db['system-catalog-tables'].issues.push({
                title: table.table_name,
                description: table.purpose,
                common_causes: `Important Columns:\n- ${table.important_columns.join('\n- ')}`,
                resolution: `Sample Select Query:\n\`\`\`sql\n${table.sample_select_query}\n\`\`\`\n\nUse in Monitoring/Debugging:\n${table.use_in_monitoring_debugging}`
            });
        });


        // Calculate initial dashboard metrics
        let totalIssues = 0;
        let categoryIssueCounts = {};
        let criticalIssuesCount = 0; // Initialize to 0, will count from data
        let totalCategories = 0;

        for (const key in db) {
            if (key !== 'dashboard' && db[key].issues) {
                totalIssues += db[key].issues.length;
                totalCategories++;
                db[key].issues.forEach(issue => {
                    // Ensure common_causes and resolution are present, even if empty
                    issue.common_causes = issue.common_causes || "N/A";
                    issue.resolution = issue.resolution || "N/A";
                    issue.description = issue.description || "N/A"; // Ensure description is also present

                    // Count critical issues if severity is defined
                    if (issue.severity && issue.severity.toLowerCase() === 'critical') {
                        criticalIssuesCount++;
                    }
                });
                categoryIssueCounts[key] = db[key].issues.length;
            }
        }

        let mostErrorsCategory = 'N/A';
        let maxErrors = 0;
        for (const key in categoryIssueCounts) {
            if (categoryIssueCounts[key] > maxErrors) {
                maxErrors = categoryIssueCounts[key];
                mostErrorsCategory = db[key].title;
            }
        }

        db.dashboard.metrics = {
            totalErrors: totalIssues,
            categoryMostErrors: mostErrorsCategory,
            criticalIssues: criticalIssuesCount,
            totalCategories: totalCategories
        };


        const categoryIcons = {
            'glossary': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 006 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 016 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 016-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0018 18a8.967 8.967 0 00-6 2.292m0-14.25v14.25" /></svg>`,
            dashboard: `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6A2.25 2.25 0 016 3.75h2.25A2.25 2.25 0 0110.5 6v2.25a2.25 2.25 0 01-2.25 2.25H6a2.25 2.25 0 01-2.25-2.25V6zM3.75 15.75A2.25 2.25 0 016 13.5h2.25a2.25 2.25 0 012.25 2.25V18a2.25 2.25 0 01-2.25 2.25H6a2.25 2.25 0 01-2.25-2.25v-2.25zM13.5 6a2.25 2.25 0 012.25-2.25H18A2.25 2.25 0 0120.25 6v2.25A2.25 2.25 0 0118 10.5h-2.25a2.25 2.25 0 01-2.25-2.25V6zM13.5 15.75a2.25 2.25 0 012.25-2.25H18a2.25 2.25 0 012.25 2.25V18a2.25 2.25 0 01-2.25 2.25h-2.25a2.25 2.25 0 01-2.25-2.25v-2.25z" /></svg>`, // Squares
            'connection-authentication': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 10.5V6.75a4.5 4.5 0 119 0v3.75M3.75 21.75h10.5a2.25 2.25 0 002.25-2.25V6.75a2.25 2.25 0 00-2.25-2.25H3.75A2.25 2.25 0 001.5 6.75v12.75a2.25 2.25 0 002.25 2.25z" /></svg>`, // Lock
            'locking-concurrency': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M16.5 10.5V6.75a4.5 4.5 0 10-9 0v3.75m-.75 11.25h10.5a2.25 2.25 0 002.25-2.25v-6.75a2.25 2.25 0 00-2.25-2.25H6.75a2.25 2.25 0 00-2.25 2.25v6.75a2.25 2.25 0 002.25 2.25z" /></svg>`, // Unlock
            'replication-ha': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M7.5 21 3 16.5m0 0L7.5 12M3 16.5h18M16.5 3l4.5 4.5m0 0L16.5 12M21 7.5H3" /></svg>`, // Arrows
            'backup-recovery': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M20.25 7.757l-4.5 4.5m0-4.5L20.25 7.757m0 0l-1.588 1.589A2.25 2.25 0 0115 10.5h-4.243c-.707 0-1.407-.201-1.99-.582L5.757 7.757m2.333-.75l2.673 2.673A2.25 2.25 0 0112.75 12h-3.75c-.707 0-1.407-.201-1.99-.582L5.757 8.252m5.07-5.071L9.52 3.593A2.25 2.25 0 007.25 6h-3.75c-.707 0-1.407-.201-1.99-.582L1.757 3.593m11.66-1.166l.896.896A2.25 2.25 0 0015 6h4.243c.707 0 1.407-.201 1.99-.582l1.589-1.588L20.25 7.757" /></svg>`, // Archive box
            'performance-optimization': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 13.5l10.5-11.25L12 10.5h8.25L13.5 21.75l1.5-6H9.75l1.5-6H3.75z" /></svg>`, // Bolt/Lightning
            'query-indexing': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 7.5h1.5m-1.5 3h1.5m-7.5 3h7.5m-7.5 3h7.5m3-9h3.375c.621 0 1.125.504 1.125 1.125V18a2.25 2.25 0 01-2.25 2.25M16.5 7.5V18L8.25 10.5M15.75 5.25a3 3 0 013 3V18a2.25 2.25 0 01-2.25 2.25H1.5A2.25 2.25 0 01-0.75 18V8.25a3 3 0 013-3h7.5z" /></svg>`, // Document with lines
            'security-access-control': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M9 12.75L11.25 15 15 9.75M21 12c0 1.657-1.343 3-3 3s-3-1.343-3-3 1.343-3 3-3 3 1.657 3 3zM12 12c0 1.657-1.343 3-3 3s-3-1.343-3-3 1.343-3 3-3 3 1.657 3 3zM6 12c0 1.657-1.343 3-3 3s-3-1.343-3-3 1.343-3 3-3 3 1.657 3 3z" /></svg>`, // Shield Check
            'data-integrity-consistency': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M9 12.75l3 3m0 0l3-3m-3 3v2.25M21 12a9 9 0 11-18 0 9 9 0 0118 0z" /></svg>`, // Check circle (data consistency)
            'upgrade-migration': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M3 7.5L7.5 3m0 0L12 7.5M7.5 3v13.5m13.5 0L16.5 21m0 0L12 16.5m4.5 4.5V7.5" /></svg>`, // Arrow up and down
            'troubleshooting-debugging': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M6.429 9.75L2.25 12l4.179 2.25m0-4.5l5.59 2.25 5.59 2.25m-11.18 0L2.25 16.5l4.179 2.25M18.106 14.166L21.75 12l-3.644-2.166m0 4.332L21.75 16.5l-3.644 2.166M12 12l5.59 2.25 5.59-2.25M12 12L6.41 9.75l-5.59-2.25" /></svg>`, // Bug / Debugging
            'indexes': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.75a.75.75 0 110-1.5.75.75 0 010 1.5zM12 12.75a.75.75 0 110-1.5.75.75 0 010 1.5zM12 18.75a.75.75 0 110-1.5.75.75 0 010 1.5z" /></svg>`, // Three dots for indexes
            'joins': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M13.19 8.688a4.5 4.5 0 011.242 7.244l-4.5 4.5a4.5 4.5 0 01-6.364-6.364l1.757-1.757m13.39-4.459l-1.757-1.757a4.5 4.5 0 00-6.364 6.364l4.5 4.5a4.5 4.5 0 006.364-6.364z" /></svg>`, // Link icon for joins
            'error-guide': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 006 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 016 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 016-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0018 18a8.967 8.967 0 00-6 2.292m0-14.25v14.25" /></svg>`, // Book icon
            'postgresql-architecture': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M8.25 3v1.5M4.5 8.25H3m18 0h-1.5M4.5 12H3m18 0h-1.5m-15 3.75H3m18 0h-1.5M8.25 19.5V21M12 2.25h.007v.008H12V2.25zm0 4.5h.007v.008H12V6.75zm0 4.5h.007v.008H12v-4.5zm0 4.5h.007v.008H12v-4.5zm0 4.5h.007v.008H12v-4.5zm0 4.5h.007v.008H12v-4.5zM12 2.25H6.75a2.25 2.25 0 00-2.25 2.25v10.5a2.25 2.25 0 002.25 2.25h5.25m-10.5-9h1.5m-1.5 3h1.5m-1.5 3h1.5M19.5 4.5a2.25 2.25 0 00-2.25-2.25H12M19.5 4.5v.007l.007-.007H19.5zm0 15a2.25 2.25 0 01-2.25 2.25H12M19.5 19.5v.007l.007-.007H19.5zm0-15a2.25 2.25 0 00-2.25-2.25H12V4.5h5.25A2.25 2.25 0 0119.5 6.75V18A2.25 2.25 0 0117.25 20.25H12V19.5h5.25a1.5 1.5 0 001.5-1.5V6.75a1.5 1.5 0 00-1.5-1.5H12" /></svg>`, // CPU Chip icon
            'postgresql-installation-guide': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h1M3 12H2m15.325-6.675l.707-.707M6.675 17.325l-.707.707M18.675 17.325l.707.707M6.675 6.675l-.707-.707M12 7a5 5 0 100 10 5 5 0 000-10z" /></svg>`, // Cog icon for installation
            'system-catalog-tables': `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M20.25 6.375c0 2.278-3.693 4.125-8.25 4.125S3.75 8.653 3.75 6.375 7.443 2.25 12 2.25s8.25 1.872 8.25 4.125zm-1.125 3.375a4.125 4.125 0 01-8.25 0v-.375c0-2.278 3.693-4.125 8.25-4.125s8.25 1.872 8.25 4.125v.375zm-1.125 3.375a4.125 4.125 0 01-8.25 0v-.375c0-2.278 3.693-4.125 8.25-4.125s8.25 1.872 8.25 4.125v.375zM12 18.75c-4.557 0-8.25-1.872-8.25-4.125v-.375c0-2.278 3.693-4.125 8.25-4.125s8.25 1.872 8.25 4.125v.375c0 2.253-3.693 4.125-8.25 4.125z" /></svg>` // Database icon
        };


        const headerTitle = document.getElementById('header-title');
        const contentArea = document.getElementById('content-area');
        const mainNav = document.getElementById('main-nav');
        const searchInput = document.getElementById('search-input');
        const searchContainer = document.getElementById('search-container');
        const sidebar = document.getElementById('sidebar');
        const menuToggle = document.getElementById('menu-toggle');

        // Chatbot elements
        const chatbotContainer = document.getElementById('chatbot-container');
        const chatbotToggleButton = document.getElementById('chatbot-toggle-button');
        const chatbotCloseButton = document.getElementById('chatbot-close-button');
        const chatbotMessages = document.getElementById('chatbot-messages');
        const chatbotInput = document.getElementById('chatbot-input');
        const chatbotSendButton = document.getElementById('chatbot-send-button');

        // Theme toggle elements
        const themeToggle = document.getElementById('theme-toggle');
        const themeToggleLightIcon = document.getElementById('theme-toggle-light-icon');
        const themeToggleDarkIcon = document.getElementById('theme-toggle-dark-icon');

        let categoryChartInstance = null; 

        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `chatbot-message ${sender}`;
            messageDiv.textContent = text;
            chatbotMessages.appendChild(messageDiv);
            chatbotMessages.scrollTop = chatbotMessages.scrollHeight; // Scroll to bottom
        }

        async function handleChatbotInput() {
            const query = chatbotInput.value.trim();
            if (query === '') return;

            addMessage(query, 'user');
            chatbotInput.value = '';

            const lowerQuery = query.toLowerCase();
            let foundMatch = false;

            const typingIndicator = document.createElement('div');
            typingIndicator.classList.add('chatbot-message', 'bot');
            typingIndicator.innerHTML = '<span>Typing...</span>';
            chatbotMessages.appendChild(typingIndicator);
            chatbotMessages.scrollTop = chatbotMessages.scrollHeight;

            try {
                let chatHistory = [];
                chatHistory.push({ role: "user", parts: [{ text: query }] });
                const payload = { contents: chatHistory };
                const apiKey = ""; 
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();
                chatbotMessages.removeChild(typingIndicator);

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const botResponse = result.candidates[0].content.parts[0].text;
                    addMessage(botResponse, 'bot');
                } else {
                    addMessage("Sorry, I couldn't get a response. Please try again.", 'bot');
                }
            } catch (error) {
                console.error('Error calling Gemini API:', error);
                chatbotMessages.removeChild(typingIndicator);
                addMessage("An error occurred while fetching the response. Please try again later.", 'bot');
            }

            for (const categoryKey in db) {
                if (categoryKey === 'dashboard') continue;

                const category = db[categoryKey];
                if (category.issues) {
                    for (let i = 0; i < category.issues.length; i++) {
                        const issue = category.issues[i];
                        const searchableContent = `${issue.title} ${issue.description} ${issue.common_causes} ${issue.resolution}`.toLowerCase();
                        if (searchableContent.includes(lowerQuery)) {
                            renderContent(categoryKey, issue.title);
                            foundMatch = true;
                            chatbotContainer.classList.remove('open');
                            break; 
                        }
                    }
                }
                if (foundMatch) break;
            }
        }


        function renderContent(key, highlightIssueTitle = null) {
            const data = db[key];
            headerTitle.textContent = data.title;
            contentArea.innerHTML = ''; // Clear previous content

            // Handle search bar visibility
            if (key === 'dashboard' || key === 'system-catalog-tables') { // Hide search for dashboard and catalog tables
                searchContainer.classList.add('hidden');
                searchInput.value = ''; // Clear search when on dashboard
            } else {
                searchContainer.classList.remove('hidden');
            }

            // Render dynamic content (like the dashboard cards or static content)
            if (data.content) {
                const dynamicContent = document.createElement('div');
                dynamicContent.innerHTML = typeof data.content === 'function' ? data.content(data.metrics) : data.content;
                contentArea.appendChild(dynamicContent);

                if (key === 'dashboard') {
                    renderCategoryCheckboxes(); 
                    renderCategoryChart(); 
                    renderCommonIssues(); 
                }
            }

            if (data.intro && key !== 'dashboard') { 
                const introSection = document.createElement('div');
                introSection.className = 'bg-card-light p-6 rounded-lg shadow-sm mb-6';
                introSection.innerHTML = `<h2 class="text-xl font-semibold text-dark-charcoal mb-2">${data.title}</h1><p class="text-medium-gray">${data.intro}</p>`;
                contentArea.appendChild(introSection);
            }

            if (data.issues) {
                const issuesContainer = document.createElement('div');
                issuesContainer.id = 'issues-list'; 
                issuesContainer.className = 'space-y-4';

                data.issues.forEach((issue, index) => {
                    const accordionItem = document.createElement('div');
                    accordionItem.className = 'bg-card-light rounded-lg shadow-sm overflow-hidden issue-item'; 
                    accordionItem.setAttribute('data-title', issue.title.toLowerCase());
                    let searchableContent = `${(issue.description || '').toLowerCase()} ${(issue.common_causes || '').toLowerCase()} ${(issue.resolution || '').toLowerCase()}`;
                    accordionItem.setAttribute('data-content', searchableContent);
                    accordionItem.id = `issue-${key}-${index}`; 

                    const accordionHeader = document.createElement('button');
                    accordionHeader.className = 'accordion-header w-full flex justify-between items-center p-4 font-semibold text-left text-dark-charcoal hover-accent-bg focus:outline-none focus:bg-accent-light transition-colors';
                    accordionHeader.innerHTML = `
                        <span>${issue.title}</span>
                        <svg class="w-5 h-5 transform transition-transform" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    `;
                    accordionHeader.addEventListener('click', () => {
                        const content = accordionHeader.nextElementSibling;
                        const icon = accordionHeader.querySelector('svg');
                        if (content.style.display === 'block') {
                            content.style.display = 'none';
                            icon.classList.remove('rotate-180');
                        } else {
                            content.style.display = 'block';
                            icon.classList.add('rotate-180');
                        }
                    });

                    const accordionContent = document.createElement('div');
                    accordionContent.className = 'accordion-content p-4 border-t border-soft-gray text-medium-gray';
                    
                    let contentHtml = '';
                    if (issue.description && issue.description !== "N/A") {
                        const descriptionWithCode = issue.description.replace(/```sql\n([\s\S]*?)\n```/g, '<div class="code-block"><pre><code>$1</code></pre></div>');
                        contentHtml += `<p><strong class="error-section-title">Description:</strong> <span class="block mt-1">${descriptionWithCode.replace(/\n/g, '<br>')}</span></p>`;
                    }
                    if (issue.common_causes && issue.common_causes !== "N/A") {
                        let commonCausesFormatted = issue.common_causes.replace(/^- (.*)$/gm, '<li>$1</li>');
                        if (commonCausesFormatted.includes('<li>')) {
                            commonCausesFormatted = `<ul class="list-disc ml-5">${commonCausesFormatted}</ul>`;
                        } else {
                            commonCausesFormatted = `<p>${commonCausesFormatted}</p>`;
                        }
                        contentHtml += `<p><strong class="error-section-title">Common Causes:</strong> <div class="error-content-body mt-1">${commonCausesFormatted}</div></p>`;
                    }
                    if (issue.resolution && issue.resolution !== "N/A") {
                        let resolutionHtml = issue.resolution.replace(/^- (.*)$/gm, '<li>$1</li>');
                        resolutionHtml = resolutionHtml.replace(/```sql\n([\s\S]*?)\n```/g, '<div class="code-block"><pre><code>$1</code></pre></div>');

                        // Replace newlines with <br> tags for general text, but not inside code blocks
                        resolutionHtml = resolutionHtml.split('<div class="code-block">').map((part, i) => {
                            if (i % 2 === 0) { // Not inside a code block
                                return part.replace(/\n/g, '<br>');
                            } else { // Inside a code block, keep newlines
                                return part;
                            }
                        }).join('<div class="code-block">');


                        if (resolutionHtml.includes('<li>')) {
                            resolutionHtml = `<ul>${resolutionHtml}</ul>`;
                        } else {
                            resolutionHtml = `<p>${resolutionHtml}</p>`;
                        }
                        contentHtml += `<p><strong class="error-section-title">Resolution:</strong> <div class="error-content-body mt-1">${resolutionHtml}</div></p>`;
                    }

                    accordionContent.innerHTML = contentHtml;

                    accordionItem.appendChild(accordionHeader);
                    accordionItem.appendChild(accordionContent);
                    issuesContainer.appendChild(accordionItem);
                });

                if (data.issues.length === 0) {
                    issuesContainer.innerHTML = '<p class="text-medium-gray text-center py-8">No common issues listed for this category yet. Check back later!</p>';
                }

                const noResults = document.createElement('p');
                noResults.id = 'no-results';
                noResults.className = 'text-medium-gray text-center py-8 hidden';
                noResults.textContent = 'No matching issues found.';
                issuesContainer.appendChild(noResults);


                contentArea.appendChild(issuesContainer);

                document.querySelectorAll('.code-block').forEach(block => {
                    const button = document.createElement('button');
                    button.className = 'copy-btn';
                    button.textContent = 'Copy';
                    block.appendChild(button);

                    button.addEventListener('click', () => {
                        const code = block.querySelector('code').textContent;
                        const textarea = document.createElement('textarea');
                        textarea.value = code;
                        document.body.appendChild(textarea);
                        textarea.select();
                        try {
                            document.execCommand('copy');
                            button.textContent = 'Copied!';
                            button.classList.add('copy-feedback');
                            setTimeout(() => {
                                button.textContent = 'Copy';
                                button.classList.remove('copy-feedback');
                            }, 2000);
                        } catch (err) {
                            console.error('Failed to copy: ', err);
                        } finally {
                            document.body.removeChild(textarea);
                        }
                    });
                });

                if (highlightIssueTitle) {
                    const issueElements = issuesContainer.querySelectorAll('.issue-item');
                    for (const element of issueElements) {
                        const title = element.querySelector('.accordion-header span').textContent;
                        if (title === highlightIssueTitle) {
                            const content = element.querySelector('.accordion-content');
                            const icon = element.querySelector('.accordion-header svg');
                            if (content.style.display !== 'block') {
                                content.style.display = 'block';
                                icon.classList.add('rotate-180');
                            }
                            element.scrollIntoView({ behavior: 'smooth', block: 'start' });
                            break;
                        }
                    }
                }
            }

            document.querySelectorAll('.sidebar-item, .sidebar-parent').forEach(item => {
                item.classList.remove('active');
            });
            const activeItem = document.querySelector(`.sidebar-item[data-key="${key}"]`);
            if (activeItem) {
                activeItem.classList.add('active');
                // Also activate the parent group
                const parentGroup = activeItem.closest('.collapsible-group');
                if(parentGroup) {
                    const parentButton = parentGroup.querySelector('.sidebar-parent');
                    parentButton.classList.add('active');
                    // Ensure the group is open
                    const subMenu = parentGroup.querySelector('.submenu-container');
                    if (subMenu.classList.contains('hidden')) {
                        subMenu.classList.remove('hidden');
                        parentButton.querySelector('.chevron-icon').classList.add('rotate-180');
                    }
                }
            }


            if (!highlightIssueTitle) {
                contentArea.scrollTop = 0;
            }
        }

        function filterContent(searchTerm) {
            const issueItems = document.querySelectorAll('.issue-item');
            let visibleCount = 0;
            issueItems.forEach(item => {
                const title = item.getAttribute('data-title');
                const content = item.getAttribute('data-content'); 
                if (title.includes(searchTerm) || content.includes(searchTerm)) {
                    item.style.display = 'block';
                    visibleCount++;
                } else {
                    item.style.display = 'none';
                }
            });
            document.getElementById('no-results').style.display = visibleCount === 0 ? 'block' : 'none';
        }

        function renderCategoryCheckboxes() {
            const categoryCheckboxesDiv = document.getElementById('category-checkboxes');
            const selectAllBtn = document.getElementById('select-all-btn');
            const deselectAllBtn = document.getElementById('deselect-all-btn');

            if (!categoryCheckboxesDiv) {
                console.error("Error: 'category-checkboxes' element not found for rendering checkboxes.");
                return;
            }
            categoryCheckboxesDiv.innerHTML = ''; 
            const categoriesToFilter = Object.keys(db).filter(key => key !== 'dashboard' && key !== 'glossary' && db[key].issues);

            categoriesToFilter.forEach(key => {
                const category = db[key];
                const checkboxContainer = document.createElement('label');
                checkboxContainer.className = 'flex items-center space-x-2 text-medium-gray cursor-pointer hover:text-dark-charcoal transition-colors';

                const checkbox = document.createElement('input');
                checkbox.type = 'checkbox';
                checkbox.className = 'form-checkbox h-4 w-4 text-accent-dark rounded focus:ring-accent-dark';
                checkbox.value = key;
                checkbox.checked = true; 
                checkbox.addEventListener('change', renderCategoryChart); 

                const span = document.createElement('span');
                span.textContent = category.title;

                checkboxContainer.appendChild(checkbox);
                checkboxContainer.appendChild(span);
                categoryCheckboxesDiv.appendChild(checkboxContainer);
            });

            if (selectAllBtn) {
                selectAllBtn.addEventListener('click', selectAllCheckboxes);
            }
            if (deselectAllBtn) {
                deselectAllBtn.addEventListener('click', deselectAllCheckboxes);
            }
        }

        function selectAllCheckboxes() {
            const checkboxes = document.querySelectorAll('#category-checkboxes input[type="checkbox"]');
            checkboxes.forEach(cb => cb.checked = true);
            renderCategoryChart();
        }

        function deselectAllCheckboxes() {
            const checkboxes = document.querySelectorAll('#category-checkboxes input[type="checkbox"]');
            checkboxes.forEach(cb => cb.checked = false);
            renderCategoryChart();
        }


        function renderCategoryChart() {
            const ctx = document.getElementById('categoryChart')?.getContext('2d');
            const selectedCategoriesElements = document.querySelectorAll('#category-checkboxes input[type="checkbox"]:checked');
            const totalIssuesDisplay = document.getElementById('total-issues-display');

            if (!ctx || selectedCategoriesElements.length === 0) {
                if (categoryChartInstance) {
                    categoryChartInstance.destroy();
                    categoryChartInstance = null; 
                }
                if (totalIssuesDisplay) {
                    totalIssuesDisplay.textContent = '0'; 
                }
                return;
            }

            const labels = [];
            const data = [];
            const selectedCategories = Array.from(selectedCategoriesElements).map(cb => cb.value);

            const backgroundColors = [
                '#66BB6A', '#FFCA28', '#42A5F5', '#AB47BC', '#EF5350', '#FFA726', '#26C6DA', '#7E57C2', '#8D6E63', '#FF7043', '#BDBDBD', '#607D8B', '#8BC34A'
            ];
            const borderColors = [
                '#388E3C', '#FFA000', '#1976D2', '#7B1FA2', '#D32F2F', '#F57C00', '#0097A7', '#5E35B1', '#5D4037', '#E64A19', '#9E9E9E', '#455A64', '#689F38'
            ];


            let colorIndex = 0;
            const currentBackgroundColors = [];
            const currentBorderColors = [];
            let currentTotalIssues = 0;

            selectedCategories.forEach(key => {
                if (db[key] && db[key].issues) {
                    labels.push(db[key].title);
                    const issueCount = db[key].issues.length;
                    data.push(issueCount);
                    currentTotalIssues += issueCount;
                    currentBackgroundColors.push(backgroundColors[colorIndex % backgroundColors.length]);
                    currentBorderColors.push(borderColors[colorIndex % borderColors.length]);
                    colorIndex++;
                }
            });

            if (totalIssuesDisplay) {
                totalIssuesDisplay.textContent = currentTotalIssues;
            }

            if (categoryChartInstance) {
                categoryChartInstance.destroy();
            }

            categoryChartInstance = new Chart(ctx, {
                type: 'doughnut',
                data: {
                    labels: labels,
                    datasets: [{
                        data: data,
                        backgroundColor: currentBackgroundColors,
                        borderColor: currentBorderColors,
                        borderWidth: 1,
                        hoverOffset: 4
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    cutout: '70%',
                    plugins: {
                        legend: {
                            position: 'right',
                            labels: {
                                color: getComputedStyle(document.body).getPropertyValue('--text-dark-charcoal') || '#2B2D42'
                            }
                        },
                        tooltip: {
                            callbacks: {
                                label: function(context) {
                                    const label = context.label || '';
                                    const value = context.parsed;
                                    const percentage = ((value / currentTotalIssues) * 100).toFixed(1);
                                    return `${label}: ${value} (${percentage}%)`;
                                }
                            }
                        }
                    }
                }
            });
        }

        function getSeverityIcon(severity) {
            if (!severity) return 'fa-info-circle';
            switch (severity.toLowerCase()) {
                case 'critical': return 'fa-exclamation-triangle';
                case 'high': return 'fa-exclamation-circle';
                case 'medium': return 'fa-info-circle';
                case 'low': return 'fa-minus-circle';
                default: return 'fa-info-circle';
            }
        }

        function getSeverityColor(severity) {
            if (!severity) return '#5B6A78';
            switch (severity.toLowerCase()) {
                case 'critical': return '#F44336';
                case 'high': return '#FFC107';
                case 'medium': return '#2196F3';
                case 'low': return '#5B6A78';
                default: return '#5B6A78';
            }
        }

        function renderCommonIssues() {
            const commonIssuesList = document.getElementById('common-issues-list');
            if (!commonIssuesList) {
                console.error("Error: 'common-issues-list' element not found.");
                return;
            }
            commonIssuesList.innerHTML = ''; 

            const selectedIssues = [];
            const categoriesUsed = new Set();
            const maxIssues = 5;

            for (const categoryKey in db) {
                if (categoryKey !== 'dashboard' && categoryKey !== 'glossary' && db[categoryKey].issues && db[categoryKey].issues.length > 0) {
                    if (selectedIssues.length < maxIssues) {
                        const issue = db[categoryKey].issues[0];
                        selectedIssues.push({
                            categoryKey: categoryKey,
                            issue: issue,
                            issueIndex: 0 
                        });
                        categoriesUsed.add(categoryKey);
                    } else {
                        break; 
                    }
                }
            }

            selectedIssues.sort((a, b) => {
                const severityOrder = { 'critical': 4, 'high': 3, 'medium': 2, 'low': 1, 'n/a': 0 };
                const severityA = severityOrder[a.issue.severity ? a.issue.severity.toLowerCase() : 'n/a'];
                const severityB = severityOrder[b.issue.severity ? b.issue.severity.toLowerCase() : 'n/a'];

                if (severityA !== severityB) {
                    return severityB - severityA; 
                }
                return a.issue.title.localeCompare(b.issue.title); 
            });

            if (selectedIssues.length > 0) {
                selectedIssues.forEach(item => {
                    const severityClass = item.issue.severity ? item.issue.severity.toLowerCase() : 'low';
                    const severityColor = getSeverityColor(item.issue.severity);
                    const severityIcon = getSeverityIcon(item.issue.severity);

                    commonIssuesList.innerHTML += `
                        <a href="#" class="common-issue-item" data-category="${item.categoryKey}" data-issue-index="${item.issueIndex}">
                            <div class="issue-icon-wrapper ${severityClass}">
                                <i class="fas ${severityIcon}" style="color: ${severityColor};"></i>
                            </div>
                            <div class="issue-content-wrapper">
                                <div class="issue-title">${item.issue.title}</div>
                                <div class="issue-category">${db[item.categoryKey].title}</div>
                            </div>
                            <div class="issue-arrow">
                                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4">
                                    <path stroke-linecap="round" stroke-linejoin="round" d="M8.25 4.5l7.5 7.5-7.5 7.5" />
                                </svg>
                            </div>
                        </a>
                    `;
                });

                commonIssuesList.querySelectorAll('.common-issue-item').forEach(item => {
                    item.addEventListener('click', (e) => {
                        e.preventDefault();
                        const categoryKey = e.currentTarget.dataset.category;
                        const issueIndex = parseInt(e.currentTarget.dataset.issueIndex, 10);
                        renderContent(categoryKey); 
                        setTimeout(() => {
                            const issueAccordionButton = document.querySelector(`#issue-${categoryKey}-${issueIndex} .accordion-header`);
                            if (issueAccordionButton) {
                                const content = issueAccordionButton.nextElementSibling;
                                const icon = issueAccordionButton.querySelector('svg');
                                if (content.style.display !== 'block') { 
                                    content.style.display = 'block';
                                    icon.classList.add('rotate-180');
                                }
                                issueAccordionButton.scrollIntoView({ behavior: 'smooth', block: 'center' });
                            }
                        }, 100); 
                    });
                });

            } else {
                commonIssuesList.innerHTML = `
                    <div class="empty-state p-4 text-center text-medium-gray">
                        <i class="fas fa-info-circle mb-2 text-xl"></i>
                        <p>No common issues defined.</p>
                    </div>
                `;
            }
        }


        function applyTheme(theme) {
            document.body.classList.toggle('dark', theme === 'dark');
            if (theme === 'dark') {
                themeToggleLightIcon.classList.add('hidden');
                themeToggleDarkIcon.classList.remove('hidden');
            } else {
                themeToggleLightIcon.classList.remove('hidden');
                themeToggleDarkIcon.classList.add('hidden');
            }
            if (document.getElementById('categoryChart')) {
                renderCategoryChart();
            }
        }

        function toggleTheme() {
            const currentTheme = localStorage.getItem('theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            localStorage.setItem('theme', newTheme);
            applyTheme(newTheme);
        }

        document.addEventListener('DOMContentLoaded', () => {
            const savedTheme = localStorage.getItem('theme') || 'light';
            applyTheme(savedTheme);

            // Updated sidebar order
            const sidebarOrder = [
                'dashboard',
                'postgresql-installation-guide', // Moved to first
                'glossary',  // Moved to second
                'system-catalog-tables', // New category added here
                'error-guide-group',
                'postgresql-architecture', 
                'indexes', 
                'joins'
            ];

            const errorGuideKeys = [
                'connection-authentication',
                'locking-concurrency',
                'replication-ha',
                'backup-recovery',
                'performance-optimization',
                'query-indexing',
                'security-access-control',
                'data-integrity-consistency',
                'upgrade-migration',
                'troubleshooting-debugging'
            ];
            
            sidebarOrder.forEach(key => {
                if (key === 'error-guide-group') {
                    // Create collapsible "PostgreSQL Error Guide"
                    const guideContainer = document.createElement('div');
                    guideContainer.className = 'collapsible-group';
                    
                    const guideButton = document.createElement('button');
                    guideButton.className = 'sidebar-parent w-full flex items-center justify-between p-2 text-sm text-medium-gray rounded-lg hover-accent-bg transition-colors text-left';
                    guideButton.innerHTML = `
                        <span class="flex items-center">
                            ${categoryIcons['error-guide'] || ''} PostgreSQL Error Guide
                        </span>
                        <svg class="w-4 h-4 transform transition-transform chevron-icon" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
                        </svg>
                    `;
                    
                    const subMenuContainer = document.createElement('div');
                    subMenuContainer.className = 'submenu-container hidden pl-4 mt-1 space-y-1';

                    guideButton.addEventListener('click', () => {
                        subMenuContainer.classList.toggle('hidden');
                        guideButton.querySelector('.chevron-icon').classList.toggle('rotate-180');
                    });
                    
                    guideContainer.appendChild(guideButton);
                    guideContainer.appendChild(subMenuContainer);
                    mainNav.appendChild(guideContainer);

                    // Render sub-items for the error guide
                    errorGuideKeys.forEach(subKey => {
                        const item = document.createElement('a');
                        item.href = '#';
                        item.dataset.key = subKey;
                        item.className = 'sidebar-item flex items-center p-2 text-sm text-medium-gray rounded-lg hover-accent-bg transition-colors';
                        item.innerHTML = `${categoryIcons[subKey] || ''} ${db[subKey].title}`;
                        item.addEventListener('click', (e) => {
                            e.preventDefault();
                            renderContent(subKey);
                            if (window.innerWidth < 640) {
                                sidebar.classList.add('-translate-x-full');
                            }
                        });
                        subMenuContainer.appendChild(item);
                    });
                } else {
                     // Render other top-level items
                    const item = document.createElement('a');
                    item.href = '#';
                    item.dataset.key = key;
                    item.className = 'sidebar-item flex items-center p-2 text-sm text-medium-gray rounded-lg hover-accent-bg transition-colors';
                    item.innerHTML = `${categoryIcons[key] || ''} ${db[key].title}`;
                    item.addEventListener('click', (e) => {
                        e.preventDefault();
                        renderContent(key);
                        if (window.innerWidth < 640) {
                            sidebar.classList.add('-translate-x-full');
                        }
                    });
                    mainNav.appendChild(item);
                }
            });


            searchInput.addEventListener('input', (e) => filterContent(e.target.value.toLowerCase()));

            menuToggle.addEventListener('click', () => {
                sidebar.classList.toggle('-translate-x-full');
            });

            chatbotToggleButton.addEventListener('click', () => {
                chatbotContainer.classList.toggle('open');
            });

            chatbotCloseButton.addEventListener('click', () => {
                chatbotContainer.classList.remove('open');
            });

            chatbotSendButton.addEventListener('click', handleChatbotInput);
            chatbotInput.addEventListener('keypress', (e) => {
                if (e.key === 'Enter') {
                    handleChatbotInput();
                }
            });

            themeToggle.addEventListener('click', toggleTheme);

            // Render dashboard content on initial load
            renderContent('dashboard');
        });
    </script>
</body>

</html>
